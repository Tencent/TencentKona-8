//
// Copyright (c) 2003, 2013, Oracle and/or its affiliates. All rights reserved.
// Copyright (c) 2015, 2022, Loongson Technology. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is free software; you can redistribute it and/or modify it
// under the terms of the GNU General Public License version 2 only, as
// published by the Free Software Foundation.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// You should have received a copy of the GNU General Public License version
// 2 along with this work; if not, write to the Free Software Foundation,
// Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
//
// Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
// or visit www.oracle.com if you need additional information or have any
// questions.
//
//

// GodSon3 Architecture Description File

//----------REGISTER DEFINITION BLOCK------------------------------------------
// This information is used by the matcher and the register allocator to
// describe individual registers and classes of registers within the target
// archtecture.

// format:
// reg_def name (call convention, c-call convention, ideal type, encoding);
//     call convention :
//      NS  = No-Save
//      SOC = Save-On-Call
//      SOE = Save-On-Entry
//      AS  = Always-Save
//    ideal type :
//      see opto/opcodes.hpp for more info
// reg_class name (reg, ...);
// alloc_class name (reg, ...);
register %{

// General Registers
// Integer Registers
  reg_def R0    ( NS,  NS,  Op_RegI,   0, VMRegImpl::Bad());
  reg_def RA    ( NS,  NS,  Op_RegI,   1, RA->as_VMReg());
  reg_def RA_H  ( NS,  NS,  Op_RegI,   1, RA->as_VMReg()->next());
  // TODO: LA
  reg_def TP    ( NS,  NS,  Op_RegI,   2, TP->as_VMReg());
  reg_def TP_H  ( NS,  NS,  Op_RegI,   2, TP->as_VMReg()->next());
  reg_def SP    ( NS,  NS,  Op_RegI,   3, SP->as_VMReg());
  reg_def SP_H  ( NS,  NS,  Op_RegI,   3, SP->as_VMReg()->next());
  reg_def A0    (SOC, SOC,  Op_RegI,   4, A0->as_VMReg());
  reg_def A0_H  (SOC, SOC,  Op_RegI,   4, A0->as_VMReg()->next());
  reg_def A1    (SOC, SOC,  Op_RegI,   5, A1->as_VMReg());
  reg_def A1_H  (SOC, SOC,  Op_RegI,   5, A1->as_VMReg()->next());
  reg_def A2    (SOC, SOC,  Op_RegI,   6, A2->as_VMReg());
  reg_def A2_H  (SOC, SOC,  Op_RegI,   6, A2->as_VMReg()->next());
  reg_def A3    (SOC, SOC,  Op_RegI,   7, A3->as_VMReg());
  reg_def A3_H  (SOC, SOC,  Op_RegI,   7, A3->as_VMReg()->next());
  reg_def A4    (SOC, SOC,  Op_RegI,   8, A4->as_VMReg());
  reg_def A4_H  (SOC, SOC,  Op_RegI,   8, A4->as_VMReg()->next());
  reg_def A5    (SOC, SOC,  Op_RegI,   9, A5->as_VMReg());
  reg_def A5_H  (SOC, SOC,  Op_RegI,   9, A5->as_VMReg()->next());
  reg_def A6    (SOC, SOC,  Op_RegI,  10, A6->as_VMReg());
  reg_def A6_H  (SOC, SOC,  Op_RegI,  10, A6->as_VMReg()->next());
  reg_def A7    (SOC, SOC,  Op_RegI,  11, A7->as_VMReg());
  reg_def A7_H  (SOC, SOC,  Op_RegI,  11, A7->as_VMReg()->next());
  reg_def T0    (SOC, SOC,  Op_RegI,  12, T0->as_VMReg());
  reg_def T0_H  (SOC, SOC,  Op_RegI,  12, T0->as_VMReg()->next());
  reg_def T1    (SOC, SOC,  Op_RegI,  13, T1->as_VMReg());
  reg_def T1_H  (SOC, SOC,  Op_RegI,  13, T1->as_VMReg()->next());
  reg_def T2    (SOC, SOC,  Op_RegI,  14, T2->as_VMReg());
  reg_def T2_H  (SOC, SOC,  Op_RegI,  14, T2->as_VMReg()->next());
  reg_def T3    (SOC, SOC,  Op_RegI,  15, T3->as_VMReg());
  reg_def T3_H  (SOC, SOC,  Op_RegI,  15, T3->as_VMReg()->next());
  reg_def T4    (SOC, SOC,  Op_RegI,  16, T4->as_VMReg());
  reg_def T4_H  (SOC, SOC,  Op_RegI,  16, T4->as_VMReg()->next());
  reg_def T5    (SOC, SOC,  Op_RegI,  17, T5->as_VMReg());
  reg_def T5_H  (SOC, SOC,  Op_RegI,  17, T5->as_VMReg()->next());
  reg_def T6    (SOC, SOC,  Op_RegI,  18, T6->as_VMReg());
  reg_def T6_H  (SOC, SOC,  Op_RegI,  18, T6->as_VMReg()->next());
  reg_def T7    (SOC, SOC,  Op_RegI,  19, T7->as_VMReg());
  reg_def T7_H  (SOC, SOC,  Op_RegI,  19, T7->as_VMReg()->next());
  reg_def T8    (SOC, SOC,  Op_RegI,  20, T8->as_VMReg());
  reg_def T8_H  (SOC, SOC,  Op_RegI,  20, T8->as_VMReg()->next());
  reg_def RX    ( NS,  NS,  Op_RegI,  21, RX->as_VMReg());
  reg_def RX_H  ( NS,  NS,  Op_RegI,  21, RX->as_VMReg()->next());
  reg_def FP    ( NS,  NS,  Op_RegI,  22, FP->as_VMReg());
  reg_def FP_H  ( NS,  NS,  Op_RegI,  22, FP->as_VMReg()->next());
  reg_def S0    (SOC, SOE,  Op_RegI,  23, S0->as_VMReg());
  reg_def S0_H  (SOC, SOE,  Op_RegI,  23, S0->as_VMReg()->next());
  reg_def S1    (SOC, SOE,  Op_RegI,  24, S1->as_VMReg());
  reg_def S1_H  (SOC, SOE,  Op_RegI,  24, S1->as_VMReg()->next());
  reg_def S2    (SOC, SOE,  Op_RegI,  25, S2->as_VMReg());
  reg_def S2_H  (SOC, SOE,  Op_RegI,  25, S2->as_VMReg()->next());
  reg_def S3    (SOC, SOE,  Op_RegI,  26, S3->as_VMReg());
  reg_def S3_H  (SOC, SOE,  Op_RegI,  26, S3->as_VMReg()->next());
  reg_def S4    (SOC, SOE,  Op_RegI,  27, S4->as_VMReg());
  reg_def S4_H  (SOC, SOE,  Op_RegI,  27, S4->as_VMReg()->next());
  reg_def S5    (SOC, SOE,  Op_RegI,  28, S5->as_VMReg());
  reg_def S5_H  (SOC, SOE,  Op_RegI,  28, S5->as_VMReg()->next());
  reg_def S6    (SOC, SOE,  Op_RegI,  29, S6->as_VMReg());
  reg_def S6_H  (SOC, SOE,  Op_RegI,  29, S6->as_VMReg()->next());
  reg_def S7    (SOC, SOE,  Op_RegI,  30, S7->as_VMReg());
  reg_def S7_H  (SOC, SOE,  Op_RegI,  30, S7->as_VMReg()->next());
  // TODO: LA
  reg_def S8    ( NS,  NS,  Op_RegI,  31, S8->as_VMReg());
  reg_def S8_H  ( NS,  NS,  Op_RegI,  31, S8->as_VMReg()->next());


// Floating/Vector registers.
reg_def F0          ( SOC, SOC, Op_RegF, 0, F0->as_VMReg()          );
reg_def F0_H        ( SOC, SOC, Op_RegF, 0, F0->as_VMReg()->next()  );
reg_def F0_J        ( SOC, SOC, Op_RegF, 0, F0->as_VMReg()->next(2) );
reg_def F0_K        ( SOC, SOC, Op_RegF, 0, F0->as_VMReg()->next(3) );
reg_def F0_L        ( SOC, SOC, Op_RegF, 0, F0->as_VMReg()->next(4) );
reg_def F0_M        ( SOC, SOC, Op_RegF, 0, F0->as_VMReg()->next(5) );
reg_def F0_N        ( SOC, SOC, Op_RegF, 0, F0->as_VMReg()->next(6) );
reg_def F0_O        ( SOC, SOC, Op_RegF, 0, F0->as_VMReg()->next(7) );

reg_def F1          ( SOC, SOC, Op_RegF, 1, F1->as_VMReg()          );
reg_def F1_H        ( SOC, SOC, Op_RegF, 1, F1->as_VMReg()->next()  );
reg_def F1_J        ( SOC, SOC, Op_RegF, 1, F1->as_VMReg()->next(2) );
reg_def F1_K        ( SOC, SOC, Op_RegF, 1, F1->as_VMReg()->next(3) );
reg_def F1_L        ( SOC, SOC, Op_RegF, 1, F1->as_VMReg()->next(4) );
reg_def F1_M        ( SOC, SOC, Op_RegF, 1, F1->as_VMReg()->next(5) );
reg_def F1_N        ( SOC, SOC, Op_RegF, 1, F1->as_VMReg()->next(6) );
reg_def F1_O        ( SOC, SOC, Op_RegF, 1, F1->as_VMReg()->next(7) );

reg_def F2          ( SOC, SOC, Op_RegF, 2, F2->as_VMReg()          );
reg_def F2_H        ( SOC, SOC, Op_RegF, 2, F2->as_VMReg()->next()  );
reg_def F2_J        ( SOC, SOC, Op_RegF, 2, F2->as_VMReg()->next(2) );
reg_def F2_K        ( SOC, SOC, Op_RegF, 2, F2->as_VMReg()->next(3) );
reg_def F2_L        ( SOC, SOC, Op_RegF, 2, F2->as_VMReg()->next(4) );
reg_def F2_M        ( SOC, SOC, Op_RegF, 2, F2->as_VMReg()->next(5) );
reg_def F2_N        ( SOC, SOC, Op_RegF, 2, F2->as_VMReg()->next(6) );
reg_def F2_O        ( SOC, SOC, Op_RegF, 2, F2->as_VMReg()->next(7) );

reg_def F3          ( SOC, SOC, Op_RegF, 3, F3->as_VMReg()          );
reg_def F3_H        ( SOC, SOC, Op_RegF, 3, F3->as_VMReg()->next()  );
reg_def F3_J        ( SOC, SOC, Op_RegF, 3, F3->as_VMReg()->next(2) );
reg_def F3_K        ( SOC, SOC, Op_RegF, 3, F3->as_VMReg()->next(3) );
reg_def F3_L        ( SOC, SOC, Op_RegF, 3, F3->as_VMReg()->next(4) );
reg_def F3_M        ( SOC, SOC, Op_RegF, 3, F3->as_VMReg()->next(5) );
reg_def F3_N        ( SOC, SOC, Op_RegF, 3, F3->as_VMReg()->next(6) );
reg_def F3_O        ( SOC, SOC, Op_RegF, 3, F3->as_VMReg()->next(7) );

reg_def F4          ( SOC, SOC, Op_RegF, 4, F4->as_VMReg()          );
reg_def F4_H        ( SOC, SOC, Op_RegF, 4, F4->as_VMReg()->next()  );
reg_def F4_J        ( SOC, SOC, Op_RegF, 4, F4->as_VMReg()->next(2) );
reg_def F4_K        ( SOC, SOC, Op_RegF, 4, F4->as_VMReg()->next(3) );
reg_def F4_L        ( SOC, SOC, Op_RegF, 4, F4->as_VMReg()->next(4) );
reg_def F4_M        ( SOC, SOC, Op_RegF, 4, F4->as_VMReg()->next(5) );
reg_def F4_N        ( SOC, SOC, Op_RegF, 4, F4->as_VMReg()->next(6) );
reg_def F4_O        ( SOC, SOC, Op_RegF, 4, F4->as_VMReg()->next(7) );

reg_def F5          ( SOC, SOC, Op_RegF, 5, F5->as_VMReg()          );
reg_def F5_H        ( SOC, SOC, Op_RegF, 5, F5->as_VMReg()->next()  );
reg_def F5_J        ( SOC, SOC, Op_RegF, 5, F5->as_VMReg()->next(2) );
reg_def F5_K        ( SOC, SOC, Op_RegF, 5, F5->as_VMReg()->next(3) );
reg_def F5_L        ( SOC, SOC, Op_RegF, 5, F5->as_VMReg()->next(4) );
reg_def F5_M        ( SOC, SOC, Op_RegF, 5, F5->as_VMReg()->next(5) );
reg_def F5_N        ( SOC, SOC, Op_RegF, 5, F5->as_VMReg()->next(6) );
reg_def F5_O        ( SOC, SOC, Op_RegF, 5, F5->as_VMReg()->next(7) );

reg_def F6          ( SOC, SOC, Op_RegF, 6, F6->as_VMReg()          );
reg_def F6_H        ( SOC, SOC, Op_RegF, 6, F6->as_VMReg()->next()  );
reg_def F6_J        ( SOC, SOC, Op_RegF, 6, F6->as_VMReg()->next(2) );
reg_def F6_K        ( SOC, SOC, Op_RegF, 6, F6->as_VMReg()->next(3) );
reg_def F6_L        ( SOC, SOC, Op_RegF, 6, F6->as_VMReg()->next(4) );
reg_def F6_M        ( SOC, SOC, Op_RegF, 6, F6->as_VMReg()->next(5) );
reg_def F6_N        ( SOC, SOC, Op_RegF, 6, F6->as_VMReg()->next(6) );
reg_def F6_O        ( SOC, SOC, Op_RegF, 6, F6->as_VMReg()->next(7) );

reg_def F7          ( SOC, SOC, Op_RegF, 7, F7->as_VMReg()          );
reg_def F7_H        ( SOC, SOC, Op_RegF, 7, F7->as_VMReg()->next()  );
reg_def F7_J        ( SOC, SOC, Op_RegF, 7, F7->as_VMReg()->next(2) );
reg_def F7_K        ( SOC, SOC, Op_RegF, 7, F7->as_VMReg()->next(3) );
reg_def F7_L        ( SOC, SOC, Op_RegF, 7, F7->as_VMReg()->next(4) );
reg_def F7_M        ( SOC, SOC, Op_RegF, 7, F7->as_VMReg()->next(5) );
reg_def F7_N        ( SOC, SOC, Op_RegF, 7, F7->as_VMReg()->next(6) );
reg_def F7_O        ( SOC, SOC, Op_RegF, 7, F7->as_VMReg()->next(7) );

reg_def F8          ( SOC, SOC, Op_RegF, 8, F8->as_VMReg()          );
reg_def F8_H        ( SOC, SOC, Op_RegF, 8, F8->as_VMReg()->next()  );
reg_def F8_J        ( SOC, SOC, Op_RegF, 8, F8->as_VMReg()->next(2) );
reg_def F8_K        ( SOC, SOC, Op_RegF, 8, F8->as_VMReg()->next(3) );
reg_def F8_L        ( SOC, SOC, Op_RegF, 8, F8->as_VMReg()->next(4) );
reg_def F8_M        ( SOC, SOC, Op_RegF, 8, F8->as_VMReg()->next(5) );
reg_def F8_N        ( SOC, SOC, Op_RegF, 8, F8->as_VMReg()->next(6) );
reg_def F8_O        ( SOC, SOC, Op_RegF, 8, F8->as_VMReg()->next(7) );

reg_def F9          ( SOC, SOC, Op_RegF, 9, F9->as_VMReg()          );
reg_def F9_H        ( SOC, SOC, Op_RegF, 9, F9->as_VMReg()->next()  );
reg_def F9_J        ( SOC, SOC, Op_RegF, 9, F9->as_VMReg()->next(2) );
reg_def F9_K        ( SOC, SOC, Op_RegF, 9, F9->as_VMReg()->next(3) );
reg_def F9_L        ( SOC, SOC, Op_RegF, 9, F9->as_VMReg()->next(4) );
reg_def F9_M        ( SOC, SOC, Op_RegF, 9, F9->as_VMReg()->next(5) );
reg_def F9_N        ( SOC, SOC, Op_RegF, 9, F9->as_VMReg()->next(6) );
reg_def F9_O        ( SOC, SOC, Op_RegF, 9, F9->as_VMReg()->next(7) );

reg_def F10          ( SOC, SOC, Op_RegF, 10, F10->as_VMReg()          );
reg_def F10_H        ( SOC, SOC, Op_RegF, 10, F10->as_VMReg()->next()  );
reg_def F10_J        ( SOC, SOC, Op_RegF, 10, F10->as_VMReg()->next(2) );
reg_def F10_K        ( SOC, SOC, Op_RegF, 10, F10->as_VMReg()->next(3) );
reg_def F10_L        ( SOC, SOC, Op_RegF, 10, F10->as_VMReg()->next(4) );
reg_def F10_M        ( SOC, SOC, Op_RegF, 10, F10->as_VMReg()->next(5) );
reg_def F10_N        ( SOC, SOC, Op_RegF, 10, F10->as_VMReg()->next(6) );
reg_def F10_O        ( SOC, SOC, Op_RegF, 10, F10->as_VMReg()->next(7) );

reg_def F11          ( SOC, SOC, Op_RegF, 11, F11->as_VMReg()          );
reg_def F11_H        ( SOC, SOC, Op_RegF, 11, F11->as_VMReg()->next()  );
reg_def F11_J        ( SOC, SOC, Op_RegF, 11, F11->as_VMReg()->next(2) );
reg_def F11_K        ( SOC, SOC, Op_RegF, 11, F11->as_VMReg()->next(3) );
reg_def F11_L        ( SOC, SOC, Op_RegF, 11, F11->as_VMReg()->next(4) );
reg_def F11_M        ( SOC, SOC, Op_RegF, 11, F11->as_VMReg()->next(5) );
reg_def F11_N        ( SOC, SOC, Op_RegF, 11, F11->as_VMReg()->next(6) );
reg_def F11_O        ( SOC, SOC, Op_RegF, 11, F11->as_VMReg()->next(7) );

reg_def F12          ( SOC, SOC, Op_RegF, 12, F12->as_VMReg()          );
reg_def F12_H        ( SOC, SOC, Op_RegF, 12, F12->as_VMReg()->next()  );
reg_def F12_J        ( SOC, SOC, Op_RegF, 12, F12->as_VMReg()->next(2) );
reg_def F12_K        ( SOC, SOC, Op_RegF, 12, F12->as_VMReg()->next(3) );
reg_def F12_L        ( SOC, SOC, Op_RegF, 12, F12->as_VMReg()->next(4) );
reg_def F12_M        ( SOC, SOC, Op_RegF, 12, F12->as_VMReg()->next(5) );
reg_def F12_N        ( SOC, SOC, Op_RegF, 12, F12->as_VMReg()->next(6) );
reg_def F12_O        ( SOC, SOC, Op_RegF, 12, F12->as_VMReg()->next(7) );

reg_def F13          ( SOC, SOC, Op_RegF, 13, F13->as_VMReg()          );
reg_def F13_H        ( SOC, SOC, Op_RegF, 13, F13->as_VMReg()->next()  );
reg_def F13_J        ( SOC, SOC, Op_RegF, 13, F13->as_VMReg()->next(2) );
reg_def F13_K        ( SOC, SOC, Op_RegF, 13, F13->as_VMReg()->next(3) );
reg_def F13_L        ( SOC, SOC, Op_RegF, 13, F13->as_VMReg()->next(4) );
reg_def F13_M        ( SOC, SOC, Op_RegF, 13, F13->as_VMReg()->next(5) );
reg_def F13_N        ( SOC, SOC, Op_RegF, 13, F13->as_VMReg()->next(6) );
reg_def F13_O        ( SOC, SOC, Op_RegF, 13, F13->as_VMReg()->next(7) );

reg_def F14          ( SOC, SOC, Op_RegF, 14, F14->as_VMReg()          );
reg_def F14_H        ( SOC, SOC, Op_RegF, 14, F14->as_VMReg()->next()  );
reg_def F14_J        ( SOC, SOC, Op_RegF, 14, F14->as_VMReg()->next(2) );
reg_def F14_K        ( SOC, SOC, Op_RegF, 14, F14->as_VMReg()->next(3) );
reg_def F14_L        ( SOC, SOC, Op_RegF, 14, F14->as_VMReg()->next(4) );
reg_def F14_M        ( SOC, SOC, Op_RegF, 14, F14->as_VMReg()->next(5) );
reg_def F14_N        ( SOC, SOC, Op_RegF, 14, F14->as_VMReg()->next(6) );
reg_def F14_O        ( SOC, SOC, Op_RegF, 14, F14->as_VMReg()->next(7) );

reg_def F15          ( SOC, SOC, Op_RegF, 15, F15->as_VMReg()          );
reg_def F15_H        ( SOC, SOC, Op_RegF, 15, F15->as_VMReg()->next()  );
reg_def F15_J        ( SOC, SOC, Op_RegF, 15, F15->as_VMReg()->next(2) );
reg_def F15_K        ( SOC, SOC, Op_RegF, 15, F15->as_VMReg()->next(3) );
reg_def F15_L        ( SOC, SOC, Op_RegF, 15, F15->as_VMReg()->next(4) );
reg_def F15_M        ( SOC, SOC, Op_RegF, 15, F15->as_VMReg()->next(5) );
reg_def F15_N        ( SOC, SOC, Op_RegF, 15, F15->as_VMReg()->next(6) );
reg_def F15_O        ( SOC, SOC, Op_RegF, 15, F15->as_VMReg()->next(7) );

reg_def F16          ( SOC, SOC, Op_RegF, 16, F16->as_VMReg()          );
reg_def F16_H        ( SOC, SOC, Op_RegF, 16, F16->as_VMReg()->next()  );
reg_def F16_J        ( SOC, SOC, Op_RegF, 16, F16->as_VMReg()->next(2) );
reg_def F16_K        ( SOC, SOC, Op_RegF, 16, F16->as_VMReg()->next(3) );
reg_def F16_L        ( SOC, SOC, Op_RegF, 16, F16->as_VMReg()->next(4) );
reg_def F16_M        ( SOC, SOC, Op_RegF, 16, F16->as_VMReg()->next(5) );
reg_def F16_N        ( SOC, SOC, Op_RegF, 16, F16->as_VMReg()->next(6) );
reg_def F16_O        ( SOC, SOC, Op_RegF, 16, F16->as_VMReg()->next(7) );

reg_def F17          ( SOC, SOC, Op_RegF, 17, F17->as_VMReg()          );
reg_def F17_H        ( SOC, SOC, Op_RegF, 17, F17->as_VMReg()->next()  );
reg_def F17_J        ( SOC, SOC, Op_RegF, 17, F17->as_VMReg()->next(2) );
reg_def F17_K        ( SOC, SOC, Op_RegF, 17, F17->as_VMReg()->next(3) );
reg_def F17_L        ( SOC, SOC, Op_RegF, 17, F17->as_VMReg()->next(4) );
reg_def F17_M        ( SOC, SOC, Op_RegF, 17, F17->as_VMReg()->next(5) );
reg_def F17_N        ( SOC, SOC, Op_RegF, 17, F17->as_VMReg()->next(6) );
reg_def F17_O        ( SOC, SOC, Op_RegF, 17, F17->as_VMReg()->next(7) );

reg_def F18          ( SOC, SOC, Op_RegF, 18, F18->as_VMReg()          );
reg_def F18_H        ( SOC, SOC, Op_RegF, 18, F18->as_VMReg()->next()  );
reg_def F18_J        ( SOC, SOC, Op_RegF, 18, F18->as_VMReg()->next(2) );
reg_def F18_K        ( SOC, SOC, Op_RegF, 18, F18->as_VMReg()->next(3) );
reg_def F18_L        ( SOC, SOC, Op_RegF, 18, F18->as_VMReg()->next(4) );
reg_def F18_M        ( SOC, SOC, Op_RegF, 18, F18->as_VMReg()->next(5) );
reg_def F18_N        ( SOC, SOC, Op_RegF, 18, F18->as_VMReg()->next(6) );
reg_def F18_O        ( SOC, SOC, Op_RegF, 18, F18->as_VMReg()->next(7) );

reg_def F19          ( SOC, SOC, Op_RegF, 19, F19->as_VMReg()          );
reg_def F19_H        ( SOC, SOC, Op_RegF, 19, F19->as_VMReg()->next()  );
reg_def F19_J        ( SOC, SOC, Op_RegF, 19, F19->as_VMReg()->next(2) );
reg_def F19_K        ( SOC, SOC, Op_RegF, 19, F19->as_VMReg()->next(3) );
reg_def F19_L        ( SOC, SOC, Op_RegF, 19, F19->as_VMReg()->next(4) );
reg_def F19_M        ( SOC, SOC, Op_RegF, 19, F19->as_VMReg()->next(5) );
reg_def F19_N        ( SOC, SOC, Op_RegF, 19, F19->as_VMReg()->next(6) );
reg_def F19_O        ( SOC, SOC, Op_RegF, 19, F19->as_VMReg()->next(7) );

reg_def F20          ( SOC, SOC, Op_RegF, 20, F20->as_VMReg()          );
reg_def F20_H        ( SOC, SOC, Op_RegF, 20, F20->as_VMReg()->next()  );
reg_def F20_J        ( SOC, SOC, Op_RegF, 20, F20->as_VMReg()->next(2) );
reg_def F20_K        ( SOC, SOC, Op_RegF, 20, F20->as_VMReg()->next(3) );
reg_def F20_L        ( SOC, SOC, Op_RegF, 20, F20->as_VMReg()->next(4) );
reg_def F20_M        ( SOC, SOC, Op_RegF, 20, F20->as_VMReg()->next(5) );
reg_def F20_N        ( SOC, SOC, Op_RegF, 20, F20->as_VMReg()->next(6) );
reg_def F20_O        ( SOC, SOC, Op_RegF, 20, F20->as_VMReg()->next(7) );

reg_def F21          ( SOC, SOC, Op_RegF, 21, F21->as_VMReg()          );
reg_def F21_H        ( SOC, SOC, Op_RegF, 21, F21->as_VMReg()->next()  );
reg_def F21_J        ( SOC, SOC, Op_RegF, 21, F21->as_VMReg()->next(2) );
reg_def F21_K        ( SOC, SOC, Op_RegF, 21, F21->as_VMReg()->next(3) );
reg_def F21_L        ( SOC, SOC, Op_RegF, 21, F21->as_VMReg()->next(4) );
reg_def F21_M        ( SOC, SOC, Op_RegF, 21, F21->as_VMReg()->next(5) );
reg_def F21_N        ( SOC, SOC, Op_RegF, 21, F21->as_VMReg()->next(6) );
reg_def F21_O        ( SOC, SOC, Op_RegF, 21, F21->as_VMReg()->next(7) );

reg_def F22          ( SOC, SOC, Op_RegF, 22, F22->as_VMReg()          );
reg_def F22_H        ( SOC, SOC, Op_RegF, 22, F22->as_VMReg()->next()  );
reg_def F22_J        ( SOC, SOC, Op_RegF, 22, F22->as_VMReg()->next(2) );
reg_def F22_K        ( SOC, SOC, Op_RegF, 22, F22->as_VMReg()->next(3) );
reg_def F22_L        ( SOC, SOC, Op_RegF, 22, F22->as_VMReg()->next(4) );
reg_def F22_M        ( SOC, SOC, Op_RegF, 22, F22->as_VMReg()->next(5) );
reg_def F22_N        ( SOC, SOC, Op_RegF, 22, F22->as_VMReg()->next(6) );
reg_def F22_O        ( SOC, SOC, Op_RegF, 22, F22->as_VMReg()->next(7) );

reg_def F23          ( SOC, SOC, Op_RegF, 23, F23->as_VMReg()          );
reg_def F23_H        ( SOC, SOC, Op_RegF, 23, F23->as_VMReg()->next()  );
reg_def F23_J        ( SOC, SOC, Op_RegF, 23, F23->as_VMReg()->next(2) );
reg_def F23_K        ( SOC, SOC, Op_RegF, 23, F23->as_VMReg()->next(3) );
reg_def F23_L        ( SOC, SOC, Op_RegF, 23, F23->as_VMReg()->next(4) );
reg_def F23_M        ( SOC, SOC, Op_RegF, 23, F23->as_VMReg()->next(5) );
reg_def F23_N        ( SOC, SOC, Op_RegF, 23, F23->as_VMReg()->next(6) );
reg_def F23_O        ( SOC, SOC, Op_RegF, 23, F23->as_VMReg()->next(7) );

reg_def F24          ( SOC, SOC, Op_RegF, 24, F24->as_VMReg()          );
reg_def F24_H        ( SOC, SOC, Op_RegF, 24, F24->as_VMReg()->next()  );
reg_def F24_J        ( SOC, SOC, Op_RegF, 24, F24->as_VMReg()->next(2) );
reg_def F24_K        ( SOC, SOC, Op_RegF, 24, F24->as_VMReg()->next(3) );
reg_def F24_L        ( SOC, SOC, Op_RegF, 24, F24->as_VMReg()->next(4) );
reg_def F24_M        ( SOC, SOC, Op_RegF, 24, F24->as_VMReg()->next(5) );
reg_def F24_N        ( SOC, SOC, Op_RegF, 24, F24->as_VMReg()->next(6) );
reg_def F24_O        ( SOC, SOC, Op_RegF, 24, F24->as_VMReg()->next(7) );

reg_def F25          ( SOC, SOC, Op_RegF, 25, F25->as_VMReg()          );
reg_def F25_H        ( SOC, SOC, Op_RegF, 25, F25->as_VMReg()->next()  );
reg_def F25_J        ( SOC, SOC, Op_RegF, 25, F25->as_VMReg()->next(2) );
reg_def F25_K        ( SOC, SOC, Op_RegF, 25, F25->as_VMReg()->next(3) );
reg_def F25_L        ( SOC, SOC, Op_RegF, 25, F25->as_VMReg()->next(4) );
reg_def F25_M        ( SOC, SOC, Op_RegF, 25, F25->as_VMReg()->next(5) );
reg_def F25_N        ( SOC, SOC, Op_RegF, 25, F25->as_VMReg()->next(6) );
reg_def F25_O        ( SOC, SOC, Op_RegF, 25, F25->as_VMReg()->next(7) );

reg_def F26          ( SOC, SOC, Op_RegF, 26, F26->as_VMReg()          );
reg_def F26_H        ( SOC, SOC, Op_RegF, 26, F26->as_VMReg()->next()  );
reg_def F26_J        ( SOC, SOC, Op_RegF, 26, F26->as_VMReg()->next(2) );
reg_def F26_K        ( SOC, SOC, Op_RegF, 26, F26->as_VMReg()->next(3) );
reg_def F26_L        ( SOC, SOC, Op_RegF, 26, F26->as_VMReg()->next(4) );
reg_def F26_M        ( SOC, SOC, Op_RegF, 26, F26->as_VMReg()->next(5) );
reg_def F26_N        ( SOC, SOC, Op_RegF, 26, F26->as_VMReg()->next(6) );
reg_def F26_O        ( SOC, SOC, Op_RegF, 26, F26->as_VMReg()->next(7) );

reg_def F27          ( SOC, SOC, Op_RegF, 27, F27->as_VMReg()          );
reg_def F27_H        ( SOC, SOC, Op_RegF, 27, F27->as_VMReg()->next()  );
reg_def F27_J        ( SOC, SOC, Op_RegF, 27, F27->as_VMReg()->next(2) );
reg_def F27_K        ( SOC, SOC, Op_RegF, 27, F27->as_VMReg()->next(3) );
reg_def F27_L        ( SOC, SOC, Op_RegF, 27, F27->as_VMReg()->next(4) );
reg_def F27_M        ( SOC, SOC, Op_RegF, 27, F27->as_VMReg()->next(5) );
reg_def F27_N        ( SOC, SOC, Op_RegF, 27, F27->as_VMReg()->next(6) );
reg_def F27_O        ( SOC, SOC, Op_RegF, 27, F27->as_VMReg()->next(7) );

reg_def F28          ( SOC, SOC, Op_RegF, 28, F28->as_VMReg()          );
reg_def F28_H        ( SOC, SOC, Op_RegF, 28, F28->as_VMReg()->next()  );
reg_def F28_J        ( SOC, SOC, Op_RegF, 28, F28->as_VMReg()->next(2) );
reg_def F28_K        ( SOC, SOC, Op_RegF, 28, F28->as_VMReg()->next(3) );
reg_def F28_L        ( SOC, SOC, Op_RegF, 28, F28->as_VMReg()->next(4) );
reg_def F28_M        ( SOC, SOC, Op_RegF, 28, F28->as_VMReg()->next(5) );
reg_def F28_N        ( SOC, SOC, Op_RegF, 28, F28->as_VMReg()->next(6) );
reg_def F28_O        ( SOC, SOC, Op_RegF, 28, F28->as_VMReg()->next(7) );

reg_def F29          ( SOC, SOC, Op_RegF, 29, F29->as_VMReg()          );
reg_def F29_H        ( SOC, SOC, Op_RegF, 29, F29->as_VMReg()->next()  );
reg_def F29_J        ( SOC, SOC, Op_RegF, 29, F29->as_VMReg()->next(2) );
reg_def F29_K        ( SOC, SOC, Op_RegF, 29, F29->as_VMReg()->next(3) );
reg_def F29_L        ( SOC, SOC, Op_RegF, 29, F29->as_VMReg()->next(4) );
reg_def F29_M        ( SOC, SOC, Op_RegF, 29, F29->as_VMReg()->next(5) );
reg_def F29_N        ( SOC, SOC, Op_RegF, 29, F29->as_VMReg()->next(6) );
reg_def F29_O        ( SOC, SOC, Op_RegF, 29, F29->as_VMReg()->next(7) );

reg_def F30          ( SOC, SOC, Op_RegF, 30, F30->as_VMReg()          );
reg_def F30_H        ( SOC, SOC, Op_RegF, 30, F30->as_VMReg()->next()  );
reg_def F30_J        ( SOC, SOC, Op_RegF, 30, F30->as_VMReg()->next(2) );
reg_def F30_K        ( SOC, SOC, Op_RegF, 30, F30->as_VMReg()->next(3) );
reg_def F30_L        ( SOC, SOC, Op_RegF, 30, F30->as_VMReg()->next(4) );
reg_def F30_M        ( SOC, SOC, Op_RegF, 30, F30->as_VMReg()->next(5) );
reg_def F30_N        ( SOC, SOC, Op_RegF, 30, F30->as_VMReg()->next(6) );
reg_def F30_O        ( SOC, SOC, Op_RegF, 30, F30->as_VMReg()->next(7) );

reg_def F31          ( SOC, SOC, Op_RegF, 31, F31->as_VMReg()          );
reg_def F31_H        ( SOC, SOC, Op_RegF, 31, F31->as_VMReg()->next()  );
reg_def F31_J        ( SOC, SOC, Op_RegF, 31, F31->as_VMReg()->next(2) );
reg_def F31_K        ( SOC, SOC, Op_RegF, 31, F31->as_VMReg()->next(3) );
reg_def F31_L        ( SOC, SOC, Op_RegF, 31, F31->as_VMReg()->next(4) );
reg_def F31_M        ( SOC, SOC, Op_RegF, 31, F31->as_VMReg()->next(5) );
reg_def F31_N        ( SOC, SOC, Op_RegF, 31, F31->as_VMReg()->next(6) );
reg_def F31_O        ( SOC, SOC, Op_RegF, 31, F31->as_VMReg()->next(7) );


// ----------------------------
// Special Registers
//S6 is used for get_thread(S6)
//S5 is uesd for heapbase of compressed oop
alloc_class chunk0(
                     S7, S7_H,
                     S0, S0_H,
                     S1, S1_H,
                     S2, S2_H,
                     S4, S4_H,
                     S5, S5_H,
                     S6, S6_H,
                     S3, S3_H,
                     T2, T2_H,
                     T3, T3_H,
                     T8, T8_H,
                     T4, T4_H,
                     T1, T1_H, // inline_cache_reg
                     T6, T6_H,
                     A7, A7_H,
                     A6, A6_H,
                     A5, A5_H,
                     A4, A4_H,
                     T5, T5_H,
                     A3, A3_H,
                     A2, A2_H,
                     A1, A1_H,
                     A0, A0_H,
                     T0, T0_H,
                     S8, S8_H
                     RA, RA_H,
                     SP, SP_H, // stack_pointer
                     FP, FP_H  // frame_pointer
                 );

// F23 is scratch reg
alloc_class chunk1(  F0, F0_H, F0_J, F0_K, F0_L, F0_M, F0_N, F0_O,
                     F1, F1_H, F1_J, F1_K, F1_L, F1_M, F1_N, F1_O,
                     F2, F2_H, F2_J, F2_K, F2_L, F2_M, F2_N, F2_O,
                     F3, F3_H, F3_J, F3_K, F3_L, F3_M, F3_N, F3_O,
                     F4, F4_H, F4_J, F4_K, F4_L, F4_M, F4_N, F4_O,
                     F5, F5_H, F5_J, F5_K, F5_L, F5_M, F5_N, F5_O,
                     F6, F6_H, F6_J, F6_K, F6_L, F6_M, F6_N, F6_O,
                     F7, F7_H, F7_J, F7_K, F7_L, F7_M, F7_N, F7_O,
                     F8, F8_H, F8_J, F8_K, F8_L, F8_M, F8_N, F8_O,
                     F9, F9_H, F9_J, F9_K, F9_L, F9_M, F9_N, F9_O,
                     F10, F10_H, F10_J, F10_K, F10_L, F10_M, F10_N, F10_O,
                     F11, F11_H, F11_J, F11_K, F11_L, F11_M, F11_N, F11_O,
                     F12, F12_H, F12_J, F12_K, F12_L, F12_M, F12_N, F12_O,
                     F13, F13_H, F13_J, F13_K, F13_L, F13_M, F13_N, F13_O,
                     F14, F14_H, F14_J, F14_K, F14_L, F14_M, F14_N, F14_O,
                     F15, F15_H, F15_J, F15_K, F15_L, F15_M, F15_N, F15_O,
                     F16, F16_H, F16_J, F16_K, F16_L, F16_M, F16_N, F16_O,
                     F17, F17_H, F17_J, F17_K, F17_L, F17_M, F17_N, F17_O,
                     F18, F18_H, F18_J, F18_K, F18_L, F18_M, F18_N, F18_O,
                     F19, F19_H, F19_J, F19_K, F19_L, F19_M, F19_N, F19_O,
                     F20, F20_H, F20_J, F20_K, F20_L, F20_M, F20_N, F20_O,
                     F21, F21_H, F21_J, F21_K, F21_L, F21_M, F21_N, F21_O,
                     F22, F22_H, F22_J, F22_K, F22_L, F22_M, F22_N, F22_O,
                     F24, F24_H, F24_J, F24_K, F24_L, F24_M, F24_N, F24_O,
                     F25, F25_H, F25_J, F25_K, F25_L, F25_M, F25_N, F25_O,
                     F26, F26_H, F26_J, F26_K, F26_L, F26_M, F26_N, F26_O,
                     F27, F27_H, F27_J, F27_K, F27_L, F27_M, F27_N, F27_O,
                     F28, F28_H, F28_J, F28_K, F28_L, F28_M, F28_N, F28_O,
                     F29, F29_H, F29_J, F29_K, F29_L, F29_M, F29_N, F29_O,
                     F30, F30_H, F30_J, F30_K, F30_L, F30_M, F30_N, F30_O,
                     F31, F31_H, F31_J, F31_K, F31_L, F31_M, F31_N, F31_O);

reg_class s_reg( S0, S1, S2, S3, S4, S5, S6, S7 );
reg_class s0_reg( S0 );
reg_class s1_reg( S1 );
reg_class s2_reg( S2 );
reg_class s3_reg( S3 );
reg_class s4_reg( S4 );
reg_class s5_reg( S5 );
reg_class s6_reg( S6 );
reg_class s7_reg( S7 );

reg_class t_reg( T0, T1, T2, T3, T8, T4 );
reg_class t0_reg( T0 );
reg_class t1_reg( T1 );
reg_class t2_reg( T2 );
reg_class t3_reg( T3 );
reg_class t8_reg( T8 );
reg_class t4_reg( T4 );

reg_class a_reg( A0, A1, A2, A3, A4, A5, A6, A7 );
reg_class a0_reg( A0 );
reg_class a1_reg( A1 );
reg_class a2_reg( A2 );
reg_class a3_reg( A3 );
reg_class a4_reg( A4 );
reg_class a5_reg( A5 );
reg_class a6_reg( A6 );
reg_class a7_reg( A7 );

// TODO: LA
//reg_class v0_reg( A0 );
//reg_class v1_reg( A1 );

reg_class sp_reg( SP, SP_H );
reg_class fp_reg( FP, FP_H );

reg_class v0_long_reg( A0, A0_H );
reg_class v1_long_reg( A1, A1_H );
reg_class a0_long_reg( A0, A0_H );
reg_class a1_long_reg( A1, A1_H );
reg_class a2_long_reg( A2, A2_H );
reg_class a3_long_reg( A3, A3_H );
reg_class a4_long_reg( A4, A4_H );
reg_class a5_long_reg( A5, A5_H );
reg_class a6_long_reg( A6, A6_H );
reg_class a7_long_reg( A7, A7_H );
reg_class t0_long_reg( T0, T0_H );
reg_class t1_long_reg( T1, T1_H );
reg_class t2_long_reg( T2, T2_H );
reg_class t3_long_reg( T3, T3_H );
reg_class t8_long_reg( T8, T8_H );
reg_class t4_long_reg( T4, T4_H );
reg_class s0_long_reg( S0, S0_H );
reg_class s1_long_reg( S1, S1_H );
reg_class s2_long_reg( S2, S2_H );
reg_class s3_long_reg( S3, S3_H );
reg_class s4_long_reg( S4, S4_H );
reg_class s5_long_reg( S5, S5_H );
reg_class s6_long_reg( S6, S6_H );
reg_class s7_long_reg( S7, S7_H );

reg_class int_reg( S7, S0, S1, S2, S4, S3, T8, T2, T3, T1, T6, A7, A6, A5, A4, T5, A3, A2, A1, A0, T0 );

reg_class no_Ax_int_reg( S7, S0, S1, S2, S4, S3, T8, T2, T3, T1, T6, T5, T0 );

reg_class p_reg(
                 S7, S7_H,
                 S0, S0_H,
                 S1, S1_H,
                 S2, S2_H,
                 S4, S4_H,
                 S3, S3_H,
                 T8, T8_H,
                 T2, T2_H,
                 T3, T3_H,
                 T1, T1_H,
                 A7, A7_H,
                 A6, A6_H,
                 A5, A5_H,
                 A4, A4_H,
                 A3, A3_H,
                 A2, A2_H,
                 A1, A1_H,
                 A0, A0_H,
                 T0, T0_H
               );

reg_class no_T8_p_reg(
                 S7, S7_H,
                 S0, S0_H,
                 S1, S1_H,
                 S2, S2_H,
                 S4, S4_H,
                 S3, S3_H,
                 T2, T2_H,
                 T3, T3_H,
                 T1, T1_H,
                 A7, A7_H,
                 A6, A6_H,
                 A5, A5_H,
                 A4, A4_H,
                 A3, A3_H,
                 A2, A2_H,
                 A1, A1_H,
                 A0, A0_H,
                 T0, T0_H
               );

reg_class no_Ax_p_reg(
                 S7, S7_H,
                 S0, S0_H,
                 S1, S1_H,
                 S2, S2_H,
                 S4, S4_H,
                 S3, S3_H,
                 T2, T2_H,
                 T3, T3_H,
                 T1, T1_H,
                 T0, T0_H
               );

reg_class long_reg(
                    S7, S7_H,
                    S0, S0_H,
                    S1, S1_H,
                    S2, S2_H,
                    S4, S4_H,
                    S3, S3_H,
                    T8, T8_H,
                    T2, T2_H,
                    T3, T3_H,
                    T1, T1_H,
                    A7, A7_H,
                    A6, A6_H,
                    A5, A5_H,
                    A4, A4_H,
                    A3, A3_H,
                    A2, A2_H,
                    A1, A1_H,
                    A0, A0_H,
                    T0, T0_H
                  );


// Floating point registers.
// F31 are not used as temporary registers in D2I
reg_class flt_reg( F0, F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, F11, F12, F13, F14, F15, F16, F17, F18, F19, F20, F21, F22, F24, F25, F26, F27, F28, F29, F30, F31);
reg_class dbl_reg( F0, F0_H,
                   F1, F1_H,
                   F2, F2_H,
                   F3, F3_H,
                   F4, F4_H,
                   F5, F5_H,
                   F6, F6_H,
                   F7, F7_H,
                   F8, F8_H,
                   F9, F9_H,
                   F10, F10_H,
                   F11, F11_H,
                   F12, F12_H,
                   F13, F13_H,
                   F14, F14_H,
                   F15, F15_H,
                   F16, F16_H,
                   F17, F17_H,
                   F18, F18_H,
                   F19, F19_H,
                   F20, F20_H,
                   F21, F21_H,
                   F22, F22_H,
                   F24, F24_H,
                   F25, F25_H,
                   F26, F26_H,
                   F27, F27_H,
                   F28, F28_H,
                   F29, F29_H,
                   F30, F30_H,
                   F31, F31_H);

// Class for all 128bit vector registers
reg_class vectorx_reg(  F0, F0_H, F0_J, F0_K,
                        F1, F1_H, F1_J, F1_K,
                        F2, F2_H, F2_J, F2_K,
                        F3, F3_H, F3_J, F3_K,
                        F4, F4_H, F4_J, F4_K,
                        F5, F5_H, F5_J, F5_K,
                        F6, F6_H, F6_J, F6_K,
                        F7, F7_H, F7_J, F7_K,
                        F8, F8_H, F8_J, F8_K,
                        F9, F9_H, F9_J, F9_K,
                        F10, F10_H, F10_J, F10_K,
                        F11, F11_H, F11_J, F11_K,
                        F12, F12_H, F12_J, F12_K,
                        F13, F13_H, F13_J, F13_K,
                        F14, F14_H, F14_J, F14_K,
                        F15, F15_H, F15_J, F15_K,
                        F16, F16_H, F16_J, F16_K,
                        F17, F17_H, F17_J, F17_K,
                        F18, F18_H, F18_J, F18_K,
                        F19, F19_H, F19_J, F19_K,
                        F20, F20_H, F20_J, F20_K,
                        F21, F21_H, F21_J, F21_K,
                        F22, F22_H, F22_J, F22_K,
                        F24, F24_H, F24_J, F24_K,
                        F25, F25_H, F25_J, F25_K,
                        F26, F26_H, F26_J, F26_K,
                        F27, F27_H, F27_J, F27_K,
                        F28, F28_H, F28_J, F28_K,
                        F29, F29_H, F29_J, F29_K,
                        F30, F30_H, F30_J, F30_K,
                        F31, F31_H, F31_J, F31_K);

// Class for all 256bit vector registers
reg_class vectory_reg(  F0, F0_H, F0_J, F0_K, F0_L, F0_M, F0_N, F0_O,
                        F1, F1_H, F1_J, F1_K, F1_L, F1_M, F1_N, F1_O,
                        F2, F2_H, F2_J, F2_K, F2_L, F2_M, F2_N, F2_O,
                        F3, F3_H, F3_J, F3_K, F3_L, F3_M, F3_N, F3_O,
                        F4, F4_H, F4_J, F4_K, F4_L, F4_M, F4_N, F4_O,
                        F5, F5_H, F5_J, F5_K, F5_L, F5_M, F5_N, F5_O,
                        F6, F6_H, F6_J, F6_K, F6_L, F6_M, F6_N, F6_O,
                        F7, F7_H, F7_J, F7_K, F7_L, F7_M, F7_N, F7_O,
                        F8, F8_H, F8_J, F8_K, F8_L, F8_M, F8_N, F8_O,
                        F9, F9_H, F9_J, F9_K, F9_L, F9_M, F9_N, F9_O,
                        F10, F10_H, F10_J, F10_K, F10_L, F10_M, F10_N, F10_O,
                        F11, F11_H, F11_J, F11_K, F11_L, F11_M, F11_N, F11_O,
                        F12, F12_H, F12_J, F12_K, F12_L, F12_M, F12_N, F12_O,
                        F13, F13_H, F13_J, F13_K, F13_L, F13_M, F13_N, F13_O,
                        F14, F14_H, F14_J, F14_K, F14_L, F14_M, F14_N, F14_O,
                        F15, F15_H, F15_J, F15_K, F15_L, F15_M, F15_N, F15_O,
                        F16, F16_H, F16_J, F16_K, F16_L, F16_M, F16_N, F16_O,
                        F17, F17_H, F17_J, F17_K, F17_L, F17_M, F17_N, F17_O,
                        F18, F18_H, F18_J, F18_K, F18_L, F18_M, F18_N, F18_O,
                        F19, F19_H, F19_J, F19_K, F19_L, F19_M, F19_N, F19_O,
                        F20, F20_H, F20_J, F20_K, F20_L, F20_M, F20_N, F20_O,
                        F21, F21_H, F21_J, F21_K, F21_L, F21_M, F21_N, F21_O,
                        F22, F22_H, F22_J, F22_K, F22_L, F22_M, F22_N, F22_O,
                        F24, F24_H, F24_J, F24_K, F24_L, F24_M, F24_N, F24_O,
                        F25, F25_H, F25_J, F25_K, F25_L, F25_M, F25_N, F25_O,
                        F26, F26_H, F26_J, F26_K, F26_L, F26_M, F26_N, F26_O,
                        F27, F27_H, F27_J, F27_K, F27_L, F27_M, F27_N, F27_O,
                        F28, F28_H, F28_J, F28_K, F28_L, F28_M, F28_N, F28_O,
                        F29, F29_H, F29_J, F29_K, F29_L, F29_M, F29_N, F29_O,
                        F30, F30_H, F30_J, F30_K, F30_L, F30_M, F30_N, F30_O,
                        F31, F31_H, F31_J, F31_K, F31_L, F31_M, F31_N, F31_O);

// TODO: LA
//reg_class flt_arg0( F0 );
//reg_class dbl_arg0( F0, F0_H );
//reg_class dbl_arg1( F1, F1_H );

%}

//----------DEFINITION BLOCK---------------------------------------------------
// Define name --> value mappings to inform the ADLC of an integer valued name
// Current support includes integer values in the range [0, 0x7FFFFFFF]
// Format:
//        int_def  <name>         ( <int_value>, <expression>);
// Generated Code in ad_<arch>.hpp
//        #define  <name>   (<expression>)
//        // value == <int_value>
// Generated code in ad_<arch>.cpp adlc_verification()
//        assert( <name> == <int_value>, "Expect (<expression>) to equal <int_value>");
//
definitions %{
  int_def DEFAULT_COST      (    100,     100);
  int_def HUGE_COST         (1000000, 1000000);

  // Memory refs are twice as expensive as run-of-the-mill.
  int_def MEMORY_REF_COST   (    200, DEFAULT_COST * 2);

  // Branches are even more expensive.
  int_def BRANCH_COST       (    300, DEFAULT_COST * 3);
  // we use jr instruction to construct call, so more expensive
  int_def CALL_COST         (    500, DEFAULT_COST * 5);
/*
        int_def EQUAL             (   1, 1  );
        int_def NOT_EQUAL         (   2, 2  );
        int_def GREATER           (   3, 3  );
        int_def GREATER_EQUAL     (   4, 4  );
        int_def LESS              (   5, 5  );
        int_def LESS_EQUAL        (   6, 6  );
*/
%}



//----------SOURCE BLOCK-------------------------------------------------------
// This is a block of C++ code which provides values, functions, and
// definitions necessary in the rest of the architecture description

source_hpp %{
// Header information of the source block.
// Method declarations/definitions which are used outside
// the ad-scope can conveniently be defined here.
//
// To keep related declarations/definitions/uses close together,
// we switch between source %{ }% and source_hpp %{ }% freely as needed.

class CallStubImpl {

  //--------------------------------------------------------------
  //---<  Used for optimization in Compile::shorten_branches  >---
  //--------------------------------------------------------------

 public:
  // Size of call trampoline stub.
  static uint size_call_trampoline() {
    return 0; // no call trampolines on this platform
  }

  // number of relocations needed by a call trampoline stub
  static uint reloc_call_trampoline() {
    return 0; // no call trampolines on this platform
  }
};

class HandlerImpl {

 public:

  static int emit_exception_handler(CodeBuffer &cbuf);
  static int emit_deopt_handler(CodeBuffer& cbuf);

  static uint size_exception_handler() {
    // NativeCall instruction size is the same as NativeJump.
    // exception handler starts out as jump and can be patched to
    // a call be deoptimization.  (4932387)
    // Note that this value is also credited (in output.cpp) to
    // the size of the code section.
    int size = NativeFarCall::instruction_size;
    return round_to(size, 16);
  }

  static uint size_deopt_handler() {
    int size = NativeFarCall::instruction_size;
    return round_to(size, 16);
  }
};

%} // end source_hpp

source %{

#define   NO_INDEX    0
#define   RELOC_IMM64    Assembler::imm_operand
#define   RELOC_DISP32   Assembler::disp32_operand

#define V0_num    A0_num
#define V0_H_num  A0_H_num

#define __ _masm.

#define A0 RA0
#define A1 RA1
#define A2 RA2
#define A3 RA3
#define A4 RA4
#define A5 RA5
#define A6 RA6
#define A7 RA7
#define T0 RT0
#define T1 RT1
#define T2 RT2
#define T3 RT3
#define T4 RT4
#define T5 RT5
#define T6 RT6
#define T7 RT7
#define T8 RT8

// Emit exception handler code.
// Stuff framesize into a register and call a VM stub routine.
int HandlerImpl::emit_exception_handler(CodeBuffer& cbuf) {
  // Note that the code buffer's insts_mark is always relative to insts.
  // That's why we must use the macroassembler to generate a handler.
  MacroAssembler _masm(&cbuf);
  address base = __ start_a_stub(size_exception_handler());
  if (base == NULL) {
    ciEnv::current()->record_failure("CodeCache is full");
    return 0;  // CodeBuffer::expand failed
  }

  int offset = __ offset();

  __ block_comment("; emit_exception_handler");

  cbuf.set_insts_mark();
  __ relocate(relocInfo::runtime_call_type);
  __ patchable_jump((address)OptoRuntime::exception_blob()->entry_point());
  assert(__ offset() - offset <= (int) size_exception_handler(), "overflow");
  __ end_a_stub();
  return offset;
}

// Emit deopt handler code.
int HandlerImpl::emit_deopt_handler(CodeBuffer& cbuf) {
  // Note that the code buffer's insts_mark is always relative to insts.
  // That's why we must use the macroassembler to generate a handler.
  MacroAssembler _masm(&cbuf);
  address base = __ start_a_stub(size_deopt_handler());
  if (base == NULL) {
    ciEnv::current()->record_failure("CodeCache is full");
    return 0;  // CodeBuffer::expand failed
  }

  int offset = __ offset();

  __ block_comment("; emit_deopt_handler");

  cbuf.set_insts_mark();
  __ relocate(relocInfo::runtime_call_type);
  __ patchable_call(SharedRuntime::deopt_blob()->unpack());
  assert(__ offset() - offset <= (int) size_deopt_handler(), "overflow");
  __ end_a_stub();
  return offset;
}


const bool Matcher::match_rule_supported(int opcode) {
  if (!has_match_rule(opcode))
    return false;

  return true;  // Per default match rules are supported.
}

bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
  const int safety_zone = 3 * BytesPerInstWord;
  int offs = offset - br_size + 4;
  // To be conservative on LoongArch
  // branch node should be end with:
  //   branch inst
  offs = (offs < 0 ? offs - safety_zone : offs + safety_zone) >> 2;
  switch (rule) {
    case jmpDir_long_rule:
    case jmpDir_short_rule:
      return Assembler::is_simm(offs, 26);
    case jmpCon_flags_long_rule:
    case jmpCon_flags_short_rule:
    case branchConP_0_long_rule:
    case branchConP_0_short_rule:
    case branchConN2P_0_long_rule:
    case branchConN2P_0_short_rule:
    case cmpN_null_branch_long_rule:
    case cmpN_null_branch_short_rule:
    case branchConIU_reg_immI_0_long_rule:
    case branchConIU_reg_immI_0_short_rule:
    case branchConF_reg_reg_long_rule:
    case branchConF_reg_reg_short_rule:
    case branchConD_reg_reg_long_rule:
    case branchConD_reg_reg_short_rule:
      return Assembler::is_simm(offs, 21);
    default:
      return Assembler::is_simm(offs, 16);
  }
  return false;
}


// No additional cost for CMOVL.
const int Matcher::long_cmove_cost() { return 0; }

// No CMOVF/CMOVD with SSE2
const int Matcher::float_cmove_cost() { return ConditionalMoveLimit; }

// Does the CPU require late expand (see block.cpp for description of late expand)?
const bool Matcher::require_postalloc_expand = false;

// Should the Matcher clone shifts on addressing modes, expecting them
// to be subsumed into complex addressing expressions or compute them
// into registers?  True for Intel but false for most RISCs
const bool Matcher::clone_shift_expressions = false;

// Do we need to mask the count passed to shift instructions or does
// the cpu only look at the lower 5/6 bits anyway?
const bool Matcher::need_masked_shift_count = false;

bool Matcher::narrow_oop_use_complex_address() {
  assert(UseCompressedOops, "only for compressed oops code");
  return false;
}

bool Matcher::narrow_klass_use_complex_address() {
  assert(UseCompressedClassPointers, "only for compressed klass code");
  return false;
}

// This is UltraSparc specific, true just means we have fast l2f conversion
const bool Matcher::convL2FSupported(void) {
  return true;
}

// Vector ideal reg
const uint Matcher::vector_ideal_reg(int size) {
  assert(MaxVectorSize == 16 || MaxVectorSize == 32, "");
  switch(size) {
    case 16: return Op_VecX;
    case 32: return Op_VecY;
  }
  ShouldNotReachHere();
  return 0;
}

// Only lowest bits of xmm reg are used for vector shift count.
const uint Matcher::vector_shift_count_ideal_reg(int size) {
  assert(MaxVectorSize == 16 || MaxVectorSize == 32, "");
  switch(size) {
    case 16: return Op_VecX;
    case 32: return Op_VecY;
  }
  ShouldNotReachHere();
  return 0;
}

// Max vector size in bytes. 0 if not supported.
const int Matcher::vector_width_in_bytes(BasicType bt) {
  return (int)MaxVectorSize;
}

// Limits on vector size (number of elements) loaded into vector.
const int Matcher::max_vector_size(const BasicType bt) {
  assert(is_java_primitive(bt), "only primitive type vectors");
  return vector_width_in_bytes(bt)/type2aelembytes(bt);
}

const int Matcher::min_vector_size(const BasicType bt) {
  int max_size = max_vector_size(bt);
  int size     = 0;

  if (UseLSX) size = 16;
  size = size / type2aelembytes(bt);
  return MIN2(size,max_size);
}

// LoongArch supports misaligned vectors store/load?
const bool Matcher::misaligned_vectors_ok() {
  return false;
  //return !AlignVector; // can be changed by flag
}

// Register for DIVI projection of divmodI
RegMask Matcher::divI_proj_mask() {
  ShouldNotReachHere();
  return RegMask();
}

// Register for MODI projection of divmodI
RegMask Matcher::modI_proj_mask() {
  ShouldNotReachHere();
  return RegMask();
}

// Register for DIVL projection of divmodL
RegMask Matcher::divL_proj_mask() {
  ShouldNotReachHere();
  return RegMask();
}

int Matcher::regnum_to_fpu_offset(int regnum) {
  return regnum - 32; // The FP registers are in the second chunk
}


const bool Matcher::isSimpleConstant64(jlong value) {
  // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
  return true;
}


// Return whether or not this register is ever used as an argument.  This
// function is used on startup to build the trampoline stubs in generateOptoStub.
// Registers not mentioned will be killed by the VM call in the trampoline, and
// arguments in those registers not be available to the callee.
bool Matcher::can_be_java_arg( int reg ) {
  // Refer to: [sharedRuntime_loongarch_64.cpp] SharedRuntime::java_calling_convention()
  if (    reg == T0_num || reg == T0_H_num
       || reg == A0_num || reg == A0_H_num
       || reg == A1_num || reg == A1_H_num
       || reg == A2_num || reg == A2_H_num
       || reg == A3_num || reg == A3_H_num
       || reg == A4_num || reg == A4_H_num
       || reg == A5_num || reg == A5_H_num
       || reg == A6_num || reg == A6_H_num
       || reg == A7_num || reg == A7_H_num )
    return true;

  if (    reg == F0_num || reg == F0_H_num
       || reg == F1_num || reg == F1_H_num
       || reg == F2_num || reg == F2_H_num
       || reg == F3_num || reg == F3_H_num
       || reg == F4_num || reg == F4_H_num
       || reg == F5_num || reg == F5_H_num
       || reg == F6_num || reg == F6_H_num
       || reg == F7_num || reg == F7_H_num )
    return true;

  return false;
}

bool Matcher::is_spillable_arg( int reg ) {
  return can_be_java_arg(reg);
}

bool Matcher::use_asm_for_ldiv_by_con( jlong divisor ) {
  return false;
}

// Register for MODL projection of divmodL
RegMask Matcher::modL_proj_mask() {
  ShouldNotReachHere();
  return RegMask();
}

const RegMask Matcher::method_handle_invoke_SP_save_mask() {
  return FP_REG_mask();
}

// LoongArch doesn't support AES intrinsics
const bool Matcher::pass_original_key_for_aes() {
  return false;
}

int CallStaticJavaDirectNode::compute_padding(int current_offset) const {
  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallDynamicJavaDirectNode::compute_padding(int current_offset) const {
  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallLeafNoFPDirectNode::compute_padding(int current_offset) const {
  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallLeafDirectNode::compute_padding(int current_offset) const {
  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallRuntimeDirectNode::compute_padding(int current_offset) const {
  return round_to(current_offset, alignment_required()) - current_offset;
}

// If CPU can load and store mis-aligned doubles directly then no fixup is
// needed.  Else we split the double into 2 integer pieces and move it
// piece-by-piece.  Only happens when passing doubles into C code as the
// Java calling convention forces doubles to be aligned.
const bool Matcher::misaligned_doubles_ok = false;
// Do floats take an entire double register or just half?
//const bool Matcher::float_in_double = true;
bool Matcher::float_in_double() { return false; }
// Threshold size for cleararray.
const int Matcher::init_array_short_size = 8 * BytesPerLong;
// Do ints take an entire long register or just half?
const bool Matcher::int_in_long = true;
// Is it better to copy float constants, or load them directly from memory?
// Intel can load a float constant from a direct address, requiring no
// extra registers.  Most RISCs will have to materialize an address into a
// register first, so they would do better to copy the constant from stack.
const bool Matcher::rematerialize_float_constants = false;
// Advertise here if the CPU requires explicit rounding operations
// to implement the UseStrictFP mode.
const bool Matcher::strict_fp_requires_explicit_rounding = false;
// false => size gets scaled to BytesPerLong, ok.
const bool Matcher::init_array_count_is_in_bytes = false;

// Indicate if the safepoint node needs the polling page as an input.
// Since LA doesn't have absolute addressing, it needs.
bool SafePointNode::needs_polling_address_input() {
  return false;
}

// !!!!! Special hack to get all type of calls to specify the byte offset
//       from the start of the call to the point where the return address
//       will point.
int MachCallStaticJavaNode::ret_addr_offset() {
  // bl
  return NativeCall::instruction_size;
}

int MachCallDynamicJavaNode::ret_addr_offset() {
  // lu12i_w IC_Klass,
  // ori IC_Klass,
  // lu32i_d IC_Klass
  // lu52i_d IC_Klass

  // bl
  return NativeMovConstReg::instruction_size + NativeCall::instruction_size;
}

//=============================================================================

// Figure out which register class each belongs in: rc_int, rc_float, rc_stack
enum RC { rc_bad, rc_int, rc_float, rc_stack };
static enum RC rc_class( OptoReg::Name reg ) {
  if( !OptoReg::is_valid(reg)  ) return rc_bad;
  if (OptoReg::is_stack(reg)) return rc_stack;
  VMReg r = OptoReg::as_VMReg(reg);
  if (r->is_Register()) return rc_int;
  assert(r->is_FloatRegister(), "must be");
  return rc_float;
}

// Helper methods for MachSpillCopyNode::implementation().
static int vec_mov_helper(CodeBuffer *cbuf, bool do_size, int src_lo, int dst_lo,
                          int src_hi, int dst_hi, uint ireg, outputStream* st) {
  int size = 0;
  if (cbuf) {
    MacroAssembler _masm(cbuf);
    int offset = __ offset();
    switch (ireg) {
      case Op_VecX:
        __ vori_b(as_FloatRegister(Matcher::_regEncode[dst_lo]), as_FloatRegister(Matcher::_regEncode[src_lo]), 0);
        break;
      case Op_VecY:
        __ xvori_b(as_FloatRegister(Matcher::_regEncode[dst_lo]), as_FloatRegister(Matcher::_regEncode[src_lo]), 0);
        break;
      default:
        ShouldNotReachHere();
    }
#ifndef PRODUCT
  } else if (!do_size) {
    switch (ireg) {
      case Op_VecX:
        st->print("vori.b    %s, %s, 0\t# spill", Matcher::regName[dst_lo], Matcher::regName[src_lo]);
        break;
      case Op_VecY:
        st->print("xvori.b    %s, %s, 0\t# spill", Matcher::regName[dst_lo], Matcher::regName[src_lo]);
        break;
      default:
        ShouldNotReachHere();
    }
#endif
  }
  size += 4;
  return size;
}

static int vec_spill_helper(CodeBuffer *cbuf, bool do_size, bool is_load,
                            int stack_offset, int reg, uint ireg, outputStream* st) {
  int size = 0;
  if (cbuf) {
    MacroAssembler _masm(cbuf);
    int offset = __ offset();
    if (is_load) {
      switch (ireg) {
        case Op_VecX:
          __ vld(as_FloatRegister(Matcher::_regEncode[reg]), SP, stack_offset);
          break;
        case Op_VecY:
          __ xvld(as_FloatRegister(Matcher::_regEncode[reg]), SP, stack_offset);
          break;
        default:
          ShouldNotReachHere();
      }
    } else { // store
      switch (ireg) {
        case Op_VecX:
          __ vst(as_FloatRegister(Matcher::_regEncode[reg]), SP, stack_offset);
          break;
        case Op_VecY:
          __ xvst(as_FloatRegister(Matcher::_regEncode[reg]), SP, stack_offset);
          break;
        default:
          ShouldNotReachHere();
      }
    }
#ifndef PRODUCT
  } else if (!do_size) {
    if (is_load) {
      switch (ireg) {
        case Op_VecX:
          st->print("vld    %s, [SP + %d]\t# spill", Matcher::regName[reg], stack_offset);
          break;
        case Op_VecY:
          st->print("xvld    %s, [SP + %d]\t# spill", Matcher::regName[reg], stack_offset);
          break;
        default:
          ShouldNotReachHere();
      }
    } else { // store
      switch (ireg) {
        case Op_VecX:
          st->print("vst    %s, [SP + %d]\t# spill", Matcher::regName[reg], stack_offset);
          break;
        case Op_VecY:
          st->print("xvst    %s, [SP + %d]\t# spill", Matcher::regName[reg], stack_offset);
          break;
        default:
          ShouldNotReachHere();
      }
    }
#endif
  }
  size += 4;
  return size;
}

static int vec_stack_to_stack_helper(CodeBuffer *cbuf, int src_offset,
                                      int dst_offset, uint ireg, outputStream* st) {
  int size = 0;
  if (cbuf) {
    MacroAssembler _masm(cbuf);
    switch (ireg) {
      case Op_VecX:
        __ vld(F23, SP, src_offset);
        __ vst(F23, SP, dst_offset);
        break;
      case Op_VecY:
        __ xvld(F23, SP, src_offset);
        __ xvst(F23, SP, dst_offset);
        break;
      default:
        ShouldNotReachHere();
    }
#ifndef PRODUCT
  } else {
    switch (ireg) {
      case Op_VecX:
        st->print("vld f23, %d(sp)\n\t"
                  "vst f23, %d(sp)\t# 128-bit mem-mem spill",
                  src_offset, dst_offset);
        break;
      case Op_VecY:
        st->print("xvld f23, %d(sp)\n\t"
                  "xvst f23, %d(sp)\t# 256-bit mem-mem spill",
                  src_offset, dst_offset);
        break;
      default:
        ShouldNotReachHere();
    }
#endif
  }
  size += 8;
  return size;
}

uint MachSpillCopyNode::implementation( CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream* st ) const {
  // Get registers to move
  OptoReg::Name src_second = ra_->get_reg_second(in(1));
  OptoReg::Name src_first = ra_->get_reg_first(in(1));
  OptoReg::Name dst_second = ra_->get_reg_second(this );
  OptoReg::Name dst_first = ra_->get_reg_first(this );

  enum RC src_second_rc = rc_class(src_second);
  enum RC src_first_rc = rc_class(src_first);
  enum RC dst_second_rc = rc_class(dst_second);
  enum RC dst_first_rc = rc_class(dst_first);

  assert(OptoReg::is_valid(src_first) && OptoReg::is_valid(dst_first), "must move at least 1 register" );

  // Generate spill code!

  if( src_first == dst_first && src_second == dst_second )
    return 0;            // Self copy, no move

  if (bottom_type()->isa_vect() != NULL) {
    uint ireg = ideal_reg();
    assert((src_first_rc != rc_int && dst_first_rc != rc_int), "sanity");
    if (src_first_rc == rc_stack && dst_first_rc == rc_stack) {
      // mem -> mem
      int src_offset = ra_->reg2offset(src_first);
      int dst_offset = ra_->reg2offset(dst_first);
      vec_stack_to_stack_helper(cbuf, src_offset, dst_offset, ireg, st);
    } else if (src_first_rc == rc_float && dst_first_rc == rc_float) {
      vec_mov_helper(cbuf, do_size, src_first, dst_first, src_second, dst_second, ireg, st);
    } else if (src_first_rc == rc_float && dst_first_rc == rc_stack) {
      int stack_offset = ra_->reg2offset(dst_first);
      vec_spill_helper(cbuf, do_size, false, stack_offset, src_first, ireg, st);
    } else if (src_first_rc == rc_stack && dst_first_rc == rc_float) {
      int stack_offset = ra_->reg2offset(src_first);
      vec_spill_helper(cbuf, do_size, true,  stack_offset, dst_first, ireg, st);
    } else {
      ShouldNotReachHere();
    }
    return 0;
  }

  if (src_first_rc == rc_stack) {
    // mem ->
    if (dst_first_rc == rc_stack) {
      // mem -> mem
      assert(src_second != dst_first, "overlap");
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int src_offset = ra_->reg2offset(src_first);
        int dst_offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ ld_d(AT, Address(SP, src_offset));
          __ st_d(AT, Address(SP, dst_offset));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("ld_d    AT, [SP + #%d]\t# 64-bit mem-mem spill 1\n\t"
                    "st_d    AT, [SP + #%d]",
                    src_offset, dst_offset);
#endif
        }
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        // No pushl/popl, so:
        int src_offset = ra_->reg2offset(src_first);
        int dst_offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ ld_w(AT, Address(SP, src_offset));
          __ st_w(AT, Address(SP, dst_offset));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("ld_w    AT, [SP + #%d] spill 2\n\t"
                    "st_w    AT, [SP + #%d]\n\t",
                    src_offset, dst_offset);
#endif
        }
      }
      return 0;
    } else if (dst_first_rc == rc_int) {
      // mem -> gpr
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ ld_d(as_Register(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("ld_d    %s, [SP + #%d]\t# spill 3",
                    Matcher::regName[dst_first],
                    offset);
#endif
        }
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          if (this->ideal_reg() == Op_RegI)
            __ ld_w(as_Register(Matcher::_regEncode[dst_first]), Address(SP, offset));
          else {
            if (Assembler::is_simm(offset, 12)) {
              __ ld_wu(as_Register(Matcher::_regEncode[dst_first]), Address(SP, offset));
            } else {
              __ li(AT, offset);
              __ ldx_wu(as_Register(Matcher::_regEncode[dst_first]), SP, AT);
            }
          }
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          if (this->ideal_reg() == Op_RegI)
            st->print("ld_w    %s, [SP + #%d]\t# spill 4",
                      Matcher::regName[dst_first],
                      offset);
          else
            st->print("ld_wu    %s, [SP + #%d]\t# spill 5",
                      Matcher::regName[dst_first],
                      offset);
#endif
        }
      }
      return 0;
    } else if (dst_first_rc == rc_float) {
      // mem-> xmm
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ fld_d( as_FloatRegister(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("fld_d  %s, [SP + #%d]\t# spill 6",
                    Matcher::regName[dst_first],
                    offset);
#endif
        }
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ fld_s( as_FloatRegister(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("fld_s   %s, [SP + #%d]\t# spill 7",
                    Matcher::regName[dst_first],
                    offset);
#endif
        }
      }
    }
    return 0;
  } else if (src_first_rc == rc_int) {
    // gpr ->
    if (dst_first_rc == rc_stack) {
      // gpr -> mem
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ st_d(as_Register(Matcher::_regEncode[src_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("st_d    %s, [SP + #%d] # spill 8",
                    Matcher::regName[src_first],
                    offset);
#endif
        }
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ st_w(as_Register(Matcher::_regEncode[src_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("st_w    %s, [SP + #%d]\t# spill 9",
                    Matcher::regName[src_first], offset);
#endif
        }
      }
      return 0;
    } else if (dst_first_rc == rc_int) {
      // gpr -> gpr
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ move(as_Register(Matcher::_regEncode[dst_first]),
                  as_Register(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("move(64bit)    %s <-- %s\t# spill 10",
                    Matcher::regName[dst_first],
                    Matcher::regName[src_first]);
#endif
        }
        return 0;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          if (this->ideal_reg() == Op_RegI)
              __ move_u32(as_Register(Matcher::_regEncode[dst_first]), as_Register(Matcher::_regEncode[src_first]));
          else
              __ add_d(as_Register(Matcher::_regEncode[dst_first]), as_Register(Matcher::_regEncode[src_first]), R0);
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("move(32-bit)    %s <-- %s\t# spill 11",
                    Matcher::regName[dst_first],
                    Matcher::regName[src_first]);
#endif
        }
        return 0;
      }
    } else if (dst_first_rc == rc_float) {
      // gpr -> xmm
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ movgr2fr_d(as_FloatRegister(Matcher::_regEncode[dst_first]), as_Register(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("movgr2fr_d   %s, %s\t# spill 12",
                    Matcher::regName[dst_first],
                    Matcher::regName[src_first]);
#endif
        }
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ movgr2fr_w(as_FloatRegister(Matcher::_regEncode[dst_first]), as_Register(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("movgr2fr_w   %s, %s\t# spill 13",
                    Matcher::regName[dst_first],
                    Matcher::regName[src_first]);
#endif
        }
      }
      return 0;
    }
  } else if (src_first_rc == rc_float) {
    // xmm ->
    if (dst_first_rc == rc_stack) {
      // xmm -> mem
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ fst_d( as_FloatRegister(Matcher::_regEncode[src_first]), Address(SP, offset) );
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("fst_d   %s, [SP + #%d]\t# spill 14",
                    Matcher::regName[src_first],
                    offset);
#endif
        }
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ fst_s(as_FloatRegister(Matcher::_regEncode[src_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("fst_s   %s, [SP + #%d]\t# spill 15",
                    Matcher::regName[src_first],
                    offset);
#endif
        }
      }
      return 0;
    } else if (dst_first_rc == rc_int) {
      // xmm -> gpr
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ movfr2gr_d( as_Register(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("movfr2gr_d   %s, %s\t# spill 16",
                    Matcher::regName[dst_first],
                    Matcher::regName[src_first]);
#endif
        }
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ movfr2gr_s( as_Register(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("movfr2gr_s   %s, %s\t# spill 17",
                    Matcher::regName[dst_first],
                    Matcher::regName[src_first]);
#endif
        }
      }
      return 0;
    } else if (dst_first_rc == rc_float) {
      // xmm -> xmm
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ fmov_d( as_FloatRegister(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("fmov_d  %s <-- %s\t# spill 18",
                    Matcher::regName[dst_first],
                    Matcher::regName[src_first]);
#endif
        }
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ fmov_s( as_FloatRegister(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
          st->print("\n\t");
          st->print("fmov_s  %s <-- %s\t# spill 19",
                    Matcher::regName[dst_first],
                    Matcher::regName[src_first]);
#endif
        }
      }
      return 0;
    }
  }

  assert(0," foo ");
  Unimplemented();
  return 0;
}

#ifndef PRODUCT
void MachSpillCopyNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  implementation( NULL, ra_, false, st );
}
#endif

void MachSpillCopyNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  implementation( &cbuf, ra_, false, NULL );
}

uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
  return MachNode::size(ra_);
}

//=============================================================================
#

#ifndef PRODUCT
void MachBreakpointNode::format( PhaseRegAlloc *, outputStream* st ) const {
  st->print("BRK");
}
#endif

void MachBreakpointNode::emit(CodeBuffer &cbuf, PhaseRegAlloc* ra_) const {
  MacroAssembler _masm(&cbuf);
  __ brk(5);
}

uint MachBreakpointNode::size(PhaseRegAlloc* ra_) const {
  return MachNode::size(ra_);
}


//=============================================================================
#ifndef PRODUCT
void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  Compile *C = ra_->C;
  int framesize = C->frame_size_in_bytes();

  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  st->print_cr("addi_d   SP, SP, %d # Rlease stack @ MachEpilogNode", framesize);
  st->print("\t");
  st->print_cr("ld_d    RA, SP, %d # Restore RA @ MachEpilogNode", -wordSize);
  st->print("\t");
  st->print_cr("ld_d    FP, SP, %d # Restore FP @ MachEpilogNode", -wordSize*2);
  if( do_polling() && C->is_method_compilation() ) {
    st->print("\t");
    st->print_cr("Poll Safepoint # MachEpilogNode");
  }
}
#endif

void MachEpilogNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  Compile *C = ra_->C;
  MacroAssembler _masm(&cbuf);
  int framesize = C->frame_size_in_bytes();

  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  __ ld_d(RA, Address(SP, framesize - wordSize));
  __ ld_d(FP, Address(SP, framesize - wordSize * 2));
  if (Assembler::is_simm(framesize, 12)) {
    __ addi_d(SP, SP, framesize);
  } else {
    __ li(AT, framesize);
    __ add_d(SP, SP, AT);
  }

  if( do_polling() && C->is_method_compilation() ) {
    __ li(AT, (long)os::get_polling_page());
    __ relocate(relocInfo::poll_return_type);
    __ ld_w(AT, AT, 0);
  }
}

uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
  return MachNode::size(ra_); // too many variables; just compute it the hard way
}

int MachEpilogNode::reloc() const {
  return 0; // a large enough number
}

const Pipeline * MachEpilogNode::pipeline() const {
  return MachNode::pipeline_class();
}

int MachEpilogNode::safepoint_offset() const { return 0; }

//=============================================================================

#ifndef PRODUCT
void BoxLockNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());
  int reg = ra_->get_reg_first(this);
  st->print("ADDI_D %s, SP, %d   @BoxLockNode",Matcher::regName[reg],offset);
}
#endif


uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
   int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());

   if (Assembler::is_simm(offset, 12))
     return 4;
   else
     return 3 * 4;
}

void BoxLockNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  MacroAssembler _masm(&cbuf);
  int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());
  int reg = ra_->get_encode(this);

  if (Assembler::is_simm(offset, 12)) {
    __ addi_d(as_Register(reg), SP, offset);
  } else {
    __ lu12i_w(AT, Assembler::split_low20(offset >> 12));
    __ ori(AT, AT, Assembler::split_low12(offset));
    __ add_d(as_Register(reg), SP, AT);
  }
}

int MachCallRuntimeNode::ret_addr_offset() {
  // pcaddu18i
  // jirl
  return NativeFarCall::instruction_size;
}


//=============================================================================
#ifndef PRODUCT
void MachNopNode::format( PhaseRegAlloc *, outputStream* st ) const {
  st->print("NOP \t# %d bytes pad for loops and calls", 4 * _count);
}
#endif

void MachNopNode::emit(CodeBuffer &cbuf, PhaseRegAlloc * ) const {
  MacroAssembler _masm(&cbuf);
  int i = 0;
  for(i = 0; i < _count; i++)
     __ nop();
}

uint MachNopNode::size(PhaseRegAlloc *) const {
  return 4 * _count;
}
const Pipeline* MachNopNode::pipeline() const {
  return MachNode::pipeline_class();
}

//=============================================================================

//=============================================================================
#ifndef PRODUCT
void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  st->print_cr("load_klass(T4, T0)");
  st->print_cr("\tbeq(T4, iCache, L)");
  st->print_cr("\tjmp(SharedRuntime::get_ic_miss_stub(), relocInfo::runtime_call_type)");
  st->print_cr("    L:");
}
#endif


void MachUEPNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  MacroAssembler _masm(&cbuf);
  int  ic_reg = Matcher::inline_cache_reg_encode();
  Label L;
  Register receiver = T0;
  Register   iCache = as_Register(ic_reg);

  __ load_klass(T4, receiver);
  __ beq(T4, iCache, L);
  __ jmp((address)SharedRuntime::get_ic_miss_stub(), relocInfo::runtime_call_type);
  __ bind(L);
}

uint MachUEPNode::size(PhaseRegAlloc *ra_) const {
  return MachNode::size(ra_);
}



//=============================================================================

const RegMask& MachConstantBaseNode::_out_RegMask = P_REG_mask();

int Compile::ConstantTable::calculate_table_base_offset() const {
  return 0;  // absolute addressing, no offset
}

bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
void MachConstantBaseNode::postalloc_expand(GrowableArray <Node *> *nodes, PhaseRegAlloc *ra_) {
  ShouldNotReachHere();
}

void MachConstantBaseNode::emit(CodeBuffer& cbuf, PhaseRegAlloc* ra_) const {
  Compile* C = ra_->C;
  Compile::ConstantTable& constant_table = C->constant_table();
  MacroAssembler _masm(&cbuf);

  Register Rtoc = as_Register(ra_->get_encode(this));
  CodeSection* consts_section = cbuf.consts();
  int consts_size = consts_section->align_at_start(consts_section->size());
  assert(constant_table.size() == consts_size, "must be equal");

  if (consts_section->size()) {
    assert((CodeBuffer::SECT_CONSTS + 1) == CodeBuffer::SECT_INSTS,
           "insts must be immediately follow consts");
    // Materialize the constant table base.
    address baseaddr = cbuf.insts()->start() - consts_size + -(constant_table.table_base_offset());
    jint offs = (baseaddr - __ pc()) >> 2;
    guarantee(Assembler::is_simm(offs, 20), "Not signed 20-bit offset");
    __ pcaddi(Rtoc, offs);
  }
}

uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
  // pcaddi
  return 1 * BytesPerInstWord;
}

#ifndef PRODUCT
void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
  Register r = as_Register(ra_->get_encode(this));
  st->print("pcaddi    %s, &constanttable (constant table base) @ MachConstantBaseNode", r->name());
}
#endif


//=============================================================================
#ifndef PRODUCT
void MachPrologNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  Compile* C = ra_->C;

  int framesize = C->frame_size_in_bytes();
  int bangsize = C->bang_size_in_bytes();
  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  // Calls to C2R adapters often do not accept exceptional returns.
  // We require that their callers must bang for them.  But be careful, because
  // some VM calls (such as call site linkage) can use several kilobytes of
  // stack.  But the stack safety zone should account for that.
  // See bugs 4446381, 4468289, 4497237.
  if (C->need_stack_bang(bangsize)) {
    st->print_cr("# stack bang"); st->print("\t");
  }
  st->print("st_d       RA, %d(SP)  @ MachPrologNode\n\t", -wordSize);
  st->print("st_d       FP, %d(SP)  @ MachPrologNode\n\t", -wordSize*2);
  st->print("addi_d   FP, SP, -%d \n\t", wordSize*2);
  st->print("addi_d   SP, SP, -%d \t",framesize);
}
#endif


void MachPrologNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  Compile* C = ra_->C;
  MacroAssembler _masm(&cbuf);

  int framesize = C->frame_size_in_bytes();
  int bangsize = C->bang_size_in_bytes();

  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

#ifdef ASSERT
  address start = __ pc();
#endif

  if (C->need_stack_bang(bangsize)) {
    __ generate_stack_overflow_check(bangsize);
  }

  if (Assembler::is_simm(-framesize, 12)) {
    __ addi_d(SP, SP, -framesize);
  } else {
    __ li(AT, -framesize);
    __ add_d(SP, SP, AT);
  }
  __ st_d(RA, Address(SP, framesize - wordSize));
  __ st_d(FP, Address(SP, framesize - wordSize * 2));
  if (Assembler::is_simm(framesize - wordSize * 2, 12)) {
    __ addi_d(FP, SP, framesize - wordSize * 2);
  } else {
    __ li(AT, framesize - wordSize * 2);
    __ add_d(FP, SP, AT);
  }

  assert((__ pc() - start) >= 1 * BytesPerInstWord, "No enough room for patch_verified_entry");

  C->set_frame_complete(cbuf.insts_size());
  if (C->has_mach_constant_base_node()) {
    // NOTE: We set the table base offset here because users might be
    // emitted before MachConstantBaseNode.
    Compile::ConstantTable& constant_table = C->constant_table();
    constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
  }
}


uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
  return MachNode::size(ra_); // too many variables; just compute it the hard way
}

int MachPrologNode::reloc() const {
  return 0; // a large enough number
}

%}

//----------ENCODING BLOCK-----------------------------------------------------
// This block specifies the encoding classes used by the compiler to output
// byte streams.  Encoding classes generate functions which are called by
// Machine Instruction Nodes in order to generate the bit encoding of the
// instruction.  Operands specify their base encoding interface with the
// interface keyword.  There are currently supported four interfaces,
// REG_INTER, CONST_INTER, MEMORY_INTER, & COND_INTER.  REG_INTER causes an
// operand to generate a function which returns its register number when
// queried.   CONST_INTER causes an operand to generate a function which
// returns the value of the constant when queried.  MEMORY_INTER causes an
// operand to generate four functions which return the Base Register, the
// Index Register, the Scale Value, and the Offset Value of the operand when
// queried.  COND_INTER causes an operand to generate six functions which
// return the encoding code (ie - encoding bits for the instruction)
// associated with each basic boolean condition for a conditional instruction.
// Instructions specify two basic values for encoding.  They use the
// ins_encode keyword to specify their encoding class (which must be one of
// the class names specified in the encoding block), and they use the
// opcode keyword to specify, in order, their primary, secondary, and
// tertiary opcode.  Only the opcode sections which a particular instruction
// needs for encoding need to be specified.
encode %{

  enc_class Java_To_Runtime (method meth) %{    // CALL Java_To_Runtime, Java_To_Runtime_Leaf
    MacroAssembler _masm(&cbuf);
    // This is the instruction starting address for relocation info.
    __ block_comment("Java_To_Runtime");
    cbuf.set_insts_mark();
    __ relocate(relocInfo::runtime_call_type);
    __ patchable_call((address)$meth$$method);
  %}

  enc_class Java_Static_Call (method meth) %{    // JAVA STATIC CALL
    // CALL to fixup routine.  Fixup routine uses ScopeDesc info to determine
    // who we intended to call.
    MacroAssembler _masm(&cbuf);
    address addr = (address)$meth$$method;
    address call;
    __ block_comment("Java_Static_Call");

    if ( !_method ) {
      // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
      call = __ trampoline_call(AddressLiteral(addr, relocInfo::runtime_call_type), &cbuf);
    } else if(_optimized_virtual) {
      call = __ trampoline_call(AddressLiteral(addr, relocInfo::opt_virtual_call_type), &cbuf);
    } else {
      call = __ trampoline_call(AddressLiteral(addr, relocInfo::static_call_type), &cbuf);
    }

    if (call == NULL) {
      ciEnv::current()->record_failure("CodeCache is full");
      return;
    }

    if( _method ) {  // Emit stub for static call
      address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
      if (stub == NULL) {
        ciEnv::current()->record_failure("CodeCache is full");
        return;
      }
    }
  %}


  //
  // [Ref: LIR_Assembler::ic_call() ]
  //
  enc_class Java_Dynamic_Call (method meth) %{    // JAVA DYNAMIC CALL
    MacroAssembler _masm(&cbuf);
    __ block_comment("Java_Dynamic_Call");
    address call = __ ic_call((address)$meth$$method);
    if (call == NULL) {
      ciEnv::current()->record_failure("CodeCache is full");
      return;
    }
  %}


  enc_class enc_PartialSubtypeCheck(mRegP result, mRegP sub, mRegP super, mRegI tmp) %{
    Register result = $result$$Register;
    Register sub    = $sub$$Register;
    Register super  = $super$$Register;
    Register length = $tmp$$Register;
    Register tmp    = T4;
    Label miss;

    // result may be the same as sub
    //    47c   B40: #    B21 B41 <- B20  Freq: 0.155379
    //    47c     partialSubtypeCheck result=S1, sub=S1, super=S3, length=S0
    //    4bc     mov   S2, NULL #@loadConP
    //    4c0     beq   S1, S2, B21 #@branchConP  P=0.999999 C=-1.000000
    //
    MacroAssembler _masm(&cbuf);
    Label done;
    __ check_klass_subtype_slow_path(sub, super, length, tmp,
        NULL, &miss,
        /*set_cond_codes:*/ true);
    // Refer to X86_64's RDI
    __ move(result, 0);
    __ b(done);

    __ bind(miss);
    __ li(result, 1);
    __ bind(done);
  %}

%}


//---------LOONGARCH FRAME--------------------------------------------------------------
// Definition of frame structure and management information.
//
//  S T A C K   L A Y O U T    Allocators stack-slot number
//                             |   (to get allocators register number
//  G  Owned by    |        |  v    add SharedInfo::stack0)
//  r   CALLER     |        |
//  o     |        +--------+      pad to even-align allocators stack-slot
//  w     V        |  pad0  |        numbers; owned by CALLER
//  t   -----------+--------+----> Matcher::_in_arg_limit, unaligned
//  h     ^        |   in   |  5
//        |        |  args  |  4   Holes in incoming args owned by SELF
//  |     |    old |        |  3
//  |     |     SP-+--------+----> Matcher::_old_SP, even aligned
//  v     |        |  ret   |  3   return address
//     Owned by    +--------+
//      Self       |  pad2  |  2   pad to align old SP
//        |        +--------+  1
//        |        | locks  |  0
//        |        +--------+----> SharedInfo::stack0, even aligned
//        |        |  pad1  | 11   pad to align new SP
//        |        +--------+
//        |        |        | 10
//        |        | spills |  9   spills
//        V        |        |  8   (pad0 slot for callee)
//      -----------+--------+----> Matcher::_out_arg_limit, unaligned
//        ^        |  out   |  7
//        |        |  args  |  6   Holes in outgoing args owned by CALLEE
//   Owned by  new |        |
//    Callee    SP-+--------+----> Matcher::_new_SP, even aligned
//                  |        |
//
// Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
//         known from SELF's arguments and the Java calling convention.
//         Region 6-7 is determined per call site.
// Note 2: If the calling convention leaves holes in the incoming argument
//         area, those holes are owned by SELF.  Holes in the outgoing area
//         are owned by the CALLEE.  Holes should not be nessecary in the
//         incoming area, as the Java calling convention is completely under
//         the control of the AD file.  Doubles can be sorted and packed to
//         avoid holes.  Holes in the outgoing arguments may be nessecary for
//         varargs C calling conventions.
// Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
//         even aligned with pad0 as needed.
//         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
//         region 6-11 is even aligned; it may be padded out more so that
//         the region from SP to FP meets the minimum stack alignment.
// Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
//         alignment.  Region 11, pad1, may be dynamically extended so that
//         SP meets the minimum alignment.


frame %{

  stack_direction(TOWARDS_LOW);

  // These two registers define part of the calling convention
  // between compiled code and the interpreter.
  // SEE StartI2CNode::calling_convention & StartC2INode::calling_convention & StartOSRNode::calling_convention
  // for more information.

  inline_cache_reg(T1);                // Inline Cache Register
  interpreter_method_oop_reg(S3);      // Method Oop Register when calling interpreter

  // Optional: name the operand used by cisc-spilling to access [stack_pointer + offset]
  cisc_spilling_operand_name(indOffset32);

  // Number of stack slots consumed by locking an object
  // generate Compile::sync_stack_slots
  sync_stack_slots(2);

  frame_pointer(SP);

  // Interpreter stores its frame pointer in a register which is
  // stored to the stack by I2CAdaptors.
  // I2CAdaptors convert from interpreted java to compiled java.

  interpreter_frame_pointer(FP);

  // generate Matcher::stack_alignment
  stack_alignment(StackAlignmentInBytes);  //wordSize = sizeof(char*);

  // Number of stack slots between incoming argument block and the start of
  // a new frame.  The PROLOG must add this many slots to the stack.  The
  // EPILOG must remove this many slots.
  in_preserve_stack_slots(4);  //Now VerifyStackAtCalls is defined as false ! Leave two stack slots for ra and fp

  // Number of outgoing stack slots killed above the out_preserve_stack_slots
  // for calls to C.  Supports the var-args backing area for register parms.
  varargs_C_out_slots_killed(0);

  // The after-PROLOG location of the return address.  Location of
  // return address specifies a type (REG or STACK) and a number
  // representing the register number (i.e. - use a register name) or
  // stack slot.
  // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
  // Otherwise, it is above the locks and verification slot and alignment word
  //return_addr(STACK -1+ round_to(1+VerifyStackAtCalls+Compile::current()->sync()*Compile::current()->sync_stack_slots(),WordsPerLong));
  return_addr(REG RA);

  // Body of function which returns an integer array locating
  // arguments either in registers or in stack slots.  Passed an array
  // of ideal registers called "sig" and a "length" count.  Stack-slot
  // offsets are based on outgoing arguments, i.e. a CALLER setting up
  // arguments for a CALLEE.  Incoming stack arguments are
  // automatically biased by the preserve_stack_slots field above.


  // will generated to Matcher::calling_convention(OptoRegPair *sig, uint length, bool is_outgoing)
  // StartNode::calling_convention call this.
  calling_convention %{
    SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
  %}




  // Body of function which returns an integer array locating
  // arguments either in registers or in stack slots.  Passed an array
  // of ideal registers called "sig" and a "length" count.  Stack-slot
  // offsets are based on outgoing arguments, i.e. a CALLER setting up
  // arguments for a CALLEE.  Incoming stack arguments are
  // automatically biased by the preserve_stack_slots field above.


  // SEE CallRuntimeNode::calling_convention for more information.
  c_calling_convention %{
   (void) SharedRuntime::c_calling_convention(sig_bt, regs, /*regs2=*/NULL, length);
  %}


  // Location of C & interpreter return values
  // register(s) contain(s) return value for Op_StartI2C and Op_StartOSR.
  // SEE Matcher::match.
  c_return_value %{
    assert( ideal_reg >= Op_RegI && ideal_reg <= Op_RegL, "only return normal values" );
                               /* -- , -- , Op_RegN, Op_RegI, Op_RegP, Op_RegF, Op_RegD, Op_RegL */
    static int lo[Op_RegL+1] = { 0, 0, V0_num,       V0_num,       V0_num,       F0_num,       F0_num,    V0_num };
    static int hi[Op_RegL+1] = { 0, 0, OptoReg::Bad, OptoReg::Bad, V0_H_num,     OptoReg::Bad, F0_H_num,  V0_H_num };
    return OptoRegPair(hi[ideal_reg],lo[ideal_reg]);
  %}

  // Location of return values
  // register(s) contain(s) return value for Op_StartC2I and Op_Start.
  // SEE Matcher::match.

  return_value %{
    assert( ideal_reg >= Op_RegI && ideal_reg <= Op_RegL, "only return normal values" );
                               /* -- , -- , Op_RegN, Op_RegI, Op_RegP, Op_RegF, Op_RegD, Op_RegL */
    static int lo[Op_RegL+1] = { 0, 0, V0_num,       V0_num,       V0_num,       F0_num,       F0_num,     V0_num };
    static int hi[Op_RegL+1] = { 0, 0, OptoReg::Bad, OptoReg::Bad, V0_H_num,     OptoReg::Bad, F0_H_num,   V0_H_num};
    return OptoRegPair(hi[ideal_reg],lo[ideal_reg]);
  %}

%}

//----------ATTRIBUTES---------------------------------------------------------
//----------Operand Attributes-------------------------------------------------
op_attrib op_cost(0);        // Required cost attribute

//----------Instruction Attributes---------------------------------------------
ins_attrib ins_cost(100);       // Required cost attribute
ins_attrib ins_size(32);         // Required size attribute (in bits)
ins_attrib ins_pc_relative(0);  // Required PC Relative flag
ins_attrib ins_short_branch(0); // Required flag: is this instruction a
                                // non-matching short branch variant of some
                                                            // long branch?
ins_attrib ins_alignment(4);    // Required alignment attribute (must be a power of 2)
                                // specifies the alignment that some part of the instruction (not
                                // necessarily the start) requires.  If > 1, a compute_padding()
                                // function must be provided for the instruction

//----------OPERANDS-----------------------------------------------------------
// Operand definitions must precede instruction definitions for correct parsing
// in the ADLC because operands constitute user defined types which are used in
// instruction definitions.

// Vectors

operand vecX() %{
  constraint(ALLOC_IN_RC(vectorx_reg));
  match(VecX);

  format %{ %}
  interface(REG_INTER);
%}

operand vecY() %{
  constraint(ALLOC_IN_RC(vectory_reg));
  match(VecY);

   format %{ %}
   interface(REG_INTER);
%}

// Flags register, used as output of compare instructions
operand FlagsReg() %{
  constraint(ALLOC_IN_RC(t0_reg));
  match(RegFlags);

  format %{ "T0" %}
  interface(REG_INTER);
%}

//----------Simple Operands----------------------------------------------------
// TODO: Should we need to define some more special immediate number ?
// Immediate Operands
// Integer Immediate
operand immI() %{
  match(ConI);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

operand immIU1() %{
  predicate((0 <= n->get_int()) && (n->get_int() <= 1));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immIU2() %{
  predicate((0 <= n->get_int()) && (n->get_int() <= 3));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immIU3() %{
  predicate((0 <= n->get_int()) && (n->get_int() <= 7));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immIU4() %{
  predicate((0 <= n->get_int()) && (n->get_int() <= 15));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immIU5() %{
  predicate((0 <= n->get_int()) && (n->get_int() <= 31));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immIU6() %{
  predicate((0 <= n->get_int()) && (n->get_int() <= 63));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immIU8() %{
  predicate((0 <= n->get_int()) && (n->get_int() <= 255));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI10() %{
  predicate((-512 <= n->get_int()) && (n->get_int() <= 511));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI12() %{
  predicate((-2048 <= n->get_int()) && (n->get_int() <= 2047));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_M65536() %{
  predicate(n->get_int() == -65536);
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for decrement
operand immI_M1() %{
  predicate(n->get_int() == -1);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for zero
operand immI_0() %{
  predicate(n->get_int() == 0);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_1() %{
  predicate(n->get_int() == 1);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_2() %{
  predicate(n->get_int() == 2);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_16() %{
  predicate(n->get_int() == 16);
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_24() %{
  predicate(n->get_int() == 24);
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

// Constant for long shifts
operand immI_32() %{
  predicate(n->get_int() == 32);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for byte-wide masking
operand immI_255() %{
  predicate(n->get_int() == 255);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_65535() %{
  predicate(n->get_int() == 65535);
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_MaxI() %{
  predicate(n->get_int() == 2147483647);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_M2047_2048() %{
  predicate((-2047 <= n->get_int()) && (n->get_int() <= 2048));
  match(ConI);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// Valid scale values for addressing modes
operand immI_0_3() %{
  predicate(0 <= n->get_int() && (n->get_int() <= 3));
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_0_31() %{
  predicate(n->get_int() >= 0 && n->get_int() <= 31);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_0_4095() %{
  predicate(n->get_int() >= 0 && n->get_int() <= 4095);
  match(ConI);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_1_4() %{
  predicate(1 <= n->get_int() && (n->get_int() <= 4));
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_32_63() %{
  predicate(n->get_int() >= 32 && n->get_int() <= 63);
  match(ConI);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_M128_255() %{
  predicate((-128 <= n->get_int()) && (n->get_int() <= 255));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

// Operand for non-negtive integer mask
operand immI_nonneg_mask() %{
  predicate((n->get_int() >= 0) && (Assembler::is_int_mask(n->get_int()) != -1));
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate
operand immL() %{
  match(ConL);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

operand immLU5() %{
  predicate((0 <= n->get_long()) && (n->get_long() <= 31));
  match(ConL);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immL10() %{
  predicate((-512 <= n->get_long()) && (n->get_long() <= 511));
  match(ConL);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immL12() %{
  predicate((-2048 <= n->get_long()) && (n->get_long() <= 2047));
  match(ConL);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate 32-bit signed
operand immL32()
%{
  predicate(n->get_long() == (int)n->get_long());
  match(ConL);

  op_cost(15);
  format %{ %}
  interface(CONST_INTER);
%}

// bit 3..6 zero
operand immL_M121() %{
  predicate(n->get_long() == -121L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// bit 0..2 zero
operand immL_M8() %{
  predicate(n->get_long() == -8L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// bit 1..2 zero
operand immL_M7() %{
  predicate(n->get_long() == -7L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// bit 2 zero
operand immL_M5() %{
  predicate(n->get_long() == -5L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// bit 0..1 zero
operand immL_M4() %{
  predicate(n->get_long() == -4L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate zero
operand immL_0() %{
  predicate(n->get_long() == 0L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

operand immL_7() %{
  predicate(n->get_long() == 7L);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

operand immL_MaxUI() %{
  predicate(n->get_long() == 0xFFFFFFFFL);
  match(ConL);
  op_cost(20);

  format %{ %}
  interface(CONST_INTER);
%}

operand immL_M2047_2048() %{
  predicate((-2047 <= n->get_long()) && (n->get_long() <= 2048));
  match(ConL);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

operand immL_0_4095() %{
  predicate(n->get_long() >= 0 && n->get_long() <= 4095);
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Operand for non-negtive long mask
operand immL_nonneg_mask() %{
  predicate((n->get_long() >= 0) && (Assembler::is_jlong_mask(n->get_long()) != -1));
  match(ConL);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Pointer Immediate
operand immP() %{
  match(ConP);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// NULL Pointer Immediate
operand immP_0() %{
  predicate(n->get_ptr() == 0);
  match(ConP);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Pointer Immediate
operand immP_no_oop_cheap() %{
  predicate(!n->bottom_type()->isa_oop_ptr());
  match(ConP);

  op_cost(5);
  // formats are generated automatically for constants and base registers
  format %{ %}
  interface(CONST_INTER);
%}

// Pointer for polling page
operand immP_poll() %{
  predicate(n->get_ptr() != 0 && n->get_ptr() == (intptr_t)os::get_polling_page());
  match(ConP);
  op_cost(5);

  format %{ %}
  interface(CONST_INTER);
%}

// Pointer Immediate
operand immN() %{
  match(ConN);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// NULL Pointer Immediate
operand immN_0() %{
  predicate(n->get_narrowcon() == 0);
  match(ConN);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immNKlass() %{
  match(ConNKlass);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// Single-precision floating-point immediate
operand immF() %{
  match(ConF);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

// Single-precision floating-point zero
operand immF_0() %{
  predicate(jint_cast(n->getf()) == 0);
  match(ConF);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

// Double-precision floating-point immediate
operand immD() %{
  match(ConD);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

// Double-precision floating-point zero
operand immD_0() %{
  predicate(jlong_cast(n->getd()) == 0);
  match(ConD);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

// Register Operands
// Integer Register
operand mRegI() %{
  constraint(ALLOC_IN_RC(int_reg));
  match(RegI);

  format %{ %}
  interface(REG_INTER);
%}

operand no_Ax_mRegI() %{
  constraint(ALLOC_IN_RC(no_Ax_int_reg));
  match(RegI);
  match(mRegI);

  format %{  %}
  interface(REG_INTER);
%}

operand mS0RegI() %{
  constraint(ALLOC_IN_RC(s0_reg));
  match(RegI);
  match(mRegI);

  format %{ "S0" %}
  interface(REG_INTER);
%}

operand mS1RegI() %{
  constraint(ALLOC_IN_RC(s1_reg));
  match(RegI);
  match(mRegI);

  format %{ "S1" %}
  interface(REG_INTER);
%}

operand mS3RegI() %{
  constraint(ALLOC_IN_RC(s3_reg));
  match(RegI);
  match(mRegI);

  format %{ "S3" %}
  interface(REG_INTER);
%}

operand mS4RegI() %{
  constraint(ALLOC_IN_RC(s4_reg));
  match(RegI);
  match(mRegI);

  format %{ "S4" %}
  interface(REG_INTER);
%}

operand mS5RegI() %{
  constraint(ALLOC_IN_RC(s5_reg));
  match(RegI);
  match(mRegI);

  format %{ "S5" %}
  interface(REG_INTER);
%}

operand mS6RegI() %{
  constraint(ALLOC_IN_RC(s6_reg));
  match(RegI);
  match(mRegI);

  format %{ "S6" %}
  interface(REG_INTER);
%}

operand mS7RegI() %{
  constraint(ALLOC_IN_RC(s7_reg));
  match(RegI);
  match(mRegI);

  format %{ "S7" %}
  interface(REG_INTER);
%}


operand mT0RegI() %{
  constraint(ALLOC_IN_RC(t0_reg));
  match(RegI);
  match(mRegI);

  format %{ "T0" %}
  interface(REG_INTER);
%}

operand mT1RegI() %{
  constraint(ALLOC_IN_RC(t1_reg));
  match(RegI);
  match(mRegI);

  format %{ "T1" %}
  interface(REG_INTER);
%}

operand mT2RegI() %{
  constraint(ALLOC_IN_RC(t2_reg));
  match(RegI);
  match(mRegI);

  format %{ "T2" %}
  interface(REG_INTER);
%}

operand mT3RegI() %{
  constraint(ALLOC_IN_RC(t3_reg));
  match(RegI);
  match(mRegI);

  format %{ "T3" %}
  interface(REG_INTER);
%}

operand mT8RegI() %{
  constraint(ALLOC_IN_RC(t8_reg));
  match(RegI);
  match(mRegI);

  format %{ "T8" %}
  interface(REG_INTER);
%}

operand mT4RegI() %{
  constraint(ALLOC_IN_RC(t4_reg));
  match(RegI);
  match(mRegI);

  format %{ "T4" %}
  interface(REG_INTER);
%}

operand mA0RegI() %{
  constraint(ALLOC_IN_RC(a0_reg));
  match(RegI);
  match(mRegI);

  format %{ "A0" %}
  interface(REG_INTER);
%}

operand mA1RegI() %{
  constraint(ALLOC_IN_RC(a1_reg));
  match(RegI);
  match(mRegI);

  format %{ "A1" %}
  interface(REG_INTER);
%}

operand mA2RegI() %{
  constraint(ALLOC_IN_RC(a2_reg));
  match(RegI);
  match(mRegI);

  format %{ "A2" %}
  interface(REG_INTER);
%}

operand mA3RegI() %{
  constraint(ALLOC_IN_RC(a3_reg));
  match(RegI);
  match(mRegI);

  format %{ "A3" %}
  interface(REG_INTER);
%}

operand mA4RegI() %{
  constraint(ALLOC_IN_RC(a4_reg));
  match(RegI);
  match(mRegI);

  format %{ "A4" %}
  interface(REG_INTER);
%}

operand mA5RegI() %{
  constraint(ALLOC_IN_RC(a5_reg));
  match(RegI);
  match(mRegI);

  format %{ "A5" %}
  interface(REG_INTER);
%}

operand mA6RegI() %{
  constraint(ALLOC_IN_RC(a6_reg));
  match(RegI);
  match(mRegI);

  format %{ "A6" %}
  interface(REG_INTER);
%}

operand mA7RegI() %{
  constraint(ALLOC_IN_RC(a7_reg));
  match(RegI);
  match(mRegI);

  format %{ "A7" %}
  interface(REG_INTER);
%}

operand mRegN() %{
  constraint(ALLOC_IN_RC(int_reg));
  match(RegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t0_RegN() %{
  constraint(ALLOC_IN_RC(t0_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t1_RegN() %{
  constraint(ALLOC_IN_RC(t1_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t3_RegN() %{
  constraint(ALLOC_IN_RC(t3_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t8_RegN() %{
  constraint(ALLOC_IN_RC(t8_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a0_RegN() %{
  constraint(ALLOC_IN_RC(a0_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a1_RegN() %{
  constraint(ALLOC_IN_RC(a1_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a2_RegN() %{
  constraint(ALLOC_IN_RC(a2_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a3_RegN() %{
  constraint(ALLOC_IN_RC(a3_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a4_RegN() %{
  constraint(ALLOC_IN_RC(a4_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a5_RegN() %{
  constraint(ALLOC_IN_RC(a5_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a6_RegN() %{
  constraint(ALLOC_IN_RC(a6_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a7_RegN() %{
  constraint(ALLOC_IN_RC(a7_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s0_RegN() %{
  constraint(ALLOC_IN_RC(s0_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s1_RegN() %{
  constraint(ALLOC_IN_RC(s1_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s2_RegN() %{
  constraint(ALLOC_IN_RC(s2_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s3_RegN() %{
  constraint(ALLOC_IN_RC(s3_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s4_RegN() %{
  constraint(ALLOC_IN_RC(s4_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s5_RegN() %{
  constraint(ALLOC_IN_RC(s5_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s6_RegN() %{
  constraint(ALLOC_IN_RC(s6_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand s7_RegN() %{
  constraint(ALLOC_IN_RC(s7_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

// Pointer Register
operand mRegP() %{
  constraint(ALLOC_IN_RC(p_reg));
  match(RegP);
  match(a0_RegP);

  format %{  %}
  interface(REG_INTER);
%}

operand no_T8_mRegP() %{
  constraint(ALLOC_IN_RC(no_T8_p_reg));
  match(RegP);
  match(mRegP);

  format %{  %}
  interface(REG_INTER);
%}

operand no_Ax_mRegP() %{
  constraint(ALLOC_IN_RC(no_Ax_p_reg));
  match(RegP);
  match(mRegP);

  format %{  %}
  interface(REG_INTER);
%}

operand s1_RegP()
%{
  constraint(ALLOC_IN_RC(s1_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s3_RegP()
%{
  constraint(ALLOC_IN_RC(s3_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s4_RegP()
%{
  constraint(ALLOC_IN_RC(s4_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s5_RegP()
%{
  constraint(ALLOC_IN_RC(s5_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s6_RegP()
%{
  constraint(ALLOC_IN_RC(s6_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s7_RegP()
%{
  constraint(ALLOC_IN_RC(s7_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t0_RegP()
%{
  constraint(ALLOC_IN_RC(t0_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t1_RegP()
%{
  constraint(ALLOC_IN_RC(t1_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t2_RegP()
%{
  constraint(ALLOC_IN_RC(t2_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t3_RegP()
%{
  constraint(ALLOC_IN_RC(t3_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t8_RegP()
%{
  constraint(ALLOC_IN_RC(t8_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a0_RegP()
%{
  constraint(ALLOC_IN_RC(a0_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a1_RegP()
%{
  constraint(ALLOC_IN_RC(a1_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a2_RegP()
%{
  constraint(ALLOC_IN_RC(a2_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a3_RegP()
%{
  constraint(ALLOC_IN_RC(a3_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a4_RegP()
%{
  constraint(ALLOC_IN_RC(a4_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}


operand a5_RegP()
%{
  constraint(ALLOC_IN_RC(a5_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a6_RegP()
%{
  constraint(ALLOC_IN_RC(a6_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a7_RegP()
%{
  constraint(ALLOC_IN_RC(a7_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand v0_RegP()
%{
  constraint(ALLOC_IN_RC(v0_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand v1_RegP()
%{
  constraint(ALLOC_IN_RC(v1_long_reg));
  match(RegP);
  match(mRegP);
  match(no_T8_mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand mRegL() %{
  constraint(ALLOC_IN_RC(long_reg));
  match(RegL);

  format %{ %}
  interface(REG_INTER);
%}

operand mRegI2L(mRegI reg) %{
  match(ConvI2L reg);

  format %{ %}
  interface(REG_INTER);
%}

operand v0RegL() %{
  constraint(ALLOC_IN_RC(v0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand v1RegL() %{
  constraint(ALLOC_IN_RC(v1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a0RegL() %{
  constraint(ALLOC_IN_RC(a0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ "A0" %}
  interface(REG_INTER);
%}

operand a1RegL() %{
  constraint(ALLOC_IN_RC(a1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a2RegL() %{
  constraint(ALLOC_IN_RC(a2_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a3RegL() %{
  constraint(ALLOC_IN_RC(a3_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t0RegL() %{
  constraint(ALLOC_IN_RC(t0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t1RegL() %{
  constraint(ALLOC_IN_RC(t1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t3RegL() %{
  constraint(ALLOC_IN_RC(t3_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t8RegL() %{
  constraint(ALLOC_IN_RC(t8_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a4RegL() %{
  constraint(ALLOC_IN_RC(a4_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a5RegL() %{
  constraint(ALLOC_IN_RC(a5_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a6RegL() %{
  constraint(ALLOC_IN_RC(a6_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a7RegL() %{
  constraint(ALLOC_IN_RC(a7_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s0RegL() %{
  constraint(ALLOC_IN_RC(s0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s1RegL() %{
  constraint(ALLOC_IN_RC(s1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s3RegL() %{
  constraint(ALLOC_IN_RC(s3_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s4RegL() %{
  constraint(ALLOC_IN_RC(s4_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand s7RegL() %{
  constraint(ALLOC_IN_RC(s7_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

// Floating register operands
operand regF() %{
  constraint(ALLOC_IN_RC(flt_reg));
  match(RegF);

  format %{ %}
  interface(REG_INTER);
%}

//Double Precision Floating register operands
operand regD() %{
  constraint(ALLOC_IN_RC(dbl_reg));
  match(RegD);

  format %{ %}
  interface(REG_INTER);
%}

//----------Memory Operands----------------------------------------------------
// Indirect Memory Operand
operand indirect(mRegP reg) %{
  constraint(ALLOC_IN_RC(p_reg));
  match(reg);

  format %{ "[$reg] @ indirect" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);  /* NO_INDEX */
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Plus Short Offset Operand
operand indOffset12(mRegP reg, immL12 off)
%{
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP reg off);

  op_cost(10);
  format %{ "[$reg + $off (12-bit)] @ indOffset12" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0); /* NO_INDEX */
    scale(0x0);
    disp($off);
  %}
%}

operand indOffset12I2L(mRegP reg, immI12 off)
%{
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP reg (ConvI2L off));

  op_cost(10);
  format %{ "[$reg + $off (12-bit)] @ indOffset12I2L" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0); /* NO_INDEX */
    scale(0x0);
    disp($off);
  %}
%}

// Indirect Memory Plus Index Register
operand indIndex(mRegP addr, mRegL index) %{
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP addr index);

  op_cost(20);
  format %{"[$addr + $index] @ indIndex" %}
  interface(MEMORY_INTER) %{
    base($addr);
    index($index);
    scale(0x0);
    disp(0x0);
  %}
%}

operand indIndexI2L(mRegP reg, mRegI ireg)
%{
  constraint(ALLOC_IN_RC(ptr_reg));
  match(AddP reg (ConvI2L ireg));
  op_cost(10);
  format %{ "[$reg + $ireg] @ indIndexI2L" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index($ireg);
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Operand
operand indirectNarrow(mRegN reg)
%{
  predicate(Universe::narrow_oop_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(DecodeN reg);

  format %{ "[$reg] @ indirectNarrow" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Plus Short Offset Operand
operand indOffset12Narrow(mRegN reg, immL12 off)
%{
  predicate(Universe::narrow_oop_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(AddP (DecodeN reg) off);

  format %{ "[$reg + $off (12-bit)] @ indOffset12Narrow" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp($off);
  %}
%}

//----------Conditional Branch Operands----------------------------------------
// Comparison Op  - This is the operation of the comparison, and is limited to
//                  the following set of codes:
//                  L (<), LE (<=), G (>), GE (>=), E (==), NE (!=)
//
// Other attributes of the comparison, such as unsignedness, are specified
// by the comparison instruction that sets a condition code flags register.
// That result is represented by a flags operand whose subtype is appropriate
// to the unsignedness (etc.) of the comparison.
//
// Later, the instruction which matches both the Comparison Op (a Bool) and
// the flags (produced by the Cmp) specifies the coding of the comparison op
// by matching a specific subtype of Bool operand below, such as cmpOpU.

// Comparision Code
operand cmpOp() %{
  match(Bool);

  format %{ "" %}
  interface(COND_INTER) %{
    equal(0x01);
    not_equal(0x02);
    greater(0x03);
    greater_equal(0x04);
    less(0x05);
    less_equal(0x06);
    overflow(0x7);
    no_overflow(0x8);
  %}
%}


// Comparision Code
// Comparison Code, unsigned compare.  Used by FP also, with
// C2 (unordered) turned into GT or LT already.  The other bits
// C0 and C3 are turned into Carry & Zero flags.
operand cmpOpU() %{
  match(Bool);

  format %{ "" %}
  interface(COND_INTER) %{
    equal(0x01);
    not_equal(0x02);
    greater(0x03);
    greater_equal(0x04);
    less(0x05);
    less_equal(0x06);
    overflow(0x7);
    no_overflow(0x8);
  %}
%}


//----------Special Memory Operands--------------------------------------------
// Stack Slot Operand - This operand is used for loading and storing temporary
//                      values on the stack where a match requires a value to
//                      flow through memory.
operand stackSlotP(sRegP reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);  // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotI(sRegI reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);  // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotF(sRegF reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);  // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotD(sRegD reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);  // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotL(sRegL reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);  // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}


//------------------------OPERAND CLASSES--------------------------------------
opclass memory( indirect, indOffset12, indOffset12I2L, indIndex, indIndexI2L,
                indirectNarrow, indOffset12Narrow);
opclass memory_loadRange(indOffset12, indirect);

opclass mRegLorI2L(mRegI2L, mRegL);
//----------PIPELINE-----------------------------------------------------------
// Rules which define the behavior of the target architectures pipeline.

pipeline %{

  //----------ATTRIBUTES---------------------------------------------------------
  attributes %{
    fixed_size_instructions;          // Fixed size instructions
    max_instructions_per_bundle = 1;     // 1 instruction per bundle
    max_bundles_per_cycle = 4;         // Up to 4 bundles per cycle
         bundle_unit_size=4;
    instruction_unit_size = 4;           // An instruction is 4 bytes long
    instruction_fetch_unit_size = 16;    // The processor fetches one line
    instruction_fetch_units = 1;         // of 16 bytes

    // List of nop instructions
    nops( MachNop );
  %}

  //----------RESOURCES----------------------------------------------------------
  // Resources are the functional units available to the machine

  resources(D1, D2, D3, D4, DECODE = D1 | D2 | D3| D4,  ALU1, ALU2,  ALU = ALU1 | ALU2,  FPU1, FPU2, FPU = FPU1 | FPU2,  MEM,  BR);

  //----------PIPELINE DESCRIPTION-----------------------------------------------
  // Pipeline Description specifies the stages in the machine's pipeline

  // IF: fetch
  // ID: decode
  // RD: read
  // CA: caculate
  // WB: write back
  // CM: commit

  pipe_desc(IF, ID, RD, CA, WB, CM);


  //----------PIPELINE CLASSES---------------------------------------------------
  // Pipeline Classes describe the stages in which input and output are
  // referenced by the hardware pipeline.

  //No.1 Integer ALU reg-reg operation : dst <-- reg1 op reg2
  pipe_class ialu_regI_regI(mRegI dst, mRegI src1, mRegI src2) %{
    single_instruction;
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write)+1;
    DECODE : ID;
    ALU    : CA;
  %}

  //No.19 Integer mult operation : dst <-- reg1 mult reg2
  pipe_class ialu_mult(mRegI dst, mRegI src1, mRegI src2) %{
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write)+5;
    DECODE : ID;
    ALU2   : CA;
  %}

  pipe_class mulL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write)+10;
    DECODE : ID;
    ALU2   : CA;
  %}

  //No.19 Integer div operation : dst <-- reg1 div reg2
  pipe_class ialu_div(mRegI dst, mRegI src1, mRegI src2) %{
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write)+10;
    DECODE : ID;
    ALU2   : CA;
  %}

  //No.19 Integer mod operation : dst <-- reg1 mod reg2
  pipe_class ialu_mod(mRegI dst, mRegI src1, mRegI src2) %{
    instruction_count(2);
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write)+10;
    DECODE : ID;
    ALU2   : CA;
  %}

  //No.15 Long ALU reg-reg operation : dst <-- reg1 op reg2
  pipe_class ialu_regL_regL(mRegL dst, mRegL src1, mRegL src2) %{
    instruction_count(2);
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write);
    DECODE : ID;
    ALU    : CA;
  %}

  //No.18 Long ALU reg-imm16 operation : dst <-- reg1 op imm16
  pipe_class ialu_regL_imm16(mRegL dst, mRegL src) %{
    instruction_count(2);
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    ALU    : CA;
  %}

  //no.16 load Long from memory :
  pipe_class ialu_loadL(mRegL dst, memory mem) %{
    instruction_count(2);
    mem    : RD(read);
    dst    : WB(write)+5;
    DECODE : ID;
    MEM    : RD;
  %}

  //No.17 Store Long to Memory :
  pipe_class ialu_storeL(mRegL src, memory mem) %{
    instruction_count(2);
    mem    : RD(read);
    src    : RD(read);
    DECODE : ID;
    MEM    : RD;
  %}

  //No.2 Integer ALU reg-imm16 operation : dst <-- reg1 op imm16
  pipe_class ialu_regI_imm16(mRegI dst, mRegI src) %{
         single_instruction;
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    ALU    : CA;
  %}

  //No.3 Integer move operation : dst <-- reg
  pipe_class ialu_regI_mov(mRegI dst, mRegI src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    ALU    : CA;
  %}

  //No.4 No instructions : do nothing
  pipe_class empty( ) %{
    instruction_count(0);
  %}

  //No.5 UnConditional branch :
  pipe_class pipe_jump( label labl ) %{
    multiple_bundles;
    DECODE : ID;
    BR     : RD;
  %}

  //No.6 ALU Conditional branch :
  pipe_class pipe_alu_branch(mRegI src1, mRegI src2, label labl ) %{
    multiple_bundles;
    src1   : RD(read);
    src2   : RD(read);
    DECODE : ID;
    BR     : RD;
  %}

  //no.7 load integer from memory :
  pipe_class ialu_loadI(mRegI dst, memory mem) %{
    mem    : RD(read);
    dst    : WB(write)+3;
    DECODE : ID;
    MEM    : RD;
  %}

  //No.8 Store Integer to Memory :
  pipe_class ialu_storeI(mRegI src, memory mem) %{
    mem    : RD(read);
    src    : RD(read);
    DECODE : ID;
    MEM    : RD;
  %}


  //No.10 Floating FPU reg-reg operation : dst <-- reg1 op reg2
  pipe_class fpu_regF_regF(regF dst, regF src1, regF src2) %{
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU    : CA;
  %}

  //No.22 Floating div operation : dst <-- reg1 div reg2
  pipe_class fpu_div(regF dst, regF src1, regF src2) %{
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU2   : CA;
  %}

  pipe_class fcvt_I2D(regD dst, mRegI src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU1   : CA;
  %}

  pipe_class fcvt_D2I(mRegI dst, regD src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU1   : CA;
  %}

  pipe_class pipe_mfc1(mRegI dst, regD src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    MEM    : RD;
  %}

  pipe_class pipe_mtc1(regD dst, mRegI src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    MEM    : RD(5);
  %}

  //No.23 Floating sqrt operation : dst <-- reg1 sqrt reg2
  pipe_class fpu_sqrt(regF dst, regF src1, regF src2) %{
    multiple_bundles;
    src1   : RD(read);
    src2   : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU2   : CA;
  %}

  //No.11 Load Floating from Memory :
  pipe_class fpu_loadF(regF dst, memory mem) %{
    instruction_count(1);
    mem    : RD(read);
    dst    : WB(write)+3;
    DECODE : ID;
    MEM    : RD;
  %}

  //No.12 Store Floating to Memory :
  pipe_class fpu_storeF(regF src, memory mem) %{
    instruction_count(1);
    mem    : RD(read);
    src    : RD(read);
    DECODE : ID;
    MEM    : RD;
  %}

  //No.13 FPU Conditional branch :
  pipe_class pipe_fpu_branch(regF src1, regF src2, label labl ) %{
    multiple_bundles;
    src1   : RD(read);
    src2   : RD(read);
    DECODE : ID;
    BR     : RD;
  %}

//No.14 Floating FPU reg operation : dst <-- op reg
  pipe_class fpu1_regF(regF dst, regF src) %{
    src    : RD(read);
    dst    : WB(write);
    DECODE : ID;
    FPU    : CA;
  %}

  pipe_class long_memory_op() %{
    instruction_count(10); multiple_bundles; force_serialization;
    fixed_latency(30);
  %}

  pipe_class simple_call() %{
   instruction_count(10); multiple_bundles; force_serialization;
   fixed_latency(200);
   BR     : RD;
  %}

  pipe_class call() %{
    instruction_count(10); multiple_bundles; force_serialization;
    fixed_latency(200);
  %}

  //FIXME:
  //No.9 Piple slow : for multi-instructions
  pipe_class pipe_slow(  ) %{
    instruction_count(20);
    force_serialization;
    multiple_bundles;
    fixed_latency(50);
  %}

%}



//----------INSTRUCTIONS-------------------------------------------------------
//
// match      -- States which machine-independent subtree may be replaced
//               by this instruction.
// ins_cost   -- The estimated cost of this instruction is used by instruction
//               selection to identify a minimum cost tree of machine
//               instructions that matches a tree of machine-independent
//               instructions.
// format     -- A string providing the disassembly for this instruction.
//               The value of an instruction's operand may be inserted
//               by referring to it with a '$' prefix.
// opcode     -- Three instruction opcodes may be provided.  These are referred
//               to within an encode class as $primary, $secondary, and $tertiary
//               respectively.  The primary opcode is commonly used to
//               indicate the type of machine instruction, while secondary
//               and tertiary are often used for prefix options or addressing
//               modes.
// ins_encode -- A list of encode classes with parameters. The encode class
//               name must have been defined in an 'enc_class' specification
//               in the encode section of the architecture description.


// Load Integer
instruct loadI(mRegI dst, memory mem) %{
  match(Set dst (LoadI mem));

  ins_cost(125);
  format %{ "ld_w    $dst, $mem   #@loadI" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_INT);
  %}
  ins_pipe( ialu_loadI );
%}

instruct loadI_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadI mem)));

  ins_cost(125);
  format %{ "ld_w    $dst, $mem   #@loadI_convI2L" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_INT);
  %}
  ins_pipe( ialu_loadI );
%}

// Load Integer (32 bit signed) to Byte (8 bit signed)
instruct loadI2B(mRegI dst, memory mem, immI_24 twentyfour) %{
  match(Set dst (RShiftI (LShiftI (LoadI mem) twentyfour) twentyfour));

  ins_cost(125);
  format %{ "ld_b  $dst, $mem\t# int -> byte #@loadI2B" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_BYTE);
  %}
  ins_pipe(ialu_loadI);
%}

// Load Integer (32 bit signed) to Unsigned Byte (8 bit UNsigned)
instruct loadI2UB(mRegI dst, memory mem, immI_255 mask) %{
  match(Set dst (AndI (LoadI mem) mask));

  ins_cost(125);
  format %{ "ld_bu  $dst, $mem\t# int -> ubyte #@loadI2UB" %}
    ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_BYTE);
  %}
  ins_pipe(ialu_loadI);
%}

// Load Integer (32 bit signed) to Short (16 bit signed)
instruct loadI2S(mRegI dst, memory mem, immI_16 sixteen) %{
  match(Set dst (RShiftI (LShiftI (LoadI mem) sixteen) sixteen));

  ins_cost(125);
  format %{ "ld_h  $dst, $mem\t# int -> short #@loadI2S" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_SHORT);
  %}
  ins_pipe(ialu_loadI);
%}

// Load Integer (32 bit signed) to Unsigned Short/Char (16 bit UNsigned)
instruct loadI2US(mRegI dst, memory mem, immI_65535 mask) %{
  match(Set dst (AndI (LoadI mem) mask));

  ins_cost(125);
  format %{ "ld_hu  $dst, $mem\t# int -> ushort/char #@loadI2US" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_SHORT);
  %}
  ins_pipe(ialu_loadI);
%}

// Load Long.
instruct loadL(mRegL dst, memory mem) %{
//  predicate(!((LoadLNode*)n)->require_atomic_access());
  match(Set dst (LoadL mem));

  ins_cost(250);
  format %{ "ld_d    $dst, $mem   #@loadL" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_LONG);
  %}
  ins_pipe( ialu_loadL );
%}

// Load Long - UNaligned
instruct loadL_unaligned(mRegL dst, memory mem) %{
  match(Set dst (LoadL_unaligned mem));

  // FIXME: Need more effective ldl/ldr
  ins_cost(450);
  format %{ "ld_d    $dst, $mem   #@loadL_unaligned\n\t" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_LONG);
  %}
  ins_pipe( ialu_loadL );
%}

// Store Long
instruct storeL_reg(memory mem, mRegL src) %{
  match(Set mem (StoreL mem src));

  ins_cost(200);
  format %{ "st_d    $mem,   $src #@storeL_reg\n" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_LONG);
  %}
  ins_pipe( ialu_storeL );
%}

instruct storeL_immL_0(memory mem, immL_0 zero) %{
  match(Set mem (StoreL mem zero));

  ins_cost(180);
  format %{ "st_d    zero, $mem #@storeL_immL_0" %}
  ins_encode %{
     __ loadstore_enc(R0, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_LONG);
  %}
  ins_pipe( ialu_storeL );
%}

// Load Compressed Pointer
instruct loadN(mRegN dst, memory mem)
%{
   match(Set dst (LoadN mem));

   ins_cost(125); // XXX
   format %{ "ld_wu    $dst, $mem\t# compressed ptr @ loadN" %}
   ins_encode %{
     relocInfo::relocType disp_reloc = $mem->disp_reloc();
     assert(disp_reloc == relocInfo::none, "cannot have disp");
     __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_INT);
   %}
   ins_pipe( ialu_loadI ); // XXX
%}

instruct loadN2P(mRegP dst, memory mem)
%{
   match(Set dst (DecodeN (LoadN mem)));
   predicate(Universe::narrow_oop_base() == NULL && Universe::narrow_oop_shift() == 0);

   ins_cost(125); // XXX
   format %{ "ld_wu    $dst, $mem\t# @ loadN2P" %}
   ins_encode %{
     relocInfo::relocType disp_reloc = $mem->disp_reloc();
     assert(disp_reloc == relocInfo::none, "cannot have disp");
     __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_INT);
   %}
   ins_pipe( ialu_loadI ); // XXX
%}

// Load Pointer
instruct loadP(mRegP dst, memory mem) %{
  match(Set dst (LoadP mem));

  ins_cost(125);
  format %{ "ld_d    $dst, $mem #@loadP" %}
  ins_encode %{
    relocInfo::relocType disp_reloc = $mem->disp_reloc();
    assert(disp_reloc == relocInfo::none, "cannot have disp");
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_LONG);
  %}
  ins_pipe( ialu_loadI );
%}

// Load Klass Pointer
instruct loadKlass(mRegP dst, memory mem) %{
  match(Set dst (LoadKlass mem));

  ins_cost(125);
  format %{ "MOV    $dst,$mem @ loadKlass" %}
  ins_encode %{
    relocInfo::relocType disp_reloc = $mem->disp_reloc();
    assert(disp_reloc == relocInfo::none, "cannot have disp");
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_LONG);
  %}
  ins_pipe( ialu_loadI );
%}

// Load narrow Klass Pointer
instruct loadNKlass(mRegN dst, memory mem)
%{
  match(Set dst (LoadNKlass mem));

  ins_cost(125); // XXX
  format %{ "ld_wu    $dst, $mem\t# compressed klass ptr @ loadNKlass" %}
  ins_encode %{
    relocInfo::relocType disp_reloc = $mem->disp_reloc();
    assert(disp_reloc == relocInfo::none, "cannot have disp");
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_INT);
  %}
  ins_pipe( ialu_loadI ); // XXX
%}

instruct loadN2PKlass(mRegP dst, memory mem)
%{
  match(Set dst (DecodeNKlass (LoadNKlass mem)));
  predicate(Universe::narrow_klass_base() == NULL && Universe::narrow_klass_shift() == 0);

  ins_cost(125); // XXX
  format %{ "ld_wu    $dst, $mem\t# compressed klass ptr @ loadN2PKlass" %}
  ins_encode %{
    relocInfo::relocType disp_reloc = $mem->disp_reloc();
    assert(disp_reloc == relocInfo::none, "cannot have disp");
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_INT);
  %}
  ins_pipe( ialu_loadI ); // XXX
%}

// Load Constant
instruct loadConI(mRegI dst, immI src) %{
  match(Set dst src);

  ins_cost(120);
  format %{ "mov    $dst, $src #@loadConI" %}
  ins_encode %{
    Register dst = $dst$$Register;
    int    value = $src$$constant;
    __ li(dst, value);
  %}
  ins_pipe( ialu_regI_regI );
%}


instruct loadConL(mRegL dst, immL src) %{
  match(Set dst src);
  ins_cost(120);
  format %{ "li   $dst, $src @ loadConL" %}
  ins_encode %{
    __ li($dst$$Register, $src$$constant);
  %}
  ins_pipe(ialu_regL_regL);
%}

// Load Range
instruct loadRange(mRegI dst, memory_loadRange mem) %{
  match(Set dst (LoadRange mem));

  ins_cost(125);
  format %{ "MOV    $dst,$mem @ loadRange" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_INT);
  %}
  ins_pipe( ialu_loadI );
%}


instruct storeP(memory mem, mRegP src ) %{
  match(Set mem (StoreP mem src));

  ins_cost(125);
  format %{ "st_d    $src, $mem #@storeP" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_LONG);
  %}
  ins_pipe( ialu_storeI );
%}

// Store NULL Pointer, mark word, or other simple pointer constant.
instruct storeImmP_immP_0(memory mem, immP_0 zero) %{
  match(Set mem (StoreP mem zero));

  ins_cost(125);
  format %{ "mov    $mem, $zero #@storeImmP_0" %}
    ins_encode %{
     __ loadstore_enc(R0, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_LONG);
  %}
  ins_pipe( ialu_storeI );
%}

// Store Compressed Pointer
instruct storeN(memory mem, mRegN src)
%{
  match(Set mem (StoreN mem src));

  ins_cost(125); // XXX
  format %{ "st_w    $mem, $src\t# compressed ptr @ storeN" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_INT);
  %}
  ins_pipe( ialu_storeI );
%}

instruct storeP2N(memory mem, mRegP src)
%{
  match(Set mem (StoreN mem (EncodeP src)));
  predicate(Universe::narrow_oop_base() == NULL && Universe::narrow_oop_shift() == 0);

  ins_cost(125); // XXX
  format %{ "st_w    $mem, $src\t# @ storeP2N" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_INT);
  %}
  ins_pipe( ialu_storeI );
%}

instruct storeNKlass(memory mem, mRegN src)
%{
  match(Set mem (StoreNKlass mem src));

  ins_cost(125); // XXX
  format %{ "st_w    $mem, $src\t# compressed klass ptr @ storeNKlass" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_INT);
  %}
  ins_pipe( ialu_storeI );
%}

instruct storeP2NKlass(memory mem, mRegP src)
%{
  match(Set mem (StoreNKlass mem (EncodePKlass src)));
  predicate(Universe::narrow_klass_base() == NULL && Universe::narrow_klass_shift() == 0);

  ins_cost(125); // XXX
  format %{ "st_w    $mem, $src\t# @ storeP2NKlass" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_INT);
  %}
  ins_pipe( ialu_storeI );
%}

instruct storeImmN_immN_0(memory mem, immN_0 zero)
%{
  match(Set mem (StoreN mem zero));

  ins_cost(125); // XXX
  format %{ "storeN0    zero, $mem\t# compressed ptr" %}
  ins_encode %{
     __ loadstore_enc(R0, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_INT);
  %}
  ins_pipe( ialu_storeI );
%}

// Store Byte
instruct storeB_immB_0(memory mem, immI_0 zero) %{
  match(Set mem (StoreB mem zero));

  format %{ "mov    $mem, zero #@storeB_immB_0" %}
  ins_encode %{
    __ loadstore_enc(R0, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_BYTE);
  %}
  ins_pipe( ialu_storeI );
%}

instruct storeB(memory mem, mRegI src) %{
  match(Set mem (StoreB mem src));

  ins_cost(125);
  format %{ "st_b    $src, $mem #@storeB" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_BYTE);
  %}
  ins_pipe( ialu_storeI );
%}

instruct storeB_convL2I(memory mem, mRegL src) %{
  match(Set mem (StoreB mem (ConvL2I src)));

  ins_cost(125);
  format %{ "st_b    $src, $mem #@storeB_convL2I" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_BYTE);
  %}
  ins_pipe( ialu_storeI );
%}

// Load Byte (8bit signed)
instruct loadB(mRegI dst, memory mem) %{
  match(Set dst (LoadB mem));

  ins_cost(125);
  format %{ "ld_b   $dst, $mem #@loadB" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_BYTE);
  %}
  ins_pipe( ialu_loadI );
%}

instruct loadB_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadB mem)));

  ins_cost(125);
  format %{ "ld_b   $dst, $mem #@loadB_convI2L" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_BYTE);
  %}
  ins_pipe( ialu_loadI );
%}

// Load Byte (8bit UNsigned)
instruct loadUB(mRegI dst, memory mem) %{
  match(Set dst (LoadUB mem));

  ins_cost(125);
  format %{ "ld_bu   $dst, $mem #@loadUB" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_BYTE);
  %}
  ins_pipe( ialu_loadI );
%}

instruct loadUB_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadUB mem)));

  ins_cost(125);
  format %{ "ld_bu   $dst, $mem #@loadUB_convI2L" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_BYTE);
  %}
  ins_pipe( ialu_loadI );
%}

// Load Short (16bit signed)
instruct loadS(mRegI dst, memory mem) %{
  match(Set dst (LoadS mem));

  ins_cost(125);
  format %{ "ld_h   $dst, $mem #@loadS" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_SHORT);
  %}
  ins_pipe( ialu_loadI );
%}

// Load Short (16 bit signed) to Byte (8 bit signed)
instruct loadS2B(mRegI dst, memory mem, immI_24 twentyfour) %{
  match(Set dst (RShiftI (LShiftI (LoadS mem) twentyfour) twentyfour));

  ins_cost(125);
  format %{ "ld_b $dst, $mem\t# short -> byte #@loadS2B" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_BYTE);
  %}
  ins_pipe(ialu_loadI);
%}

instruct loadS_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadS mem)));

  ins_cost(125);
  format %{ "ld_h   $dst, $mem #@loadS_convI2L" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_SHORT);
  %}
  ins_pipe( ialu_loadI );
%}

// Store Integer Immediate
instruct storeI_immI_0(memory mem, immI_0 zero) %{
  match(Set mem (StoreI mem zero));

  format %{ "mov    $mem, zero #@storeI_immI_0" %}
  ins_encode %{
    __ loadstore_enc(R0, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_INT);
  %}
  ins_pipe( ialu_storeI );
%}

// Store Integer
instruct storeI(memory mem, mRegI src) %{
  match(Set mem (StoreI mem src));

  ins_cost(125);
  format %{ "st_w    $mem, $src #@storeI" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_INT);
  %}
  ins_pipe( ialu_storeI );
%}

instruct storeI_convL2I(memory mem, mRegL src) %{
  match(Set mem (StoreI mem (ConvL2I src)));

  ins_cost(125);
  format %{ "st_w    $mem, $src #@storeI_convL2I" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_INT);
  %}
  ins_pipe( ialu_storeI );
%}

// Load Float
instruct loadF(regF dst, memory mem) %{
  match(Set dst (LoadF mem));

  ins_cost(150);
  format %{ "loadF $dst, $mem #@loadF" %}
  ins_encode %{
    __ loadstore_enc($dst$$FloatRegister, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_FLOAT);
  %}
  ins_pipe( ialu_loadI );
%}

instruct loadConP_general(mRegP dst, immP src) %{
  match(Set dst src);

  ins_cost(120);
  format %{ "li   $dst, $src #@loadConP_general" %}

  ins_encode %{
    Register dst = $dst$$Register;
    long* value = (long*)$src$$constant;

    if($src->constant_reloc() == relocInfo::metadata_type){
      int klass_index = __ oop_recorder()->find_index((Klass*)value);
      RelocationHolder rspec = metadata_Relocation::spec(klass_index);

      __ relocate(rspec);
      __ patchable_li52(dst, (long)value);
    } else if($src->constant_reloc() == relocInfo::oop_type){
      int oop_index = __ oop_recorder()->find_index((jobject)value);
      RelocationHolder rspec = oop_Relocation::spec(oop_index);

      __ relocate(rspec);
      __ patchable_li52(dst, (long)value);
    } else if ($src->constant_reloc() == relocInfo::none) {
        __ li(dst, (long)value);
    }
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct loadConP_no_oop_cheap(mRegP dst, immP_no_oop_cheap src) %{
  match(Set dst src);

  ins_cost(80);
  format %{ "li    $dst, $src @ loadConP_no_oop_cheap" %}

  ins_encode %{
    if ($src->constant_reloc() == relocInfo::metadata_type) {
      __ mov_metadata($dst$$Register, (Metadata*)$src$$constant);
    } else {
      __ li($dst$$Register, $src$$constant);
    }
  %}

  ins_pipe(ialu_regI_regI);
%}


instruct loadConP_poll(mRegP dst, immP_poll src) %{
  match(Set dst src);

  ins_cost(50);
  format %{ "li   $dst, $src #@loadConP_poll" %}

  ins_encode %{
    Register dst = $dst$$Register;
    intptr_t value = (intptr_t)$src$$constant;

    __ li(dst, (jlong)value);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct loadConP_immP_0(mRegP dst, immP_0 src)
%{
  match(Set dst src);

  ins_cost(50);
  format %{ "mov    $dst, R0\t# ptr" %}
  ins_encode %{
     Register dst_reg = $dst$$Register;
     __ add_d(dst_reg, R0, R0);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct loadConN_immN_0(mRegN dst, immN_0 src) %{
  match(Set dst src);
  format %{ "move    $dst, R0\t# compressed NULL ptr" %}
  ins_encode %{
    __ move($dst$$Register, R0);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct loadConN(mRegN dst, immN src) %{
  match(Set dst src);

  ins_cost(125);
  format %{ "li    $dst, $src\t# compressed ptr @ loadConN" %}
  ins_encode %{
    Register dst = $dst$$Register;
    __ set_narrow_oop(dst, (jobject)$src$$constant);
  %}
  ins_pipe( ialu_regI_regI ); // XXX
%}

instruct loadConNKlass(mRegN dst, immNKlass src) %{
  match(Set dst src);

  ins_cost(125);
  format %{ "li    $dst, $src\t# compressed klass ptr @ loadConNKlass" %}
  ins_encode %{
    Register dst = $dst$$Register;
    __ set_narrow_klass(dst, (Klass*)$src$$constant);
  %}
  ins_pipe( ialu_regI_regI ); // XXX
%}

//FIXME
// Tail Call; Jump from runtime stub to Java code.
// Also known as an 'interprocedural jump'.
// Target of jump will eventually return to caller.
// TailJump below removes the return address.
instruct TailCalljmpInd(mRegP jump_target, mRegP method_oop) %{
  match(TailCall jump_target method_oop );
  ins_cost(300);
  format %{ "JMP    $jump_target \t# @TailCalljmpInd" %}

  ins_encode %{
    Register target = $jump_target$$Register;
    Register    oop = $method_oop$$Register;

    // RA will be used in generate_forward_exception()
    __ push(RA);

    __ move(S3, oop);
    __ jr(target);
  %}

  ins_pipe( pipe_jump );
%}

// Create exception oop: created by stack-crawling runtime code.
// Created exception is now available to this handler, and is setup
// just prior to jumping to this handler.  No code emitted.
instruct CreateException( a0_RegP ex_oop )
%{
  match(Set ex_oop (CreateEx));

  // use the following format syntax
  format %{ "# exception oop is in A0; no code emitted @CreateException" %}
  ins_encode %{
    // X86 leaves this function empty
    __ block_comment("CreateException is empty in LA");
  %}
  ins_pipe( empty );
//  ins_pipe( pipe_jump );
%}


/* The mechanism of exception handling is clear now.

- Common try/catch:
  [stubGenerator_loongarch.cpp] generate_forward_exception()
      |- V0, V1 are created
      |- T4 <= SharedRuntime::exception_handler_for_return_address
      `- jr T4
           `- the caller's exception_handler
                 `- jr OptoRuntime::exception_blob
                        `- here
- Rethrow(e.g. 'unwind'):
  * The callee:
     |- an exception is triggered during execution
     `- exits the callee method through RethrowException node
          |- The callee pushes exception_oop(T0) and exception_pc(RA)
          `- The callee jumps to OptoRuntime::rethrow_stub()
  * In OptoRuntime::rethrow_stub:
     |- The VM calls _rethrow_Java to determine the return address in the caller method
     `- exits the stub with tailjmpInd
          |- pops exception_oop(V0) and exception_pc(V1)
          `- jumps to the return address(usually an exception_handler)
  * The caller:
     `- continues processing the exception_blob with V0/V1
*/

// Rethrow exception:
// The exception oop will come in the first argument position.
// Then JUMP (not call) to the rethrow stub code.
instruct RethrowException()
%{
  match(Rethrow);

  // use the following format syntax
  format %{ "JMP    rethrow_stub #@RethrowException" %}
  ins_encode %{
    __ block_comment("@ RethrowException");

    cbuf.set_insts_mark();
    cbuf.relocate(cbuf.insts_mark(), runtime_call_Relocation::spec());

    // call OptoRuntime::rethrow_stub to get the exception handler in parent method
    __ patchable_jump((address)OptoRuntime::rethrow_stub());
  %}
  ins_pipe( pipe_jump );
%}

// ============================================================================
// Branch Instructions --- long offset versions

// Jump Direct
instruct jmpDir_long(label labl) %{
  match(Goto);
  effect(USE labl);

  ins_cost(300);
  format %{ "JMP    $labl #@jmpDir_long" %}

  ins_encode %{
    Label* L = $labl$$label;
    __ jmp_far(*L);
  %}

  ins_pipe( pipe_jump );
  //ins_pc_relative(1);
%}

// Jump Direct Conditional - Label defines a relative address from Jcc+1
instruct  jmpLoopEnd_long(cmpOp cop, mRegI src1, mRegI src2, label labl) %{
  match(CountedLoopEnd cop (CmpI src1 src2));
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop  $src1, $src2,  $labl\t# Loop end @ jmpLoopEnd_long" %}
  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label*     L = $labl$$label;
    int     flag = $cop$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      case 0x03: //above
        __ blt_long(op2, op1, *L, true /* signed */);
        break;
      case 0x04: //above_equal
        __ bge_long(op1, op2, *L, true /* signed */);
        break;
      case 0x05: //below
        __ blt_long(op1, op2, *L, true /* signed */);
        break;
      case 0x06: //below_equal
        __ bge_long(op2, op1, *L, true /* signed */);
        break;
      default:
        Unimplemented();
    }
  %}
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}

instruct  jmpLoopEnd_reg_immI_long(cmpOp cop, mRegI src1, immI src2, label labl) %{
  match(CountedLoopEnd cop (CmpI src1 src2));
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop  $src1, $src2,  $labl\t# Loop end @ jmpLoopEnd_reg_immI_long" %}
  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = AT;
    Label*     L = $labl$$label;
    int     flag = $cop$$cmpcode;

    __ li(op2, $src2$$constant);

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      case 0x03: //above
        __ blt_long(op2, op1, *L, true /* signed */);
        break;
      case 0x04: //above_equal
        __ bge_long(op1, op2, *L, true /* signed */);
        break;
      case 0x05: //below
        __ blt_long(op1, op2, *L, true /* signed */);
        break;
      case 0x06: //below_equal
        __ bge_long(op2, op1, *L, true /* signed */);
        break;
      default:
        Unimplemented();
    }
  %}
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}


// This match pattern is created for StoreIConditional since I cannot match IfNode without a RegFlags!
instruct jmpCon_flags_long(cmpOp cop, FlagsReg cr, label labl) %{
  match(If cop cr);
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop    $labl  #LoongArch uses T0 as equivalent to eflag @jmpCon_flags_long" %}

  ins_encode %{
    Label*    L =  $labl$$label;
    switch($cop$$cmpcode) {
      case 0x01: //equal
        __ bne_long($cr$$Register, R0, *L);
        break;
      case 0x02: //not equal
        __ beq_long($cr$$Register, R0, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}

// Conditional jumps
instruct branchConP_0_long(cmpOpU cmp, mRegP op1, immP_0 zero, label labl) %{
  match(If cmp (CmpP op1 zero));
  effect(USE labl);

  ins_cost(180);
  format %{ "b$cmp   $op1, R0, $labl #@branchConP_0_long" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label*    L  = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConN2P_0_long(cmpOpU cmp, mRegN op1, immP_0 zero, label labl) %{
  match(If cmp (CmpP (DecodeN op1) zero));
  predicate(Universe::narrow_oop_base() == NULL && Universe::narrow_oop_shift() == 0);
  effect(USE labl);

  ins_cost(180);
  format %{ "b$cmp   $op1, R0, $labl #@branchConN2P_0_long" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label*    L  = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConP_long(cmpOpU cmp, mRegP op1, mRegP op2, label labl) %{
  match(If cmp (CmpP op1 op2));
//  predicate(can_branch_register(_kids[0]->_leaf, _kids[1]->_leaf));
  effect(USE labl);

  ins_cost(200);
  format %{ "b$cmp   $op1, $op2, $labl #@branchConP_long" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = $op2$$Register;
    Label*    L  = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      case 0x03: //above
        __ blt_long(op2, op1, *L, false /* unsigned */);
        break;
      case 0x04: //above_equal
        __ bge_long(op1, op2, *L, false /* unsigned */);
        break;
      case 0x05: //below
        __ blt_long(op1, op2, *L, false /* unsigned */);
        break;
      case 0x06: //below_equal
        __ bge_long(op2, op1, *L, false /* unsigned */);
       break;
      default:
          Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct cmpN_null_branch_long(cmpOp cmp, mRegN op1, immN_0 null, label labl) %{
  match(If cmp (CmpN op1 null));
  effect(USE labl);

  ins_cost(180);
  format %{ "CMP    $op1,0\t! compressed ptr\n\t"
            "BP$cmp   $labl @ cmpN_null_branch_long" %}
  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label*    L  = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
    case 0x01: //equal
      __ beq_long(op1, op2, *L);
      break;
    case 0x02: //not_equal
      __ bne_long(op1, op2, *L);
      break;
    default:
          Unimplemented();
    }
  %}
//TODO: pipe_branchP or create pipe_branchN LEE
  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct cmpN_reg_branch_long(cmpOp cmp, mRegN op1, mRegN op2, label labl) %{
  match(If cmp (CmpN op1 op2));
  effect(USE labl);

  ins_cost(180);
  format %{ "CMP    $op1,$op2\t! compressed ptr\n\t"
            "BP$cmp   $labl @ cmpN_reg_branch_long" %}
  ins_encode %{
    Register op1_reg = $op1$$Register;
    Register op2_reg = $op2$$Register;
    Label*    L  = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
    case 0x01: //equal
      __ beq_long(op1_reg, op2_reg, *L);
      break;
    case 0x02: //not_equal
      __ bne_long(op1_reg, op2_reg, *L);
      break;
    case 0x03: //above
      __ blt_long(op2_reg, op1_reg, *L, false /* unsigned */);
      break;
    case 0x04: //above_equal
      __ bge_long(op1_reg, op2_reg, *L, false /* unsigned */);
      break;
    case 0x05: //below
      __ blt_long(op1_reg, op2_reg, *L, false /* unsigned */);
      break;
    case 0x06: //below_equal
      __ bge_long(op2_reg, op1_reg, *L, false /* unsigned */);
      break;
    default:
      Unimplemented();
    }
  %}
  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConIU_reg_reg_long(cmpOpU cmp, mRegI src1, mRegI src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_reg_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label*     L = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      case 0x03: //above
        __ blt_long(op2, op1, *L, false /* unsigned */);
        break;
      case 0x04: //above_equal
        __ bge_long(op1, op2, *L, false /* unsigned */);
        break;
      case 0x05: //below
        __ blt_long(op1, op2, *L, false /* unsigned */);
        break;
      case 0x06: //below_equal
        __ bge_long(op2, op1, *L, false /* unsigned */);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConIU_reg_imm_long(cmpOpU cmp, mRegI src1, immI src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_imm_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label*     L = $labl$$label;
    int     flag = $cmp$$cmpcode;

    __ li(AT, val);
    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, AT, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, AT, *L);
        break;
      case 0x03: //above
        __ blt_long(AT, op1, *L, false /* unsigned */);
        break;
      case 0x04: //above_equal
        __ bge_long(op1, AT, *L, false /* unsigned */);
        break;
      case 0x05: //below
        __ blt_long(op1, AT, *L, false /* unsigned */);
        break;
      case 0x06: //below_equal
        __ bge_long(AT, op1, *L, false /* unsigned */);
       break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConI_reg_reg_long(cmpOp cmp, mRegI src1, mRegI src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_reg_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label*     L = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, op2, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, op2, *L);
        break;
      case 0x03: //above
        __ blt_long(op2, op1, *L, true /* signed */);
        break;
      case 0x04: //above_equal
        __ bge_long(op1, op2, *L, true /* signed */);
        break;
      case 0x05: //below
        __ blt_long(op1, op2, *L, true /* signed */);
        break;
      case 0x06: //below_equal
        __ bge_long(op2, op1, *L, true /* signed */);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConI_reg_immI_0_long(cmpOp cmp, mRegI src1, immI_0 src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(170);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_immI_0_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Label*     L =  $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, R0, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, R0, *L);
        break;
      case 0x03: //greater
        __ blt_long(R0, op1, *L, true /* signed */);
        break;
      case 0x04: //greater_equal
        __ bge_long(op1, R0, *L, true /* signed */);
        break;
      case 0x05: //less
        __ blt_long(op1, R0, *L, true /* signed */);
        break;
      case 0x06: //less_equal
        __ bge_long(R0, op1, *L, true /* signed */);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConI_reg_imm_long(cmpOp cmp, mRegI src1, immI src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(200);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_imm_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label*     L =  $labl$$label;
    int     flag = $cmp$$cmpcode;

    __ li(AT, val);
    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, AT, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, AT, *L);
        break;
      case 0x03: //greater
        __ blt_long(AT, op1, *L, true /* signed */);
        break;
      case 0x04: //greater_equal
        __ bge_long(op1, AT, *L, true /* signed */);
        break;
      case 0x05: //less
        __ blt_long(op1, AT, *L, true /* signed */);
        break;
      case 0x06: //less_equal
        __ bge_long(AT, op1, *L, true /* signed */);
        break;
      default:
          Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConIU_reg_immI_0_long(cmpOpU cmp, mRegI src1, immI_0 zero, label labl) %{
  match( If cmp (CmpU src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConIU_reg_immI_0_long" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Label*     L = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(op1, R0, *L);
        break;
      case 0x02: //not_equal
        __ bne_long(op1, R0, *L);
        break;
      case 0x03: //above
        __ bne_long(R0, op1, *L);
        break;
      case 0x04: //above_equal
        __ beq_long(R0, R0, *L);
        break;
      case 0x05: //below
        return;
        break;
      case 0x06: //below_equal
        __ beq_long(op1, R0, *L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConL_regL_regL_long(cmpOp cmp, mRegLorI2L src1, mRegLorI2L src2, label labl) %{
  match( If cmp (CmpL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConL_regL_regL_long" %}
  ins_cost(250);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = as_Register($src2$$reg);

    Label*   target = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x02: //not_equal
        __ bne_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x03: //greater
        __ blt_long(opr2_reg, opr1_reg, *target, true /* signed */);
        break;

      case 0x04: //greater_equal
        __ bge_long(opr1_reg, opr2_reg, *target, true /* signed */);
        break;

      case 0x05: //less
        __ blt_long(opr1_reg, opr2_reg, *target, true /* signed */);
        break;

      case 0x06: //less_equal
        __ bge_long(opr2_reg, opr1_reg, *target, true /* signed */);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConUL_regL_regL_long(cmpOp cmp, mRegLorI2L src1, mRegLorI2L src2, label labl) %{
  match( If cmp (CmpUL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConUL_regL_regL_long" %}
  ins_cost(250);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = as_Register($src2$$reg);

    Label*   target = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x02: //not_equal
        __ bne_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x03: //greater
        __ blt_long(opr2_reg, opr1_reg, *target, false /* signed */);
        break;

      case 0x04: //greater_equal
        __ bge_long(opr1_reg, opr2_reg, *target, false /* signed */);
        break;

      case 0x05: //less
        __ blt_long(opr1_reg, opr2_reg, *target, false /* signed */);
        break;

      case 0x06: //less_equal
        __ bge_long(opr2_reg, opr1_reg, *target, false /* signed */);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConL_regL_immL_0_long(cmpOp cmp, mRegL src1, immL_0 zero, label labl) %{
  match( If cmp (CmpL src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConL_regL_immL_0_long" %}
  ins_cost(150);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = R0;

    Label*   target = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x02: //not_equal
        __ bne_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x03: //greater
        __ blt_long(opr2_reg, opr1_reg, *target, true /* signed */);
        break;

      case 0x04: //greater_equal
        __ bge_long(opr1_reg, opr2_reg, *target, true /* signed */);
        break;

      case 0x05: //less
        __ blt_long(opr1_reg, opr2_reg, *target, true /* signed */);
        break;

      case 0x06: //less_equal
        __ bge_long(opr2_reg, opr1_reg, *target, true /* signed */);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConUL_regL_immL_0_long(cmpOp cmp, mRegL src1, immL_0 zero, label labl) %{
  match( If cmp (CmpUL src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConUL_regL_immL_0_long" %}
  ins_cost(150);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = R0;

    Label*   target = $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ beq_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x02: //not_equal
        __ bne_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x03: //greater
        __ blt_long(opr2_reg, opr1_reg, *target, false /* signed */);
        break;

      case 0x04: //greater_equal
        __ bge_long(opr1_reg, opr2_reg, *target, false /* signed */);
        break;

      case 0x05: //less
        __ blt_long(opr1_reg, opr2_reg, *target, false /* signed */);
        break;

      case 0x06: //less_equal
        __ bge_long(opr2_reg, opr1_reg, *target, false /* signed */);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConL_regL_immL_long(cmpOp cmp, mRegL src1, immL src2, label labl) %{
  match( If cmp (CmpL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConL_regL_immL_long" %}
  ins_cost(180);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = AT;

    Label*   target = $labl$$label;
    int     flag = $cmp$$cmpcode;

    __ li(opr2_reg, $src2$$constant);

    switch(flag) {
      case 0x01: //equal
        __ beq_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x02: //not_equal
        __ bne_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x03: //greater
        __ blt_long(opr2_reg, opr1_reg, *target, true /* signed */);
        break;

      case 0x04: //greater_equal
        __ bge_long(opr1_reg, opr2_reg, *target, true /* signed */);
        break;

      case 0x05: //less
        __ blt_long(opr1_reg, opr2_reg, *target, true /* signed */);
        break;

      case 0x06: //less_equal
        __ bge_long(opr2_reg, opr1_reg, *target, true /* signed */);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConUL_regL_immL_long(cmpOp cmp, mRegL src1, immL src2, label labl) %{
  match( If cmp (CmpUL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConUL_regL_immL_long" %}
  ins_cost(180);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = AT;

    Label*   target = $labl$$label;
    int     flag = $cmp$$cmpcode;

    __ li(opr2_reg, $src2$$constant);

    switch(flag) {
      case 0x01: //equal
        __ beq_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x02: //not_equal
        __ bne_long(opr1_reg, opr2_reg, *target);
        break;

      case 0x03: //greater
        __ blt_long(opr2_reg, opr1_reg, *target, false /* signed */);
        break;

      case 0x04: //greater_equal
        __ bge_long(opr1_reg, opr2_reg, *target, false /* signed */);
        break;

      case 0x05: //less
        __ blt_long(opr1_reg, opr2_reg, *target, false /* signed */);
        break;

      case 0x06: //less_equal
        __ bge_long(opr2_reg, opr1_reg, *target, false /* signed */);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

//FIXME
instruct branchConF_reg_reg_long(cmpOp cmp, regF src1, regF src2, label labl) %{
  match( If cmp (CmpF src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConF_reg_reg_long" %}

  ins_encode %{
    FloatRegister reg_op1 = $src1$$FloatRegister;
    FloatRegister reg_op2 = $src2$$FloatRegister;
    Label*     L =  $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ fcmp_ceq_s(FCC0, reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      case 0x02: //not_equal
        __ fcmp_ceq_s(FCC0, reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x03: //greater
        __ fcmp_cule_s(FCC0, reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x04: //greater_equal
        __ fcmp_cult_s(FCC0, reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x05: //less
        __ fcmp_cult_s(FCC0, reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      case 0x06: //less_equal
        __ fcmp_cule_s(FCC0, reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe(pipe_slow);
%}

instruct branchConD_reg_reg_long(cmpOp cmp, regD src1, regD src2, label labl) %{
  match( If cmp (CmpD src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConD_reg_reg_long" %}

  ins_encode %{
    FloatRegister reg_op1 = $src1$$FloatRegister;
    FloatRegister reg_op2 = $src2$$FloatRegister;
    Label*     L =  $labl$$label;
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ fcmp_ceq_d(FCC0, reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      case 0x02: //not_equal
        // c_ueq_d cannot distinguish NaN from equal. Double.isNaN(Double) is implemented by 'f != f', so the use of c_ueq_d causes bugs.
        __ fcmp_ceq_d(FCC0, reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x03: //greater
        __ fcmp_cule_d(FCC0, reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x04: //greater_equal
        __ fcmp_cult_d(FCC0, reg_op1, reg_op2);
        __ bc1f_long(*L);
        break;
      case 0x05: //less
        __ fcmp_cult_d(FCC0, reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      case 0x06: //less_equal
        __ fcmp_cule_d(FCC0, reg_op1, reg_op2);
        __ bc1t_long(*L);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe(pipe_slow);
%}


// ============================================================================
// Branch Instructions -- short offset versions

// Jump Direct
instruct jmpDir_short(label labl) %{
  match(Goto);
  effect(USE labl);

  ins_cost(300);
  format %{ "JMP    $labl #@jmpDir_short" %}

  ins_encode %{
    Label &L = *($labl$$label);
    if(&L)
       __ b(L);
    else
       __ b(int(0));
  %}

    ins_pipe( pipe_jump );
    ins_pc_relative(1);
    ins_short_branch(1);
%}

// Jump Direct Conditional - Label defines a relative address from Jcc+1
instruct  jmpLoopEnd_short(cmpOp cop, mRegI src1, mRegI src2, label labl) %{
  match(CountedLoopEnd cop (CmpI src1 src2));
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop  $src1, $src2,  $labl\t# Loop end @ jmpLoopEnd_short" %}
  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cop$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      case 0x03: //above
        if (&L)
          __ blt(op2, op1, L);
        else
          __ blt(op2, op1, (int)0);
        break;
      case 0x04: //above_equal
        if (&L)
          __ bge(op1, op2, L);
        else
          __ bge(op1, op2, (int)0);
        break;
      case 0x05: //below
        if (&L)
          __ blt(op1, op2, L);
        else
          __ blt(op1, op2, (int)0);
        break;
      case 0x06: //below_equal
        if (&L)
          __ bge(op2, op1, L);
        else
          __ bge(op2, op1, (int)0);
        break;
      default:
        Unimplemented();
    }
  %}
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
  ins_short_branch(1);
%}

instruct  jmpLoopEnd_reg_immI_short(cmpOp cop, mRegI src1, immI src2, label labl) %{
  match(CountedLoopEnd cop (CmpI src1 src2));
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop  $src1, $src2,  $labl\t# Loop end @ jmpLoopEnd_reg_immI_short" %}
  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = AT;
    Label     &L = *($labl$$label);
    int     flag = $cop$$cmpcode;

    __ li(op2, $src2$$constant);

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      case 0x03: //above
        if (&L)
          __ blt(op2, op1, L);
        else
          __ blt(op2, op1, (int)0);
        break;
      case 0x04: //above_equal
        if (&L)
          __ bge(op1, op2, L);
        else
          __ bge(op1, op2, (int)0);
        break;
      case 0x05: //below
        if (&L)
          __ blt(op1, op2, L);
        else
          __ blt(op1, op2, (int)0);
        break;
      case 0x06: //below_equal
        if (&L)
          __ bge(op2, op1, L);
        else
          __ bge(op2, op1, (int)0);
        break;
      default:
        Unimplemented();
    }
  %}
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
  ins_short_branch(1);
%}


// This match pattern is created for StoreIConditional since I cannot match IfNode without a RegFlags!
instruct jmpCon_flags_short(cmpOp cop, FlagsReg cr, label labl) %{
  match(If cop cr);
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop    $labl  #LoongArch uses T0 as equivalent to eflag @jmpCon_flags_short" %}

  ins_encode %{
    Label    &L =  *($labl$$label);
    switch($cop$$cmpcode) {
      case 0x01: //equal
        if (&L)
          __ bnez($cr$$Register, L);
        else
          __ bnez($cr$$Register, (int)0);
        break;
      case 0x02: //not equal
        if (&L)
          __ beqz($cr$$Register, L);
        else
          __ beqz($cr$$Register, (int)0);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pipe( pipe_jump );
  ins_pc_relative(1);
  ins_short_branch(1);
%}

// Conditional jumps
instruct branchConP_0_short(cmpOpU cmp, mRegP op1, immP_0 zero, label labl) %{
  match(If cmp (CmpP op1 zero));
  effect(USE labl);

  ins_cost(180);
  format %{ "b$cmp   $op1, R0, $labl #@branchConP_0_short" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beqz(op1, L);
        else
          __ beqz(op1, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bnez(op1, L);
        else
          __ bnez(op1, (int)0);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConN2P_0_short(cmpOpU cmp, mRegN op1, immP_0 zero, label labl) %{
  match(If cmp (CmpP (DecodeN op1) zero));
  predicate(Universe::narrow_oop_base() == NULL && Universe::narrow_oop_shift() == 0);
  effect(USE labl);

  ins_cost(180);
  format %{ "b$cmp   $op1, R0, $labl #@branchConN2P_0_short" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        if (&L)
          __ beqz(op1, L);
        else
          __ beqz(op1, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bnez(op1, L);
        else
          __ bnez(op1, (int)0);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


instruct branchConP_short(cmpOpU cmp, mRegP op1, mRegP op2, label labl) %{
  match(If cmp (CmpP op1 op2));
//  predicate(can_branch_register(_kids[0]->_leaf, _kids[1]->_leaf));
  effect(USE labl);

  ins_cost(200);
  format %{ "b$cmp   $op1, $op2, $labl #@branchConP_short" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = $op2$$Register;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      case 0x03: //above
        if (&L)
          __ bltu(op2, op1, L);
        else
          __ bltu(op2, op1, (int)0);
        break;
      case 0x04: //above_equal
        if (&L)
          __ bgeu(op1, op2, L);
        else
          __ bgeu(op1, op2, (int)0);
        break;
      case 0x05: //below
        if (&L)
          __ bltu(op1, op2, L);
        else
          __ bltu(op1, op2, (int)0);
        break;
      case 0x06: //below_equal
        if (&L)
          __ bgeu(op2, op1, L);
        else
          __ bgeu(op2, op1, (int)0);
       break;
      default:
          Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct cmpN_null_branch_short(cmpOp cmp, mRegN op1, immN_0 null, label labl) %{
  match(If cmp (CmpN op1 null));
  effect(USE labl);

  ins_cost(180);
  format %{ "CMP    $op1,0\t! compressed ptr\n\t"
            "BP$cmp   $labl @ cmpN_null_branch_short" %}
  ins_encode %{
    Register op1 = $op1$$Register;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
    case 0x01: //equal
      if (&L)
        __ beqz(op1, L);
      else
        __ beqz(op1, (int)0);
      break;
    case 0x02: //not_equal
      if (&L)
        __ bnez(op1, L);
      else
        __ bnez(op1, (int)0);
      break;
    default:
          Unimplemented();
    }
  %}
//TODO: pipe_branchP or create pipe_branchN LEE
  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct cmpN_reg_branch_short(cmpOp cmp, mRegN op1, mRegN op2, label labl) %{
  match(If cmp (CmpN op1 op2));
  effect(USE labl);

  ins_cost(180);
  format %{ "CMP    $op1,$op2\t! compressed ptr\n\t"
            "BP$cmp   $labl @ cmpN_reg_branch_short" %}
  ins_encode %{
    Register op1_reg = $op1$$Register;
    Register op2_reg = $op2$$Register;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
    case 0x01: //equal
      if (&L)
        __ beq(op1_reg, op2_reg, L);
      else
        __ beq(op1_reg, op2_reg, (int)0);
      break;
    case 0x02: //not_equal
      if (&L)
        __ bne(op1_reg, op2_reg, L);
      else
        __ bne(op1_reg, op2_reg, (int)0);
      break;
    case 0x03: //above
      if (&L)
        __ bltu(op2_reg, op1_reg, L);
      else
        __ bltu(op2_reg, op1_reg, (int)0);
      break;
    case 0x04: //above_equal
      if (&L)
        __ bgeu(op1_reg, op2_reg, L);
      else
        __ bgeu(op1_reg, op2_reg, (int)0);
      break;
    case 0x05: //below
      if (&L)
        __ bltu(op1_reg, op2_reg, L);
      else
        __ bltu(op1_reg, op2_reg, (int)0);
      break;
    case 0x06: //below_equal
      if (&L)
        __ bgeu(op2_reg, op1_reg, L);
      else
        __ bgeu(op2_reg, op1_reg, (int)0);
      break;
    default:
      Unimplemented();
    }
  %}
  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConIU_reg_reg_short(cmpOpU cmp, mRegI src1, mRegI src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_reg_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      case 0x03: //above
        if (&L)
          __ bltu(op2, op1, L);
        else
          __ bltu(op2, op1, (int)0);
        break;
      case 0x04: //above_equal
        if (&L)
          __ bgeu(op1, op2, L);
        else
          __ bgeu(op1, op2, (int)0);
        break;
      case 0x05: //below
        if (&L)
           __ bltu(op1, op2, L);
        else
           __ bltu(op1, op2, (int)0);
        break;
      case 0x06: //below_equal
        if (&L)
          __ bgeu(op2, op1, L);
        else
          __ bgeu(op2, op1, (int)0);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


instruct branchConIU_reg_imm_short(cmpOpU cmp, mRegI src1, immI src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_imm_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    __ li(AT, val);
    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, AT, L);
        else
          __ beq(op1, AT, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, AT, L);
        else
          __ bne(op1, AT, (int)0);
        break;
      case 0x03: //above
        if (&L)
          __ bltu(AT, op1, L);
        else
          __ bltu(AT, op1, (int)0);
        break;
      case 0x04: //above_equal
        if (&L)
          __ bgeu(op1, AT, L);
        else
          __ bgeu(op1, AT, (int)0);
        break;
      case 0x05: //below
        if (&L)
           __ bltu(op1, AT, L);
        else
           __ bltu(op1, AT, (int)0);
        break;
      case 0x06: //below_equal
        if (&L)
          __ bgeu(AT, op1, L);
        else
          __ bgeu(AT, op1, (int)0);
       break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConI_reg_reg_short(cmpOp cmp, mRegI src1, mRegI src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_reg_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, op2, L);
        else
          __ beq(op1, op2, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, op2, L);
        else
          __ bne(op1, op2, (int)0);
        break;
      case 0x03: //above
        if (&L)
          __ blt(op2, op1, L);
        else
          __ blt(op2, op1, (int)0);
        break;
      case 0x04: //above_equal
        if (&L)
          __ bge(op1, op2, L);
        else
          __ bge(op1, op2, (int)0);
        break;
      case 0x05: //below
        if (&L)
          __ blt(op1, op2, L);
        else
          __ blt(op1, op2, (int)0);
        break;
      case 0x06: //below_equal
        if (&L)
          __ bge(op2, op1, L);
        else
          __ bge(op2, op1, (int)0);
       break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConI_reg_immI_0_short(cmpOp cmp, mRegI src1, immI_0 src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(170);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_immI_0_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beqz(op1, L);
        else
          __ beqz(op1, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bnez(op1, L);
        else
          __ bnez(op1, (int)0);
        break;
      case 0x03: //greater
        if (&L)
          __ blt(R0, op1, L);
        else
          __ blt(R0, op1, (int)0);
        break;
      case 0x04: //greater_equal
        if (&L)
          __ bge(op1, R0, L);
        else
          __ bge(op1, R0, (int)0);
        break;
      case 0x05: //less
        if (&L)
          __ blt(op1, R0, L);
        else
          __ blt(op1, R0, (int)0);
        break;
      case 0x06: //less_equal
        if (&L)
          __ bge(R0, op1, L);
        else
          __ bge(R0, op1, (int)0);
       break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


instruct branchConI_reg_imm_short(cmpOp cmp, mRegI src1, immI src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(200);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_imm_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    __ li(AT, val);
    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beq(op1, AT, L);
        else
          __ beq(op1, AT, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bne(op1, AT, L);
        else
          __ bne(op1, AT, (int)0);
        break;
      case 0x03: //greater
        if (&L)
          __ blt(AT, op1, L);
        else
          __ blt(AT, op1, (int)0);
        break;
      case 0x04: //greater_equal
        if (&L)
          __ bge(op1, AT, L);
        else
          __ bge(op1, AT, (int)0);
        break;
      case 0x05: //less
        if (&L)
          __ blt(op1, AT, L);
        else
          __ blt(op1, AT, (int)0);
        break;
      case 0x06: //less_equal
        if (&L)
          __ bge(AT, op1, L);
        else
          __ bge(AT, op1, (int)0);
       break;
      default:
          Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConIU_reg_immI_0_short(cmpOpU cmp, mRegI src1, immI_0 zero, label labl) %{
  match( If cmp (CmpU src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConIU_reg_immI_0_short" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&L)
          __ beqz(op1, L);
        else
          __ beqz(op1, (int)0);
        break;
      case 0x02: //not_equal
        if (&L)
          __ bnez(op1, L);
        else
          __ bnez(op1, (int)0);
        break;
      case 0x03: //above
        if (&L)
          __ bnez(op1, L);
        else
          __ bnez(op1, (int)0);
        break;
      case 0x04: //above_equal
        if (&L)
          __ b(L);
        else
          __ b((int)0);
        break;
      case 0x05: //below
        return;
        break;
      case 0x06: //below_equal
        if (&L)
          __ beqz(op1, L);
        else
          __ beqz(op1, (int)0);
        break;
      default:
        Unimplemented();
    }
    %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}


instruct branchConL_regL_regL_short(cmpOp cmp, mRegLorI2L src1, mRegLorI2L src2, label labl) %{
  match( If cmp (CmpL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConL_regL_regL_short" %}
  ins_cost(250);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = as_Register($src2$$reg);

    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&target)
          __ beq(opr1_reg, opr2_reg, target);
        else
          __ beq(opr1_reg, opr2_reg, (int)0);
        break;
      case 0x02: //not_equal
        if(&target)
          __ bne(opr1_reg, opr2_reg, target);
        else
          __ bne(opr1_reg, opr2_reg, (int)0);
        break;
      case 0x03: //greater
        if (&target)
          __ blt(opr2_reg, opr1_reg, target);
        else
          __ blt(opr2_reg, opr1_reg, (int)0);
        break;
      case 0x04: //greater_equal
        if (&target)
          __ bge(opr1_reg, opr2_reg, target);
        else
          __ bge(opr1_reg, opr2_reg, (int)0);
        break;
      case 0x05: //less
        if (&target)
          __ blt(opr1_reg, opr2_reg, target);
        else
          __ blt(opr1_reg, opr2_reg, (int)0);
        break;
      case 0x06: //less_equal
        if (&target)
          __ bge(opr2_reg, opr1_reg, target);
        else
          __ bge(opr2_reg, opr1_reg, (int)0);
        break;
      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConUL_regL_regL_short(cmpOp cmp, mRegLorI2L src1, mRegLorI2L src2, label labl) %{
  match( If cmp (CmpUL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConUL_regL_regL_short" %}
  ins_cost(250);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = as_Register($src2$$reg);

    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&target)
          __ beq(opr1_reg, opr2_reg, target);
        else
          __ beq(opr1_reg, opr2_reg, (int)0);
        break;
      case 0x02: //not_equal
        if(&target)
          __ bne(opr1_reg, opr2_reg, target);
        else
          __ bne(opr1_reg, opr2_reg, (int)0);
        break;
      case 0x03: //greater
        if (&target)
          __ bltu(opr2_reg, opr1_reg, target);
        else
          __ bltu(opr2_reg, opr1_reg, (int)0);
        break;
      case 0x04: //greater_equal
        if (&target)
          __ bgeu(opr1_reg, opr2_reg, target);
        else
          __ bgeu(opr1_reg, opr2_reg, (int)0);
        break;
      case 0x05: //less
        if (&target)
          __ bltu(opr1_reg, opr2_reg, target);
        else
          __ bltu(opr1_reg, opr2_reg, (int)0);
        break;
      case 0x06: //less_equal
        if (&target)
          __ bgeu(opr2_reg, opr1_reg, target);
        else
          __ bgeu(opr2_reg, opr1_reg, (int)0);
        break;
      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConL_regL_immL_0_short(cmpOp cmp, mRegL src1, immL_0 zero, label labl) %{
  match( If cmp (CmpL src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConL_regL_immL_0_short" %}
  ins_cost(150);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&target)
           __ beqz(opr1_reg, target);
        else
           __ beqz(opr1_reg, int(0));
        break;

      case 0x02: //not_equal
        if (&target)
           __ bnez(opr1_reg, target);
        else
           __ bnez(opr1_reg, (int)0);
        break;

      case 0x03: //greater
        if (&target)
           __ blt(R0, opr1_reg, target);
        else
           __ blt(R0, opr1_reg, (int)0);
       break;

      case 0x04: //greater_equal
        if (&target)
           __ bge(opr1_reg, R0, target);
        else
           __ bge(opr1_reg, R0, (int)0);
        break;

      case 0x05: //less
        if (&target)
           __ blt(opr1_reg, R0, target);
        else
           __ blt(opr1_reg, R0, (int)0);
        break;

      case 0x06: //less_equal
        if (&target)
           __ bge(R0, opr1_reg, target);
        else
           __ bge(R0, opr1_reg, int(0));
        break;

      default:
          Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConUL_regL_immL_0_short(cmpOp cmp, mRegL src1, immL_0 zero, label labl) %{
  match( If cmp (CmpUL src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConUL_regL_immL_0_short" %}
  ins_cost(150);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        if (&target)
           __ beqz(opr1_reg, target);
        else
           __ beqz(opr1_reg, int(0));
        break;

      case 0x02: //not_equal
        if (&target)
           __ bnez(opr1_reg, target);
        else
           __ bnez(opr1_reg, (int)0);
        break;

      case 0x03: //greater
        if (&target)
           __ bltu(R0, opr1_reg, target);
        else
           __ bltu(R0, opr1_reg, (int)0);
       break;

      case 0x04: //greater_equal
        if (&target)
           __ bgeu(opr1_reg, R0, target);
        else
           __ bgeu(opr1_reg, R0, (int)0);
        break;

      case 0x05: //less
        if (&target)
           __ bltu(opr1_reg, R0, target);
        else
           __ bltu(opr1_reg, R0, (int)0);
        break;

      case 0x06: //less_equal
        if (&target)
           __ bgeu(R0, opr1_reg, target);
        else
           __ bgeu(R0, opr1_reg, int(0));
        break;

      default:
          Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConL_regL_immL_short(cmpOp cmp, mRegL src1, immL src2, label labl) %{
  match( If cmp (CmpL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConL_regL_immL_short" %}
  ins_cost(180);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = AT;

    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    __ li(opr2_reg, $src2$$constant);

    switch(flag) {
      case 0x01: //equal
        if (&target)
          __ beq(opr1_reg, opr2_reg, target);
        else
          __ beq(opr1_reg, opr2_reg, (int)0);
        break;

      case 0x02: //not_equal
        if(&target)
          __ bne(opr1_reg, opr2_reg, target);
        else
          __ bne(opr1_reg, opr2_reg, (int)0);
        break;

      case 0x03: //greater
        if (&target)
          __ blt(opr2_reg, opr1_reg, target);
        else
          __ blt(opr2_reg, opr1_reg, (int)0);
        break;

      case 0x04: //greater_equal
        if (&target)
          __ bge(opr1_reg, opr2_reg, target);
        else
          __ bge(opr1_reg, opr2_reg, (int)0);
        break;

      case 0x05: //less
        if (&target)
          __ blt(opr1_reg, opr2_reg, target);
        else
          __ blt(opr1_reg, opr2_reg, (int)0);
        break;

      case 0x06: //less_equal
        if (&target)
          __ bge(opr2_reg, opr1_reg, target);
        else
          __ bge(opr2_reg, opr1_reg, (int)0);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

instruct branchConUL_regL_immL_short(cmpOp cmp, mRegL src1, immL src2, label labl) %{
  match( If cmp (CmpUL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConUL_regL_immL_short" %}
  ins_cost(180);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = AT;

    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    __ li(opr2_reg, $src2$$constant);

    switch(flag) {
      case 0x01: //equal
        if (&target)
          __ beq(opr1_reg, opr2_reg, target);
        else
          __ beq(opr1_reg, opr2_reg, (int)0);
        break;

      case 0x02: //not_equal
        if(&target)
          __ bne(opr1_reg, opr2_reg, target);
        else
          __ bne(opr1_reg, opr2_reg, (int)0);
        break;

      case 0x03: //greater
        if (&target)
          __ bltu(opr2_reg, opr1_reg, target);
        else
          __ bltu(opr2_reg, opr1_reg, (int)0);
        break;

      case 0x04: //greater_equal
        if (&target)
          __ bgeu(opr1_reg, opr2_reg, target);
        else
          __ bgeu(opr1_reg, opr2_reg, (int)0);
        break;

      case 0x05: //less
        if (&target)
          __ bltu(opr1_reg, opr2_reg, target);
        else
          __ bltu(opr1_reg, opr2_reg, (int)0);
        break;

      case 0x06: //less_equal
        if (&target)
          __ bgeu(opr2_reg, opr1_reg, target);
        else
          __ bgeu(opr2_reg, opr1_reg, (int)0);
        break;

      default:
        Unimplemented();
    }
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
  ins_short_branch(1);
%}

//FIXME
instruct branchConF_reg_reg_short(cmpOp cmp, regF src1, regF src2, label labl) %{
  match( If cmp (CmpF src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConF_reg_reg_short" %}

  ins_encode %{
    FloatRegister reg_op1 = $src1$$FloatRegister;
    FloatRegister reg_op2 = $src2$$FloatRegister;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ fcmp_ceq_s(FCC0, reg_op1, reg_op2);
        if (&L)
          __ bcnez(FCC0, L);
        else
          __ bcnez(FCC0, (int)0);
        break;
      case 0x02: //not_equal
        __ fcmp_ceq_s(FCC0, reg_op1, reg_op2);
        if (&L)
          __ bceqz(FCC0, L);
        else
          __ bceqz(FCC0, (int)0);
        break;
      case 0x03: //greater
        __ fcmp_cule_s(FCC0, reg_op1, reg_op2);
        if(&L)
          __ bceqz(FCC0, L);
        else
          __ bceqz(FCC0, (int)0);
        break;
      case 0x04: //greater_equal
        __ fcmp_cult_s(FCC0, reg_op1, reg_op2);
        if(&L)
          __ bceqz(FCC0, L);
        else
          __ bceqz(FCC0, (int)0);
        break;
      case 0x05: //less
        __ fcmp_cult_s(FCC0, reg_op1, reg_op2);
        if(&L)
          __ bcnez(FCC0, L);
        else
          __ bcnez(FCC0, (int)0);
        break;
      case 0x06: //less_equal
        __ fcmp_cule_s(FCC0, reg_op1, reg_op2);
        if(&L)
          __ bcnez(FCC0, L);
        else
          __ bcnez(FCC0, (int)0);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe(pipe_fpu_branch);
  ins_short_branch(1);
%}

instruct branchConD_reg_reg_short(cmpOp cmp, regD src1, regD src2, label labl) %{
  match( If cmp (CmpD src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConD_reg_reg_short" %}

  ins_encode %{
    FloatRegister reg_op1 = $src1$$FloatRegister;
    FloatRegister reg_op2 = $src2$$FloatRegister;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag) {
      case 0x01: //equal
        __ fcmp_ceq_d(FCC0, reg_op1, reg_op2);
        if (&L)
          __ bcnez(FCC0, L);
        else
          __ bcnez(FCC0, (int)0);
        break;
      case 0x02: //not_equal
        // c_ueq_d cannot distinguish NaN from equal. Double.isNaN(Double) is implemented by 'f != f', so the use of c_ueq_d causes bugs.
        __ fcmp_ceq_d(FCC0, reg_op1, reg_op2);
        if (&L)
          __ bceqz(FCC0, L);
        else
          __ bceqz(FCC0, (int)0);
        break;
      case 0x03: //greater
        __ fcmp_cule_d(FCC0, reg_op1, reg_op2);
        if(&L)
          __ bceqz(FCC0, L);
        else
          __ bceqz(FCC0, (int)0);
        break;
      case 0x04: //greater_equal
        __ fcmp_cult_d(FCC0, reg_op1, reg_op2);
        if(&L)
          __ bceqz(FCC0, L);
        else
          __ bceqz(FCC0, (int)0);
        break;
      case 0x05: //less
        __ fcmp_cult_d(FCC0, reg_op1, reg_op2);
        if(&L)
          __ bcnez(FCC0, L);
        else
          __ bcnez(FCC0, (int)0);
        break;
      case 0x06: //less_equal
        __ fcmp_cule_d(FCC0, reg_op1, reg_op2);
        if(&L)
          __ bcnez(FCC0, L);
        else
          __ bcnez(FCC0, (int)0);
        break;
      default:
        Unimplemented();
    }
  %}

  ins_pc_relative(1);
  ins_pipe(pipe_fpu_branch);
  ins_short_branch(1);
%}

// =================== End of branch instructions ==========================

// Call Runtime Instruction
instruct CallRuntimeDirect(method meth) %{
  match(CallRuntime );
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL,runtime #@CallRuntimeDirect" %}
  ins_encode( Java_To_Runtime( meth ) );
  ins_pipe( pipe_slow );
  ins_alignment(4);
%}



//------------------------MemBar Instructions-------------------------------
//Memory barrier flavors

instruct membar_acquire() %{
  match(MemBarAcquire);
  ins_cost(400);

  format %{ "MEMBAR-acquire @ membar_acquire" %}
  ins_encode %{
    __ membar(Assembler::Membar_mask_bits(__ LoadLoad|__ LoadStore));
  %}
  ins_pipe(empty);
%}

instruct load_fence() %{
  match(LoadFence);
  ins_cost(400);

  format %{ "MEMBAR @ load_fence" %}
  ins_encode %{
    __ membar(Assembler::Membar_mask_bits(__ LoadLoad|__ LoadStore));
  %}
  ins_pipe(pipe_slow);
%}

instruct membar_acquire_lock()
%{
  match(MemBarAcquireLock);
  ins_cost(0);

  size(0);
  format %{ "MEMBAR-acquire (acquire as part of CAS in prior FastLock so empty encoding) @ membar_acquire_lock" %}
  ins_encode();
  ins_pipe(empty);
%}

instruct membar_release() %{
  match(MemBarRelease);
  ins_cost(400);

  format %{ "MEMBAR-release @ membar_release" %}

  ins_encode %{
    // Attention: DO NOT DELETE THIS GUY!
    __ membar(Assembler::Membar_mask_bits(__ LoadStore|__ StoreStore));
  %}

  ins_pipe(pipe_slow);
%}

instruct store_fence() %{
  match(StoreFence);
  ins_cost(400);

  format %{ "MEMBAR @ store_fence" %}

  ins_encode %{
    __ membar(Assembler::Membar_mask_bits(__ LoadStore|__ StoreStore));
  %}

  ins_pipe(pipe_slow);
%}

instruct membar_release_lock()
%{
  match(MemBarReleaseLock);
  ins_cost(0);

  size(0);
  format %{ "MEMBAR-release-lock (release in FastUnlock so empty) @ membar_release_lock" %}
  ins_encode();
  ins_pipe(empty);
%}


instruct membar_volatile() %{
  match(MemBarVolatile);
  ins_cost(400);

  format %{ "MEMBAR-volatile" %}
  ins_encode %{
    if( !os::is_MP() ) return;     // Not needed on single CPU
    __ membar(__ StoreLoad);

  %}
  ins_pipe(pipe_slow);
%}

instruct unnecessary_membar_volatile() %{
  match(MemBarVolatile);
  predicate(Matcher::post_store_load_barrier(n));
  ins_cost(0);

  size(0);
  format %{ "MEMBAR-volatile (unnecessary so empty encoding) @ unnecessary_membar_volatile" %}
  ins_encode( );
  ins_pipe(empty);
%}

instruct membar_storestore() %{
  match(MemBarStoreStore);

  ins_cost(400);
  format %{ "MEMBAR-storestore @ membar_storestore" %}
  ins_encode %{
    __ membar(__ StoreStore);
  %}
  ins_pipe(empty);
%}

//----------Move Instructions--------------------------------------------------
instruct castX2P(mRegP dst, mRegL src) %{
  match(Set dst (CastX2P src));
  format %{ "castX2P  $dst, $src @ castX2P" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

  if(src != dst)
    __ move(dst, src);
  %}
  ins_cost(10);
  ins_pipe( ialu_regI_mov );
%}

instruct castP2X(mRegL dst, mRegP src ) %{
  match(Set dst (CastP2X src));

  format %{ "mov    $dst, $src\t  #@castP2X" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

  if(src != dst)
    __ move(dst, src);
  %}
  ins_pipe( ialu_regI_mov );
%}

instruct MoveF2I_reg_reg(mRegI dst, regF src) %{
  match(Set dst (MoveF2I src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveF2I   $dst, $src @ MoveF2I_reg_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);

    __ movfr2gr_s(dst, src);
  %}
  ins_pipe( pipe_slow );
%}

instruct MoveI2F_reg_reg(regF dst, mRegI src) %{
  match(Set dst (MoveI2F src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveI2F   $dst, $src @ MoveI2F_reg_reg" %}
  ins_encode %{
    Register src = as_Register($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ movgr2fr_w(dst, src);
  %}
  ins_pipe( pipe_slow );
%}

instruct MoveD2L_reg_reg(mRegL dst, regD src) %{
  match(Set dst (MoveD2L src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveD2L   $dst, $src @ MoveD2L_reg_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);

    __ movfr2gr_d(dst, src);
  %}
  ins_pipe( pipe_slow );
%}

instruct MoveL2D_reg_reg(regD dst, mRegL src) %{
  match(Set dst (MoveL2D src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveL2D   $dst, $src @ MoveL2D_reg_reg" %}
  ins_encode %{
    FloatRegister dst = as_FloatRegister($dst$$reg);
    Register src = as_Register($src$$reg);

    __ movgr2fr_d(dst, src);
  %}
  ins_pipe( pipe_slow );
%}

//----------Conditional Move---------------------------------------------------
// Conditional move
instruct cmovI_cmpI_reg_reg(mRegI dst, mRegI src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpI_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpP_reg_reg(mRegI dst, mRegI src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovI_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovI_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpN_reg_reg(mRegI dst, mRegI src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovI_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovI_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpU_reg_reg(mRegP dst, mRegP src, mRegI tmp1, mRegI tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpU tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovP_cmpU_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpU_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpF_reg_reg(mRegP dst, mRegP src, regF tmp1, regF tmp2, cmpOp cop, regD tmp3, regD tmp4) %{
  match(Set dst (CMoveP (Binary cop (CmpF tmp1 tmp2)) (Binary dst src)));
  effect(TEMP tmp3, TEMP tmp4);
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovP_cmpF_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovP_cmpF_reg_reg"
         %}

  ins_encode %{
    FloatRegister reg_op1 = $tmp1$$FloatRegister;
    FloatRegister reg_op2 = $tmp2$$FloatRegister;
    FloatRegister tmp1 = $tmp3$$FloatRegister;
    FloatRegister tmp2 = $tmp4$$FloatRegister;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, tmp1, tmp2, (MacroAssembler::CMCompare) flag, true /* is_float */);
  %}
  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpN_reg_reg(mRegP dst, mRegP src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovP_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpP_reg_reg(mRegN dst, mRegN src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovN_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpD_reg_reg(mRegP dst, mRegP src, regD tmp1, regD tmp2, cmpOp cop, regD tmp3, regD tmp4) %{
  match(Set dst (CMoveP (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  effect(TEMP tmp3, TEMP tmp4);
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovP_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovP_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    FloatRegister tmp1 = $tmp3$$FloatRegister;
    FloatRegister tmp2 = $tmp4$$FloatRegister;
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, tmp1, tmp2, (MacroAssembler::CMCompare) flag, false /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovN_cmpN_reg_reg(mRegN dst, mRegN src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovN_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovI_cmpU_reg_reg(mRegI dst, mRegI src, mRegI tmp1, mRegI tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpU tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovI_cmpU_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovI_cmpU_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpL_reg_reg(mRegI dst, mRegI src, mRegLorI2L tmp1, mRegLorI2L tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = $dst$$Register;
    Register src  = $src$$Register;
    int     flag  = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpUL_reg_reg(mRegI dst, mRegI src, mRegLorI2L tmp1, mRegLorI2L tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpUL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpUL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpUL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = $dst$$Register;
    Register src  = $src$$Register;
    int     flag  = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpL_reg_reg(mRegP dst, mRegP src, mRegLorI2L tmp1, mRegLorI2L tmp2, cmpOp cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovP_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovP_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = $dst$$Register;
    Register src  = $src$$Register;
    int     flag  = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpUL_reg_reg(mRegP dst, mRegP src, mRegLorI2L tmp1, mRegLorI2L tmp2, cmpOp cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpUL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovP_cmpUL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovP_cmpUL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = $dst$$Register;
    Register src  = $src$$Register;
    int     flag  = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpD_reg_reg(mRegI dst, mRegI src, regD tmp1, regD tmp2, cmpOp cop, regD tmp3, regD tmp4) %{
  match(Set dst (CMoveI (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  effect(TEMP tmp3, TEMP tmp4);
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    FloatRegister tmp1 = $tmp3$$FloatRegister;
    FloatRegister tmp2 = $tmp4$$FloatRegister;
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, tmp1, tmp2, (MacroAssembler::CMCompare) flag, false /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovP_cmpP_reg_reg(mRegP dst, mRegP src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovP_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpI_reg_reg(mRegP dst, mRegP src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop $tmp1,$tmp2\t @cmovP_cmpI_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpI_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpP_reg_reg(mRegL dst, mRegL src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovL_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovL_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;
    Label L;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpU_reg_reg(mRegN dst, mRegN src, mRegI tmp1, mRegI tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpU tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovN_cmpU_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpU_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpL_reg_reg(mRegN dst, mRegN src, mRegL tmp1, mRegL tmp2, cmpOp cop) %{
  match(Set dst (CMoveN (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovN_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovN_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = $dst$$Register;
    Register src  = $src$$Register;
    int     flag  = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpUL_reg_reg(mRegN dst, mRegN src, mRegL tmp1, mRegL tmp2, cmpOp cop) %{
  match(Set dst (CMoveN (Binary cop (CmpUL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovN_cmpUL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovN_cmpUL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = $dst$$Register;
    Register src  = $src$$Register;
    int     flag  = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpI_reg_reg(mRegN dst, mRegN src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop $tmp1,$tmp2\t @cmovN_cmpI_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpI_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpU_reg_reg(mRegL dst, mRegL src, mRegI tmp1, mRegI tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpU tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovL_cmpU_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovL_cmpU_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpF_reg_reg(mRegL dst, mRegL src, regF tmp1, regF tmp2, cmpOp cop, regD tmp3, regD tmp4) %{
  match(Set dst (CMoveL (Binary cop (CmpF tmp1 tmp2)) (Binary dst src)));
  effect(TEMP tmp3, TEMP tmp4);
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpF_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpF_reg_reg"
         %}

  ins_encode %{
    FloatRegister reg_op1 = $tmp1$$FloatRegister;
    FloatRegister reg_op2 = $tmp2$$FloatRegister;
    FloatRegister tmp1 = $tmp3$$FloatRegister;
    FloatRegister tmp2 = $tmp4$$FloatRegister;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, tmp1, tmp2, (MacroAssembler::CMCompare) flag, true /* is_float */);
  %}
  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpI_reg_reg(mRegL dst, mRegL src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpI_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpL_reg_reg(mRegL dst, mRegL src, mRegL tmp1, mRegL tmp2, cmpOp cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = as_Register($dst$$reg);
    Register src  = as_Register($src$$reg);
    int     flag  = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpUL_reg_reg(mRegL dst, mRegL src, mRegL tmp1, mRegL tmp2, cmpOp cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpUL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpUL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpUL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = as_Register($dst$$reg);
    Register src  = as_Register($src$$reg);
    int     flag  = $cop$$cmpcode;

    __ cmp_cmov(opr1, opr2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpN_reg_reg(mRegL dst, mRegL src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovL_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovL_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_signed */);
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovL_cmpD_reg_reg(mRegL dst, mRegL src, regD tmp1, regD tmp2, cmpOp cop, regD tmp3, regD tmp4) %{
  match(Set dst (CMoveL (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  effect(TEMP tmp3, TEMP tmp4);
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    FloatRegister tmp1 = $tmp3$$FloatRegister;
    FloatRegister tmp2 = $tmp4$$FloatRegister;
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, tmp1, tmp2, (MacroAssembler::CMCompare) flag, false /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovD_cmpD_reg_reg(regD dst, regD src, regD tmp1, regD tmp2, cmpOp cop ) %{
  match(Set dst (CMoveD (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovD_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovD_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    int flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, (MacroAssembler::CMCompare) flag, false /* is_float */);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovF_cmpI_reg_reg(regF dst, regF src, mRegI tmp1, mRegI tmp2, cmpOp cop, regF tmp3, regF tmp4) %{
  match(Set dst (CMoveF (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  effect(TEMP tmp3, TEMP tmp4);
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovF_cmpI_reg_reg\n"
             "\tCMOV  $dst, $src \t @cmovF_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister tmp1 = as_FloatRegister($tmp3$$reg);
    FloatRegister tmp2 = as_FloatRegister($tmp4$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, tmp1, tmp2, (MacroAssembler::CMCompare) flag);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovD_cmpI_reg_reg(regD dst, regD src, mRegI tmp1, mRegI tmp2, cmpOp cop, regF tmp3, regF tmp4) %{
  match(Set dst (CMoveD (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  effect(TEMP tmp3, TEMP tmp4);
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovD_cmpI_reg_reg\n"
             "\tCMOV  $dst, $src \t @cmovD_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister tmp1 = as_FloatRegister($tmp3$$reg);
    FloatRegister tmp2 = as_FloatRegister($tmp4$$reg);
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(op1, op2, dst, src, tmp1, tmp2, (MacroAssembler::CMCompare) flag);
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovD_cmpP_reg_reg(regD dst, regD src, mRegP tmp1, mRegP tmp2, cmpOp cop, regF tmp3, regF tmp4) %{
  match(Set dst (CMoveD (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  effect(TEMP tmp3, TEMP tmp4);
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovD_cmpP_reg_reg\n"
             "\tCMOV  $dst, $src \t @cmovD_cmpP_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister tmp1 = as_FloatRegister($tmp3$$reg);
    FloatRegister tmp2 = as_FloatRegister($tmp4$$reg);
    int     flag = $cop$$cmpcode;

    // Use signed comparison here, because the most significant bit of the
    // user-space virtual address must be 0.
    __ cmp_cmov(op1, op2, dst, src, tmp1, tmp2, (MacroAssembler::CMCompare) flag);
  %}

  ins_pipe( pipe_slow );
%}

//FIXME
instruct cmovI_cmpF_reg_reg(mRegI dst, mRegI src, regF tmp1, regF tmp2, cmpOp cop, regD tmp3, regD tmp4) %{
  match(Set dst (CMoveI (Binary cop (CmpF tmp1 tmp2)) (Binary dst src)));
  effect(TEMP tmp3, TEMP tmp4);
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpF_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpF_reg_reg"
         %}

  ins_encode %{
    FloatRegister reg_op1 = $tmp1$$FloatRegister;
    FloatRegister reg_op2 = $tmp2$$FloatRegister;
    FloatRegister tmp1 = $tmp3$$FloatRegister;
    FloatRegister tmp2 = $tmp4$$FloatRegister;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, tmp1, tmp2, (MacroAssembler::CMCompare) flag, true /* is_float */);
  %}
  ins_pipe( pipe_slow );
%}

instruct cmovF_cmpF_reg_reg(regF dst, regF src, regF tmp1, regF tmp2, cmpOp cop ) %{
  match(Set dst (CMoveF (Binary cop (CmpF tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovF_cmpF_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovF_cmpF_reg_reg"
         %}

  ins_encode %{
    FloatRegister reg_op1 = $tmp1$$FloatRegister;
    FloatRegister reg_op2 = $tmp2$$FloatRegister;
    FloatRegister dst = $dst$$FloatRegister;
    FloatRegister src = $src$$FloatRegister;
    int flag = $cop$$cmpcode;

    __ cmp_cmov(reg_op1, reg_op2, dst, src, (MacroAssembler::CMCompare) flag, true /* is_float */);
  %}
  ins_pipe( pipe_slow );
%}

// Manifest a CmpL result in an integer register.  Very painful.
// This is the test to avoid.
instruct cmpL3_reg_reg(mRegI dst, mRegL src1, mRegL src2) %{
  match(Set dst (CmpL3 src1 src2));
  ins_cost(1000);
  format %{ "cmpL3  $dst, $src1, $src2 @ cmpL3_reg_reg" %}
  ins_encode %{
    Register opr1 = as_Register($src1$$reg);
    Register opr2 = as_Register($src2$$reg);
    Register dst  = as_Register($dst$$reg);

    __ slt(AT, opr1, opr2);
    __ slt(dst, opr2, opr1);
    __ sub_d(dst, dst, AT);
  %}
  ins_pipe( pipe_slow );
%}

//
// less_rsult     = -1
// greater_result =  1
// equal_result   =  0
// nan_result     = -1
//
instruct cmpF3_reg_reg(mRegI dst, regF src1, regF src2) %{
  match(Set dst (CmpF3 src1 src2));
  ins_cost(1000);
  format %{ "cmpF3  $dst, $src1, $src2 @ cmpF3_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    Register dst = as_Register($dst$$reg);

    __ fcmp_clt_s(FCC0, src2, src1);
    __ fcmp_cult_s(FCC1, src1, src2);
    __ movcf2gr(dst, FCC0);
    __ movcf2gr(AT, FCC1);
    __ sub_d(dst, dst, AT);

  %}
  ins_pipe( pipe_slow );
%}

instruct cmpD3_reg_reg(mRegI dst, regD src1, regD src2) %{
  match(Set dst (CmpD3 src1 src2));
  ins_cost(1000);
  format %{ "cmpD3  $dst, $src1, $src2 @ cmpD3_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    Register dst = as_Register($dst$$reg);

    __ fcmp_clt_d(FCC0, src2, src1);
    __ fcmp_cult_d(FCC1, src1, src2);
    __ movcf2gr(dst, FCC0);
    __ movcf2gr(AT, FCC1);
    __ sub_d(dst, dst, AT);
  %}
  ins_pipe( pipe_slow );
%}

instruct clear_array(mRegL cnt, mRegP base, Universe dummy) %{
  match(Set dummy (ClearArray cnt base));
  format %{ "CLEAR_ARRAY base = $base, cnt = $cnt # Clear doublewords" %}
  ins_encode %{
    //Assume cnt is the number of bytes in an array to be cleared,
    //and base points to the starting address of the array.
    Register base = $base$$Register;
    Register num  = $cnt$$Register;
    Label Loop, done;

    __ add_d(AT, base, R0);
    __ beq(num, R0, done);

    __ move(T4, num);  /* T4 = words */

    __ bind(Loop);
    __ st_d(R0, AT, 0);
    __ addi_d(T4, T4, -1);
    __ addi_d(AT, AT, wordSize);
    __ bne(T4, R0, Loop);

    __ bind(done);
  %}
  ins_pipe( pipe_slow );
%}

instruct string_compare(a4_RegP str1, mA5RegI cnt1, a6_RegP str2,  mA7RegI cnt2, no_Ax_mRegI result) %{
  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
  effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2);

  format %{ "String Compare $str1[len: $cnt1], $str2[len: $cnt2] -> $result @ string_compare" %}
  ins_encode %{
    // Get the first character position in both strings
    //         [8] char array, [12] offset, [16] count
    Register str1   = $str1$$Register;
    Register str2   = $str2$$Register;
    Register cnt1   = $cnt1$$Register;
    Register cnt2   = $cnt2$$Register;
    Register result = $result$$Register;

    Label L, Loop, haveResult, done;

   // compute the and difference of lengths (in result)
   __ sub_d(result, cnt1, cnt2); // result holds the difference of two lengths

   // compute the shorter length (in cnt1)
   __ bge(cnt2, cnt1, Loop);
   __ move(cnt1, cnt2);

   // Now the shorter length is in cnt1 and cnt2 can be used as a tmp register
   __ bind(Loop);                        // Loop begin
   __ beq(cnt1, R0, done);
   __ ld_hu(AT, str1, 0);
   // compare current character
   __ ld_hu(cnt2, str2, 0);
   __ addi_d(str1, str1, 2);
   __ bne(AT, cnt2, haveResult);
   __ addi_d(str2, str2, 2);
   __ addi_d(cnt1, cnt1, -1);  // Loop end
   __ b(Loop);

   __ bind(haveResult);
   __ sub_d(result, AT, cnt2);

   __ bind(done);
  %}

  ins_pipe( pipe_slow );
%}

// intrinsic optimization
instruct string_equals(a4_RegP str1, a5_RegP str2, mA6RegI cnt, mA7RegI temp, no_Ax_mRegI result) %{
  match(Set result (StrEquals (Binary str1 str2) cnt));
  effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL temp);

  format %{ "String Equal $str1, $str2, len:$cnt  tmp:$temp -> $result @ string_equals" %}
  ins_encode %{
    // Get the first character position in both strings
    //         [8] char array, [12] offset, [16] count
    Register str1   = $str1$$Register;
    Register str2   = $str2$$Register;
    Register cnt    = $cnt$$Register;
    Register tmp    = $temp$$Register;
    Register result = $result$$Register;

    Label Loop, True, False;

    __ addi_d(result, R0, 1);
    __ beq(str1, str2, True);  // same char[] ?

    __ beq(cnt, R0, True);

    __ bind(Loop);

    // compare current character
    __ ld_hu(AT, str1, 0);
    __ ld_hu(tmp, str2, 0);
    __ addi_d(str1, str1, 2);
    __ bne(AT, tmp, False);
    __ addi_d(cnt, cnt, -1);
    __ addi_d(str2, str2, 2);
    __ bne(cnt, R0, Loop);

    __ b(True);

    __ bind(False);
    __ addi_d(result, R0, 0);

    __ bind(True);
  %}

  ins_pipe( pipe_slow );
%}

//----------Arithmetic Instructions-------------------------------------------
//----------Addition Instructions---------------------------------------------
instruct addI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (AddI src1 src2));

  format %{ "add   $dst, $src1, $src2 #@addI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ add_w(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct addI_Reg_imm(mRegI dst, mRegI src1,  immI12 src2) %{
  match(Set dst (AddI src1 src2));

  format %{ "add    $dst, $src1, $src2 #@addI_Reg_imm12" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    int       imm = $src2$$constant;

    __ addi_w(dst, src1, imm);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct addI_salI_Reg_Reg_immI_1_4(mRegI dst, mRegI src1, mRegI src2, immI_1_4 shift) %{
  match(Set dst (AddI src1 (LShiftI src2 shift)));

  format %{ "alsl    $dst, $src1, $src2, $shift #@addI_salI_Reg_Reg_immI_1_4" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    int        sh = $shift$$constant;
    __ alsl_w(dst, src2, src1, sh - 1);
  %}
  ins_pipe(ialu_regI_regI);
%}

instruct addP_reg_reg(mRegP dst, mRegP src1, mRegLorI2L src2) %{
  match(Set dst (AddP src1 src2));

  format %{ "ADD    $dst, $src1, $src2 #@addP_reg_reg" %}

  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ add_d(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct addP_reg_reg_M8(mRegP dst, mRegP src1, mRegLorI2L src2, immL_M8 M8) %{
  match(Set dst (AddP src1 (AndL src2 M8)));
  format %{ "ADD    $dst, $src1, $src2 #@addP_reg_reg_M8" %}

  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ bstrins_d(src2, R0, 2, 0);
    __ add_d(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct addP_reg_imm12(mRegP dst, mRegP src1,  immL12 src2) %{
  match(Set dst (AddP src1 src2));

  format %{ "ADD   $dst, $src1, $src2 #@addP_reg_imm12" %}
  ins_encode %{
    Register src1 = $src1$$Register;
    long     src2 = $src2$$constant;
    Register  dst = $dst$$Register;

    __ addi_d(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_imm16 );
%}

instruct addP_salL_Reg_RegI2L_immI_1_4(mRegP dst, mRegP src1, mRegI src2, immI_1_4 shift) %{
  match(Set dst (AddP src1 (LShiftL (ConvI2L src2) shift)));

  format %{ "alsl    $dst, $src1, $src2, $shift #@addP_salL_Reg_RegI2L_immI_1_4" %}

  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    int        sh = $shift$$constant;
    __ alsl_d(dst, src2, src1, sh - 1);
  %}

  ins_pipe(ialu_regI_regI);
%}

// Add Long Register with Register
instruct addL_Reg_Reg(mRegL dst, mRegLorI2L src1, mRegLorI2L src2) %{
  match(Set dst (AddL src1 src2));
  ins_cost(200);
  format %{ "ADD    $dst, $src1, $src2 #@addL_Reg_Reg\t" %}

  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ add_d(dst_reg, src1_reg, src2_reg);
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct addL_Reg_imm(mRegL dst, mRegLorI2L src1, immL12 src2)
%{
  match(Set dst (AddL src1 src2));

  format %{ "ADD    $dst, $src1, $src2 #@addL_Reg_imm " %}
  ins_encode %{
    Register dst_reg  = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    int      src2_imm = $src2$$constant;

    __ addi_d(dst_reg, src1_reg, src2_imm);
  %}

  ins_pipe( ialu_regL_regL );
%}

//----------Subtraction Instructions-------------------------------------------
// Integer Subtraction Instructions
instruct subI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (SubI src1 src2));
  ins_cost(100);

  format %{ "sub    $dst, $src1, $src2 #@subI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ sub_w(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct subI_Reg_immI_M2047_2048(mRegI dst, mRegI src1,  immI_M2047_2048 src2) %{
  match(Set dst (SubI src1 src2));
  ins_cost(80);

  format %{ "sub    $dst, $src1, $src2 #@subI_Reg_immI_M2047_2048" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    __ addi_w(dst, src1, -1 * $src2$$constant);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct negI_Reg(mRegI dst, immI_0 zero,  mRegI src) %{
  match(Set dst (SubI zero src));
  ins_cost(80);

  format %{ "neg    $dst, $src #@negI_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register  src = $src$$Register;
    __ sub_w(dst, R0, src);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct negL_Reg(mRegL dst, immL_0 zero,  mRegLorI2L src) %{
  match(Set dst (SubL zero src));
  ins_cost(80);

  format %{ "neg    $dst, $src #@negL_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register  src = $src$$Register;
    __ sub_d(dst, R0, src);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct subL_Reg_immL_M2047_2048(mRegL dst, mRegL src1,  immL_M2047_2048 src2) %{
  match(Set dst (SubL src1 src2));
  ins_cost(80);

  format %{ "sub    $dst, $src1, $src2 #@subL_Reg_immL_M2047_2048" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    __ addi_d(dst, src1, -1 * $src2$$constant);
  %}
  ins_pipe( ialu_regI_regI );
%}

// Subtract Long Register with Register.
instruct subL_Reg_Reg(mRegL dst, mRegLorI2L src1, mRegLorI2L src2) %{
  match(Set dst (SubL src1 src2));
  ins_cost(100);
  format %{ "SubL    $dst, $src1, $src2 @ subL_Reg_Reg" %}
  ins_encode %{
    Register dst  = as_Register($dst$$reg);
    Register src1 = as_Register($src1$$reg);
    Register src2 = as_Register($src2$$reg);

    __ sub_d(dst, src1, src2);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Integer MOD with Register
instruct modI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (ModI src1 src2));
  ins_cost(300);
  format %{ "modi   $dst, $src1, $src2 @ modI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ mod_w(dst, src1, src2);
  %}

  //ins_pipe( ialu_mod );
  ins_pipe( ialu_regI_regI );
%}

instruct modL_reg_reg(mRegL dst, mRegLorI2L src1, mRegLorI2L src2) %{
  match(Set dst (ModL src1 src2));
  format %{ "modL  $dst, $src1, $src2 @modL_reg_reg" %}

  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    __ mod_d(dst, op1, op2);
  %}
  ins_pipe( pipe_slow );
%}

instruct mulI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (MulI src1 src2));

  ins_cost(300);
  format %{ "mul   $dst, $src1, $src2 @ mulI_Reg_Reg" %}
  ins_encode %{
     Register src1 = $src1$$Register;
     Register src2 = $src2$$Register;
     Register dst  = $dst$$Register;

     __ mul_w(dst, src1, src2);
  %}
  ins_pipe( ialu_mult );
%}

instruct divI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (DivI src1 src2));

  ins_cost(300);
  format %{ "div   $dst, $src1, $src2 @ divI_Reg_Reg" %}
  ins_encode %{
     Register src1 = $src1$$Register;
     Register src2 = $src2$$Register;
     Register dst  = $dst$$Register;

    __ div_w(dst, src1, src2);

  %}
  ins_pipe( ialu_mod );
%}

instruct divF_Reg_Reg(regF dst, regF src1, regF src2) %{
  match(Set dst (DivF src1 src2));

  ins_cost(300);
  format %{ "divF   $dst, $src1, $src2 @ divF_Reg_Reg" %}
  ins_encode %{
     FloatRegister src1 = $src1$$FloatRegister;
     FloatRegister src2 = $src2$$FloatRegister;
     FloatRegister dst  = $dst$$FloatRegister;

    __ fdiv_s(dst, src1, src2);
  %}
  ins_pipe( pipe_slow );
%}

instruct divD_Reg_Reg(regD dst, regD src1, regD src2) %{
  match(Set dst (DivD src1 src2));

  ins_cost(300);
  format %{ "divD   $dst, $src1, $src2 @ divD_Reg_Reg" %}
  ins_encode %{
     FloatRegister src1 = $src1$$FloatRegister;
     FloatRegister src2 = $src2$$FloatRegister;
     FloatRegister dst  = $dst$$FloatRegister;

    __ fdiv_d(dst, src1, src2);
  %}
  ins_pipe( pipe_slow );
%}

instruct mulL_reg_reg(mRegL dst, mRegLorI2L src1, mRegLorI2L src2) %{
  match(Set dst (MulL src1 src2));
  format %{ "mulL  $dst, $src1, $src2 @mulL_reg_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    __ mul_d(dst, op1, op2);
  %}
  ins_pipe( pipe_slow );
%}

instruct mulHiL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (MulHiL src1 src2));
  format %{ "mulHiL  $dst, $src1, $src2 @mulL_reg_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    __ mulh_d(dst, op1, op2);
  %}
  ins_pipe( pipe_slow );
%}

instruct divL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (DivL src1 src2));
  format %{ "divL  $dst, $src1, $src2 @divL_reg_reg" %}

  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    __ div_d(dst, op1, op2);
  %}
  ins_pipe( pipe_slow );
%}

instruct addF_reg_reg(regF dst, regF src1, regF src2) %{
  match(Set dst (AddF src1 src2));
  format %{ "AddF  $dst, $src1, $src2 @addF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ fadd_s(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct subF_reg_reg(regF dst, regF src1, regF src2) %{
  match(Set dst (SubF src1 src2));
  format %{ "SubF  $dst, $src1, $src2 @subF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ fsub_s(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}
instruct addD_reg_reg(regD dst, regD src1, regD src2) %{
  match(Set dst (AddD src1 src2));
  format %{ "AddD  $dst, $src1, $src2 @addD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ fadd_d(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct subD_reg_reg(regD dst, regD src1, regD src2) %{
  match(Set dst (SubD src1 src2));
  format %{ "SubD  $dst, $src1, $src2 @subD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ fsub_d(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct negF_reg(regF dst, regF src) %{
  match(Set dst (NegF src));
  format %{ "negF  $dst, $src @negF_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ fneg_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct negD_reg(regD dst, regD src) %{
  match(Set dst (NegD src));
  format %{ "negD  $dst, $src @negD_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ fneg_d(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}


instruct mulF_reg_reg(regF dst, regF src1, regF src2) %{
  match(Set dst (MulF src1 src2));
  format %{ "MULF  $dst, $src1, $src2 @mulF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = $src1$$FloatRegister;
    FloatRegister src2 = $src2$$FloatRegister;
    FloatRegister dst  = $dst$$FloatRegister;

    __ fmul_s(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct maddF_reg_reg(regF dst, regF src1, regF src2, regF src3) %{
  match(Set dst (AddF (MulF src1 src2) src3));
  // For compatibility reason (e.g. on the Loongson platform), disable this guy.
  ins_cost(44444);
  format %{ "maddF  $dst, $src1, $src2, $src3 @maddF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = $src1$$FloatRegister;
    FloatRegister src2 = $src2$$FloatRegister;
    FloatRegister src3 = $src3$$FloatRegister;
    FloatRegister dst  = $dst$$FloatRegister;

    __ fmadd_s(dst, src1, src2, src3);
  %}
  ins_pipe( fpu_regF_regF );
%}

// Mul two double precision floating piont number
instruct mulD_reg_reg(regD dst, regD src1, regD src2) %{
  match(Set dst (MulD src1 src2));
  format %{ "MULD  $dst, $src1, $src2 @mulD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = $src1$$FloatRegister;
    FloatRegister src2 = $src2$$FloatRegister;
    FloatRegister dst  = $dst$$FloatRegister;

    __ fmul_d(dst, src1, src2);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct maddD_reg_reg(regD dst, regD src1, regD src2, regD src3) %{
  match(Set dst (AddD (MulD src1 src2) src3));
  // For compatibility reason (e.g. on the Loongson platform), disable this guy.
  ins_cost(44444);
  format %{ "maddD  $dst, $src1, $src2, $src3 @maddD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = $src1$$FloatRegister;
    FloatRegister src2 = $src2$$FloatRegister;
    FloatRegister src3 = $src3$$FloatRegister;
    FloatRegister dst  = $dst$$FloatRegister;

    __ fmadd_d(dst, src1, src2, src3);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct absF_reg(regF dst, regF src) %{
  match(Set dst (AbsF src));
  ins_cost(100);
  format %{ "absF  $dst, $src @absF_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ fabs_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}


// intrinsics for math_native.
// AbsD  SqrtD  CosD  SinD  TanD  LogD  Log10D

instruct absD_reg(regD dst, regD src) %{
  match(Set dst (AbsD src));
  ins_cost(100);
  format %{ "absD  $dst, $src @absD_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ fabs_d(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct sqrtD_reg(regD dst, regD src) %{
  match(Set dst (SqrtD src));
  ins_cost(100);
  format %{ "SqrtD  $dst, $src @sqrtD_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ fsqrt_d(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct sqrtF_reg(regF dst, regF src) %{
  match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
  ins_cost(100);
  format %{ "SqrtF  $dst, $src @sqrtF_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ fsqrt_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}
//----------------------------------Logical Instructions----------------------
//__________________________________Integer Logical Instructions-------------

//And Instuctions
// And Register with Immediate
instruct andI_Reg_imm_0_4095(mRegI dst, mRegI src1,  immI_0_4095 src2) %{
  match(Set dst (AndI src1 src2));
  ins_cost(60);

  format %{ "and  $dst, $src1, $src2 #@andI_Reg_imm_0_4095" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int      val = $src2$$constant;

    __ andi(dst, src, val);

  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andI_Reg_immI_nonneg_mask(mRegI dst, mRegI src1,  immI_nonneg_mask mask) %{
  match(Set dst (AndI src1 mask));
  ins_cost(60);

  format %{ "and  $dst, $src1, $mask #@andI_Reg_immI_nonneg_mask" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int     size = Assembler::is_int_mask($mask$$constant);

    __ bstrpick_w(dst, src, size-1, 0);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL_Reg_immL_nonneg_mask(mRegL dst, mRegL src1,  immL_nonneg_mask mask) %{
  match(Set dst (AndL src1 mask));
  ins_cost(60);

  format %{ "and  $dst, $src1, $mask #@andL_Reg_immL_nonneg_mask" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int     size = Assembler::is_jlong_mask($mask$$constant);

    __ bstrpick_d(dst, src, size-1, 0);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct xorI_Reg_imm_0_4095(mRegI dst, mRegI src1,  immI_0_4095 src2) %{
  match(Set dst (XorI src1 src2));
  ins_cost(60);

  format %{ "xori  $dst, $src1, $src2 #@xorI_Reg_imm_0_4095" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int      val = $src2$$constant;

       __ xori(dst, src, val);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct xorI_Reg_immI_M1(mRegI dst, mRegI src1,  immI_M1 M1) %{
  match(Set dst (XorI src1 M1));
  ins_cost(60);

  format %{ "xor  $dst, $src1, $M1 #@xorI_Reg_immI_M1" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;

    __ orn(dst, R0, src);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct xorL2I_Reg_immI_M1(mRegI dst, mRegL src1,  immI_M1 M1) %{
  match(Set dst (XorI (ConvL2I src1) M1));
  ins_cost(60);

  format %{ "xor  $dst, $src1, $M1 #@xorL2I_Reg_immI_M1" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;

    __ orn(dst, R0, src);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct xorL_Reg_imm_0_4095(mRegL dst, mRegL src1,  immL_0_4095 src2) %{
  match(Set dst (XorL src1 src2));
  ins_cost(60);

  format %{ "xori  $dst, $src1, $src2 #@xorL_Reg_imm_0_4095" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int      val = $src2$$constant;

    __ xori(dst, src, val);
  %}
  ins_pipe( ialu_regI_regI );
%}


instruct lbu_and_lmask(mRegI dst, memory mem,  immI_255 mask) %{
  match(Set dst (AndI mask (LoadB mem)));
  ins_cost(60);

  format %{ "lhu  $dst, $mem #@lbu_and_lmask" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_BYTE);
  %}
  ins_pipe( ialu_loadI );
%}

instruct lbu_and_rmask(mRegI dst, memory mem,  immI_255 mask) %{
  match(Set dst (AndI (LoadB mem) mask));
  ins_cost(60);

  format %{ "lhu  $dst, $mem #@lbu_and_rmask" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_BYTE);
  %}
  ins_pipe( ialu_loadI );
%}

instruct andI_Reg_Reg(mRegI dst, mRegI src1,  mRegI src2) %{
  match(Set dst (AndI src1 src2));

  format %{ "and    $dst, $src1, $src2 #@andI_Reg_Reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ andr(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andnI_Reg_nReg(mRegI dst, mRegI src1,  mRegI src2, immI_M1 M1) %{
  match(Set dst (AndI src1 (XorI src2 M1)));

  format %{ "andn   $dst, $src1, $src2 #@andnI_Reg_nReg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ andn(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct ornI_Reg_nReg(mRegI dst, mRegI src1,  mRegI src2, immI_M1 M1) %{
  match(Set dst (OrI src1 (XorI src2 M1)));

  format %{ "orn    $dst, $src1, $src2 #@ornI_Reg_nReg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ orn(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andnI_nReg_Reg(mRegI dst, mRegI src1,  mRegI src2, immI_M1 M1) %{
  match(Set dst (AndI (XorI src1 M1) src2));

  format %{ "andn   $dst, $src2, $src1 #@andnI_nReg_Reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ andn(dst, src2, src1);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct ornI_nReg_Reg(mRegI dst, mRegI src1,  mRegI src2, immI_M1 M1) %{
  match(Set dst (OrI (XorI src1 M1) src2));

  format %{ "orn    $dst, $src2, $src1 #@ornI_nReg_Reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    __ orn(dst, src2, src1);
  %}
  ins_pipe( ialu_regI_regI );
%}

// And Long Register with Register
instruct andL_Reg_Reg(mRegL dst, mRegL src1, mRegLorI2L src2) %{
  match(Set dst (AndL src1 src2));
  format %{ "AND    $dst, $src1, $src2 @ andL_Reg_Reg\n\t" %}
  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ andr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct andL_Reg_imm_0_4095(mRegL dst, mRegL src1,  immL_0_4095 src2) %{
  match(Set dst (AndL src1 src2));
  ins_cost(60);

  format %{ "and  $dst, $src1, $src2 #@andL_Reg_imm_0_4095" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    long     val = $src2$$constant;

    __ andi(dst, src, val);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL2I_Reg_imm_0_4095(mRegI dst, mRegL src1,  immL_0_4095 src2) %{
  match(Set dst (ConvL2I (AndL src1 src2)));
  ins_cost(60);

  format %{ "and  $dst, $src1, $src2 #@andL2I_Reg_imm_0_4095" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    long     val = $src2$$constant;

    __ andi(dst, src, val);
  %}
  ins_pipe( ialu_regI_regI );
%}


instruct andL_Reg_immL_M8(mRegL dst,  immL_M8 M8) %{
  match(Set dst (AndL dst M8));
  ins_cost(60);

  format %{ "and  $dst, $dst, $M8 #@andL_Reg_immL_M8" %}
  ins_encode %{
    Register dst = $dst$$Register;

    __ bstrins_d(dst, R0, 2, 0);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL_Reg_immL_M5(mRegL dst,  immL_M5 M5) %{
  match(Set dst (AndL dst M5));
  ins_cost(60);

  format %{ "and  $dst, $dst, $M5 #@andL_Reg_immL_M5" %}
  ins_encode %{
    Register dst = $dst$$Register;

    __ bstrins_d(dst, R0, 2, 2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL_Reg_immL_M7(mRegL dst,  immL_M7 M7) %{
  match(Set dst (AndL dst M7));
  ins_cost(60);

  format %{ "and  $dst, $dst, $M7 #@andL_Reg_immL_M7" %}
  ins_encode %{
    Register dst = $dst$$Register;

    __ bstrins_d(dst, R0, 2, 1);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL_Reg_immL_M4(mRegL dst,  immL_M4 M4) %{
  match(Set dst (AndL dst M4));
  ins_cost(60);

  format %{ "and  $dst, $dst, $M4 #@andL_Reg_immL_M4" %}
  ins_encode %{
    Register dst = $dst$$Register;

    __ bstrins_d(dst, R0, 1, 0);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andL_Reg_immL_M121(mRegL dst,  immL_M121 M121) %{
  match(Set dst (AndL dst M121));
  ins_cost(60);

  format %{ "and  $dst, $dst, $M121 #@andL_Reg_immL_M121" %}
  ins_encode %{
    Register dst = $dst$$Register;

    __ bstrins_d(dst, R0, 6, 3);
  %}
  ins_pipe( ialu_regI_regI );
%}

// Or Long Register with Register
instruct orL_Reg_Reg(mRegL dst, mRegLorI2L src1, mRegLorI2L src2) %{
  match(Set dst (OrL src1 src2));
  format %{ "OR    $dst, $src1, $src2 @ orL_Reg_Reg\t" %}
  ins_encode %{
    Register dst_reg  = $dst$$Register;
    Register src1_reg = $src1$$Register;
    Register src2_reg = $src2$$Register;

    __ orr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct orL_Reg_P2XReg(mRegL dst, mRegP src1, mRegLorI2L src2) %{
  match(Set dst (OrL (CastP2X src1) src2));
  format %{ "OR    $dst, $src1, $src2 @ orL_Reg_P2XReg\t" %}
  ins_encode %{
    Register dst_reg  = $dst$$Register;
    Register src1_reg = $src1$$Register;
    Register src2_reg = $src2$$Register;

    __ orr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Xor Long Register with Register
instruct xorL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (XorL src1 src2));
  format %{ "XOR    $dst, $src1, $src2 @ xorL_Reg_Reg\t" %}
  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ xorr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Left by 5-bit immediate
instruct salI_Reg_imm(mRegI dst, mRegI src, immIU5 shift) %{
  match(Set dst (LShiftI src shift));

  format %{ "SHL    $dst, $src, $shift #@salI_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shamt = $shift$$constant;

    __ slli_w(dst, src, shamt);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct salL2I_Reg_imm(mRegI dst, mRegL src, immIU5 shift) %{
  match(Set dst (LShiftI (ConvL2I src) shift));

  format %{ "SHL    $dst, $src, $shift #@salL2I_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shamt = $shift$$constant;

    __ slli_w(dst, src, shamt);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct salI_Reg_imm_and_M65536(mRegI dst, mRegI src, immI_16 shift, immI_M65536 mask) %{
  match(Set dst (AndI (LShiftI src shift) mask));

  format %{ "SHL    $dst, $src, $shift #@salI_Reg_imm_and_M65536" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

    __ slli_w(dst, src, 16);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct land7_2_s(mRegI dst, mRegL src, immL_7 seven, immI_16 sixteen)
%{
  match(Set dst (RShiftI (LShiftI (ConvL2I (AndL src seven)) sixteen) sixteen));

  format %{ "andi  $dst, $src, 7\t# @land7_2_s" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

    __ andi(dst, src, 7);
  %}
  ins_pipe(ialu_regI_regI);
%}

// Logical Shift Right by 16, followed by Arithmetic Shift Left by 16.
// This idiom is used by the compiler the i2s bytecode.
instruct i2s(mRegI dst, mRegI src, immI_16 sixteen)
%{
  match(Set dst (RShiftI (LShiftI src sixteen) sixteen));

  format %{ "i2s  $dst, $src\t# @i2s" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

    __ ext_w_h(dst, src);
  %}
  ins_pipe(ialu_regI_regI);
%}

// Logical Shift Right by 24, followed by Arithmetic Shift Left by 24.
// This idiom is used by the compiler for the i2b bytecode.
instruct i2b(mRegI dst, mRegI src, immI_24 twentyfour)
%{
  match(Set dst (RShiftI (LShiftI src twentyfour) twentyfour));

  format %{ "i2b  $dst, $src\t# @i2b" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

    __ ext_w_b(dst, src);
  %}
  ins_pipe(ialu_regI_regI);
%}


instruct salI_RegL2I_imm(mRegI dst, mRegL src, immIU5 shift) %{
  match(Set dst (LShiftI (ConvL2I src) shift));

  format %{ "SHL    $dst, $src, $shift #@salI_RegL2I_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shamt = $shift$$constant;

    __ slli_w(dst, src, shamt);
  %}
  ins_pipe( ialu_regI_regI );
%}

// Shift Left by 8-bit immediate
instruct salI_Reg_Reg(mRegI dst, mRegI src, mRegI shift) %{
  match(Set dst (LShiftI src shift));

  format %{ "SHL    $dst, $src, $shift #@salI_Reg_Reg" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    Register shamt = $shift$$Register;
    __ sll_w(dst, src, shamt);
  %}
  ins_pipe( ialu_regI_regI );
%}


// Shift Left Long 6-bit immI
instruct salL_Reg_imm(mRegL dst, mRegLorI2L src, immIU6 shift) %{
  match(Set dst (LShiftL src shift));
  ins_cost(100);
  format %{ "salL    $dst, $src, $shift @ salL_Reg_imm" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int      shamt = $shift$$constant;

    __ slli_d(dst_reg, src_reg, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Left Long
instruct salL_Reg_Reg(mRegL dst, mRegLorI2L src, mRegI shift) %{
  match(Set dst (LShiftL src shift));
  ins_cost(100);
  format %{ "salL    $dst, $src, $shift @ salL_Reg_Reg" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);

    __ sll_d(dst_reg, src_reg, $shift$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Right Long 6-bit
instruct sarL_Reg_imm(mRegL dst, mRegLorI2L src, immIU6 shift) %{
  match(Set dst (RShiftL src shift));
  ins_cost(100);
  format %{ "sarL    $dst, $src, $shift @ sarL_Reg_imm" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int      shamt = $shift$$constant;

    __ srai_d(dst_reg, src_reg, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct sarL2I_Reg_immI_32_63(mRegI dst, mRegLorI2L src, immI_32_63 shift) %{
  match(Set dst (ConvL2I (RShiftL src shift)));
  ins_cost(100);
  format %{ "sarL    $dst, $src, $shift @ sarL2I_Reg_immI_32_63" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int      shamt   = $shift$$constant;

    __ srai_d(dst_reg, src_reg, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Right Long arithmetically
instruct sarL_Reg_Reg(mRegL dst, mRegLorI2L src, mRegI shift) %{
  match(Set dst (RShiftL src shift));
  ins_cost(100);
  format %{ "sarL    $dst, $src, $shift @ sarL_Reg_Reg" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);

    __ sra_d(dst_reg, src_reg, $shift$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Right Long logically
instruct slrL_Reg_Reg(mRegL dst, mRegL src, mRegI shift) %{
  match(Set dst (URShiftL src shift));
  ins_cost(100);
  format %{ "slrL    $dst, $src, $shift @ slrL_Reg_Reg" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);

    __ srl_d(dst_reg, src_reg, $shift$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_Reg_immI_0_31(mRegL dst, mRegLorI2L src, immI_0_31 shift) %{
  match(Set dst (URShiftL src shift));
  ins_cost(80);
  format %{ "slrL    $dst, $src, $shift @ slrL_Reg_immI_0_31" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ srli_d(dst_reg, src_reg, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_Reg_immI_0_31_and_max_int(mRegI dst, mRegLorI2L src, immI_0_31 shift, immI_MaxI max_int) %{
  match(Set dst (AndI (ConvL2I (URShiftL src shift)) max_int));
  ins_cost(80);
  format %{ "bstrpick_d    $dst, $src, $shift+30, shift @ slrL_Reg_immI_0_31_and_max_int" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ bstrpick_d(dst_reg, src_reg, shamt+30, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_P2XReg_immI_0_31(mRegL dst, mRegP src, immI_0_31 shift) %{
  match(Set dst (URShiftL (CastP2X src) shift));
  ins_cost(80);
  format %{ "slrL    $dst, $src, $shift @ slrL_P2XReg_immI_0_31" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ srli_d(dst_reg, src_reg, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_Reg_immI_32_63(mRegL dst, mRegLorI2L src, immI_32_63 shift) %{
  match(Set dst (URShiftL src shift));
  ins_cost(80);
  format %{ "slrL    $dst, $src, $shift @ slrL_Reg_immI_32_63" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ srli_d(dst_reg, src_reg, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_Reg_immI_convL2I(mRegI dst, mRegLorI2L src, immI_32_63 shift) %{
  match(Set dst (ConvL2I (URShiftL src shift)));
  predicate(n->in(1)->in(2)->get_int() > 32);
  ins_cost(80);
  format %{ "slrL    $dst, $src, $shift @ slrL_Reg_immI_convL2I" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ srli_d(dst_reg, src_reg, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct slrL_P2XReg_immI_32_63(mRegL dst, mRegP src, immI_32_63 shift) %{
  match(Set dst (URShiftL (CastP2X src) shift));
  ins_cost(80);
  format %{ "slrL    $dst, $src, $shift @ slrL_P2XReg_immI_32_63" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int        shamt = $shift$$constant;

    __ srli_d(dst_reg, src_reg, shamt);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Xor Instructions
// Xor Register with Register
instruct xorI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (XorI src1 src2));

  format %{ "XOR    $dst, $src1, $src2 #@xorI_Reg_Reg" %}

  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ xorr(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

// Or Instructions
instruct orI_Reg_imm(mRegI dst, mRegI src1, immI_0_4095 src2) %{
  match(Set dst (OrI src1 src2));

  format %{ "OR     $dst, $src1, $src2 #@orI_Reg_imm" %}
  ins_encode %{
    __ ori($dst$$Register, $src1$$Register, $src2$$constant);
  %}

  ins_pipe( ialu_regI_regI );
%}

// Or Register with Register
instruct orI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (OrI src1 src2));

  format %{ "OR     $dst, $src1, $src2 #@orI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ orr(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct rotI_shr_logical_Reg(mRegI dst, mRegI src, immI_0_31 rshift, immI_0_31 lshift, immI_1 one) %{
  match(Set dst (OrI (URShiftI src rshift) (LShiftI (AndI src one) lshift)));
  predicate(32 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int())));

  format %{ "rotri_w     $dst, $src, 1 ...\n\t"
            "srli_w      $dst, $dst, ($rshift-1) @ rotI_shr_logical_Reg" %}
  ins_encode %{
    Register   dst = $dst$$Register;
    Register   src = $src$$Register;
    int     rshift = $rshift$$constant;

    __ rotri_w(dst, src, 1);
    if (rshift - 1) {
      __ srli_w(dst, dst, rshift - 1);
    }
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct orI_Reg_castP2X(mRegL dst, mRegL src1, mRegP src2) %{
  match(Set dst (OrI src1 (CastP2X src2)));

  format %{ "OR     $dst, $src1, $src2 #@orI_Reg_castP2X" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ orr(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

// Logical Shift Right by 5-bit immediate
instruct shr_logical_Reg_imm(mRegI dst, mRegI src, immIU5 shift) %{
  match(Set dst (URShiftI src shift));
  //effect(KILL cr);

  format %{ "SRLI_W    $dst, $src, $shift #@shr_logical_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shift = $shift$$constant;

    __ srli_w(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct shr_logical_Reg_imm_nonneg_mask(mRegI dst, mRegI src, immI_0_31 shift, immI_nonneg_mask mask) %{
  match(Set dst (AndI (URShiftI src shift) mask));

  format %{ "bstrpick_w    $dst, $src, $shift+one-bits($mask)-1, shift #@shr_logical_Reg_imm_nonneg_mask" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int      pos = $shift$$constant;
    int     size = Assembler::is_int_mask($mask$$constant);

    __ bstrpick_w(dst, src, pos+size-1, pos);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rolI_Reg_immI_0_31(mRegI dst, mRegI src, immI_0_31 lshift, immI_0_31 rshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x1f));
  match(Set dst (OrI (LShiftI src lshift) (URShiftI src rshift)));

  ins_cost(100);
  format %{ "rotri_w    $dst, $src, $rshift #@rolI_Reg_immI_0_31" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ rotri_w(dst, src, sa);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rolL_Reg_immI_0_31(mRegL dst, mRegLorI2L src, immI_32_63 lshift, immI_0_31 rshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x3f));
  match(Set dst (OrL (LShiftL src lshift) (URShiftL src rshift)));

  ins_cost(100);
  format %{ "rotri_d    $dst, $src, $rshift #@rolL_Reg_immI_0_31" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ rotri_d(dst, src, sa);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rolL_Reg_immI_32_63(mRegL dst, mRegLorI2L src, immI_0_31 lshift, immI_32_63 rshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x3f));
  match(Set dst (OrL (LShiftL src lshift) (URShiftL src rshift)));

  ins_cost(100);
  format %{ "rotri_d    $dst, $src, $rshift #@rolL_Reg_immI_32_63" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ rotri_d(dst, src, sa);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rorI_Reg_immI_0_31(mRegI dst, mRegI src, immI_0_31 rshift, immI_0_31 lshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x1f));
  match(Set dst (OrI (URShiftI src rshift) (LShiftI src lshift)));

  ins_cost(100);
  format %{ "rotri_w    $dst, $src, $rshift #@rorI_Reg_immI_0_31" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ rotri_w(dst, src, sa);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rorL_Reg_immI_0_31(mRegL dst, mRegLorI2L src, immI_0_31 rshift, immI_32_63 lshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x3f));
  match(Set dst (OrL (URShiftL src rshift) (LShiftL src lshift)));

  ins_cost(100);
  format %{ "rotri_d    $dst, $src, $rshift #@rorL_Reg_immI_0_31" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ rotri_d(dst, src, sa);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct rorL_Reg_immI_32_63(mRegL dst, mRegLorI2L src, immI_32_63 rshift, immI_0_31 lshift)
%{
  predicate(0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x3f));
  match(Set dst (OrL (URShiftL src rshift) (LShiftL src lshift)));

  ins_cost(100);
  format %{ "rotri_d    $dst, $src, $rshift #@rorL_Reg_immI_32_63" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int      sa  = $rshift$$constant;

    __ rotri_d(dst, src, sa);
  %}
  ins_pipe( ialu_regI_regI );
%}

// Logical Shift Right
instruct shr_logical_Reg_Reg(mRegI dst, mRegI src, mRegI shift) %{
  match(Set dst (URShiftI src shift));

  format %{ "SRL_W    $dst, $src, $shift #@shr_logical_Reg_Reg" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    Register shift = $shift$$Register;
    __ srl_w(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}


instruct shr_arith_Reg_imm(mRegI dst, mRegI src, immIU5 shift) %{
  match(Set dst (RShiftI src shift));
 // effect(KILL cr);

  format %{ "SRAI_W    $dst, $src, $shift #@shr_arith_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shift = $shift$$constant;
    __ srai_w(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct shr_arith_Reg_Reg(mRegI dst, mRegI src, mRegI shift) %{
  match(Set dst (RShiftI src shift));
 // effect(KILL cr);

  format %{ "SRA_W    $dst, $src, $shift #@shr_arith_Reg_Reg" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    Register shift = $shift$$Register;
    __ sra_w(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}

//----------Convert Int to Boolean---------------------------------------------

instruct convI2B(mRegI dst, mRegI src) %{
  match(Set dst (Conv2B src));

  ins_cost(100);
  format %{ "convI2B    $dst, $src @ convI2B"  %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    if (dst != src) {
      __ addi_d(dst, R0, 1);
      __ maskeqz(dst, dst, src);
    } else {
      __ move(AT, src);
      __ addi_d(dst, R0, 1);
      __ maskeqz(dst, dst, AT);
    }
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct convI2L_reg( mRegL dst, mRegI src) %{
  match(Set dst (ConvI2L src));

  ins_cost(100);
  format %{ "SLLI_W    $dst, $src @ convI2L_reg\t"  %}

  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    if(dst != src) __ slli_w(dst, src, 0);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct convL2I_reg( mRegI dst, mRegLorI2L src ) %{
  match(Set dst (ConvL2I src));

  format %{ "MOV    $dst, $src @ convL2I_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    __ slli_w(dst, src, 0);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct convL2D_reg( regD dst, mRegL src ) %{
  match(Set dst (ConvL2D src));
  format %{ "convL2D    $dst, $src @ convL2D_reg" %}
  ins_encode %{
    Register src = as_Register($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ movgr2fr_d(dst, src);
    __ ffint_d_l(dst, dst);
  %}

  ins_pipe( pipe_slow );
%}


// Convert double to int.
// If the double is NaN, stuff a zero in instead.
instruct convD2I_reg_reg(mRegI dst, regD src, regD tmp) %{
  match(Set dst (ConvD2I src));
  effect(USE src, TEMP tmp);

  format %{ "convd2i    $dst, $src, using $tmp as TEMP @ convD2I_reg_reg" %}

  ins_encode %{
    __ ftintrz_w_d($tmp$$FloatRegister, $src$$FloatRegister);
    __ movfr2gr_s($dst$$Register, $tmp$$FloatRegister);
  %}

  ins_pipe( pipe_slow );
%}

instruct convD2L_reg_reg(mRegL dst, regD src, regD tmp) %{
  match(Set dst (ConvD2L src));
  effect(USE src, TEMP tmp);

  format %{ "convd2l    $dst, $src, using $tmp as TEMP @ convD2L_reg_reg" %}

  ins_encode %{
    __ ftintrz_l_d($tmp$$FloatRegister, $src$$FloatRegister);
    __ movfr2gr_d($dst$$Register, $tmp$$FloatRegister);
  %}

  ins_pipe( pipe_slow );
%}

// Convert float to int.
// If the float is NaN, stuff a zero in instead.
instruct convF2I_reg_reg(mRegI dst, regF src, regF tmp) %{
  match(Set dst (ConvF2I src));
  effect(USE src, TEMP tmp);

  format %{ "convf2i    $dst, $src, using $tmp as TEMP @ convF2I_reg_reg" %}

  ins_encode %{
    __ ftintrz_w_s($tmp$$FloatRegister, $src$$FloatRegister);
    __ movfr2gr_s($dst$$Register, $tmp$$FloatRegister);
  %}

  ins_pipe( pipe_slow );
%}

instruct convF2L_reg_reg(mRegL dst, regF src, regF tmp) %{
  match(Set dst (ConvF2L src));
  effect(USE src, TEMP tmp);

  format %{ "convf2l    $dst, $src, using $tmp as TEMP @ convF2L_reg_reg" %}

  ins_encode %{
    __ ftintrz_l_s($tmp$$FloatRegister, $src$$FloatRegister);
    __ movfr2gr_d($dst$$Register, $tmp$$FloatRegister);
  %}

  ins_pipe( pipe_slow );
%}


instruct convL2F_reg( regF dst, mRegL src ) %{
  match(Set dst (ConvL2F src));
  format %{ "convl2f    $dst, $src @ convL2F_reg" %}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    Register src = as_Register($src$$reg);
    Label L;

    __ movgr2fr_d(dst, src);
    __ ffint_s_l(dst, dst);
  %}

  ins_pipe( pipe_slow );
%}

instruct convI2F_reg( regF dst, mRegI src ) %{
  match(Set dst (ConvI2F src));
  format %{ "convi2f    $dst, $src @ convI2F_reg" %}
  ins_encode %{
    Register      src = $src$$Register;
    FloatRegister dst = $dst$$FloatRegister;

    __ movgr2fr_w(dst, src);
    __ ffint_s_w(dst, dst);
  %}

  ins_pipe( fpu_regF_regF );
%}

instruct cmpLTMask_immI_0( mRegI dst, mRegI p, immI_0 zero ) %{
  match(Set dst (CmpLTMask p zero));
  ins_cost(100);

  format %{ "srai_w    $dst, $p, 31 @ cmpLTMask_immI_0" %}
    ins_encode %{
       Register src = $p$$Register;
       Register dst = $dst$$Register;

       __ srai_w(dst, src, 31);
    %}
    ins_pipe( pipe_slow );
%}


instruct cmpLTMask( mRegI dst, mRegI p, mRegI q ) %{
  match(Set dst (CmpLTMask p q));
  ins_cost(400);

  format %{ "cmpLTMask    $dst, $p, $q @ cmpLTMask" %}
  ins_encode %{
    Register p   = $p$$Register;
    Register q   = $q$$Register;
    Register dst = $dst$$Register;

    __ slt(dst, p, q);
    __ sub_d(dst, R0, dst);
    %}
  ins_pipe( pipe_slow );
%}

instruct convP2B(mRegI dst, mRegP src) %{
  match(Set dst (Conv2B src));

  ins_cost(100);
  format %{ "convP2B    $dst, $src @ convP2B"  %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    if (dst != src) {
      __ addi_d(dst, R0, 1);
      __ maskeqz(dst, dst, src);
    } else {
      __ move(AT, src);
      __ addi_d(dst, R0, 1);
      __ maskeqz(dst, dst, AT);
    }
  %}

  ins_pipe( ialu_regL_regL );
%}


instruct convI2D_reg_reg(regD dst, mRegI src) %{
  match(Set dst (ConvI2D src));
  format %{ "conI2D $dst, $src @convI2D_reg" %}
  ins_encode %{
    Register      src = $src$$Register;
    FloatRegister dst = $dst$$FloatRegister;
    __ movgr2fr_w(dst ,src);
    __ ffint_d_w(dst, dst);
    %}
  ins_pipe( fpu_regF_regF );
%}

instruct convF2D_reg_reg(regD dst, regF src) %{
  match(Set dst (ConvF2D src));
  format %{ "convF2D  $dst, $src\t# @convF2D_reg_reg" %}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    FloatRegister src = $src$$FloatRegister;

    __ fcvt_d_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct convD2F_reg_reg(regF dst, regD src) %{
  match(Set dst (ConvD2F src));
  format %{ "convD2F  $dst, $src\t# @convD2F_reg_reg" %}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    FloatRegister src = $src$$FloatRegister;

    __ fcvt_s_d(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}


// Convert oop pointer into compressed form
instruct encodeHeapOop(mRegN dst, mRegP src) %{
  predicate(n->bottom_type()->make_ptr()->ptr() != TypePtr::NotNull);
  match(Set dst (EncodeP src));
  format %{ "encode_heap_oop $dst,$src" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

    __ encode_heap_oop(dst, src);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct encodeHeapOop_not_null(mRegN dst, mRegP src) %{
  predicate(n->bottom_type()->make_ptr()->ptr() == TypePtr::NotNull);
  match(Set dst (EncodeP src));
  format %{ "encode_heap_oop_not_null $dst,$src @ encodeHeapOop_not_null" %}
  ins_encode %{
    __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct decodeHeapOop(mRegP dst, mRegN src) %{
  predicate(n->bottom_type()->is_ptr()->ptr() != TypePtr::NotNull &&
            n->bottom_type()->is_ptr()->ptr() != TypePtr::Constant);
  match(Set dst (DecodeN src));
  format %{ "decode_heap_oop $dst,$src @ decodeHeapOop" %}
  ins_encode %{
    Register s = $src$$Register;
    Register d = $dst$$Register;

    __ decode_heap_oop(d, s);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct decodeHeapOop_not_null(mRegP dst, mRegN src) %{
  predicate(n->bottom_type()->is_ptr()->ptr() == TypePtr::NotNull ||
            n->bottom_type()->is_ptr()->ptr() == TypePtr::Constant);
  match(Set dst (DecodeN src));
  format %{ "decode_heap_oop_not_null $dst,$src @ decodeHeapOop_not_null" %}
  ins_encode %{
    Register s = $src$$Register;
    Register d = $dst$$Register;
    if (s != d) {
      __ decode_heap_oop_not_null(d, s);
    } else {
      __ decode_heap_oop_not_null(d);
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct encodeKlass_not_null(mRegN dst, mRegP src) %{
  match(Set dst (EncodePKlass src));
  format %{ "encode_heap_oop_not_null $dst,$src @ encodeKlass_not_null" %}
  ins_encode %{
    __ encode_klass_not_null($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct decodeKlass_not_null(mRegP dst, mRegN src) %{
  match(Set dst (DecodeNKlass src));
  format %{ "decode_heap_klass_not_null $dst,$src" %}
  ins_encode %{
    Register s = $src$$Register;
    Register d = $dst$$Register;
    if (s != d) {
      __ decode_klass_not_null(d, s);
    } else {
      __ decode_klass_not_null(d);
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

//FIXME
instruct tlsLoadP(mRegP dst) %{
  match(Set dst (ThreadLocal));

  ins_cost(0);
  format %{ " get_thread in $dst #@tlsLoadP" %}
  ins_encode %{
    Register dst = $dst$$Register;
#ifdef OPT_THREAD
    __ move(dst, TREG);
#else
    __ get_thread(dst);
#endif
  %}

  ins_pipe( ialu_loadI );
%}


instruct checkCastPP( mRegP dst ) %{
  match(Set dst (CheckCastPP dst));

  format %{ "#checkcastPP of $dst (empty encoding) #@chekCastPP" %}
  ins_encode( /*empty encoding*/ );
  ins_pipe( empty );
%}

instruct castPP(mRegP dst)
%{
  match(Set dst (CastPP dst));

  size(0);
  format %{ "# castPP of $dst" %}
  ins_encode(/* empty encoding */);
  ins_pipe(empty);
%}

instruct castII( mRegI dst ) %{
  match(Set dst (CastII dst));
  format %{ "#castII of $dst  empty encoding" %}
  ins_encode( /*empty encoding*/ );
  ins_cost(0);
  ins_pipe( empty );
%}

// Return Instruction
// Remove the return address & jump to it.
instruct Ret() %{
  match(Return);
  format %{ "RET #@Ret" %}

  ins_encode %{
   __ jr(RA);
  %}

  ins_pipe( pipe_jump );
%}



// Tail Jump; remove the return address; jump to target.
// TailCall above leaves the return address around.
// TailJump is used in only one place, the rethrow_Java stub (fancy_jump=2).
// ex_oop (Exception Oop) is needed in %o0 at the jump. As there would be a
// "restore" before this instruction (in Epilogue), we need to materialize it
// in %i0.
//FIXME
instruct tailjmpInd(no_Ax_mRegP jump_target, mRegP ex_oop) %{
  match( TailJump jump_target ex_oop );
  ins_cost(200);
  format %{ "Jmp     $jump_target  ; ex_oop = $ex_oop #@tailjmpInd" %}
  ins_encode %{
    Register target = $jump_target$$Register;

    // V0, V1 are indicated in:
    //     [stubGenerator_loongarch.cpp] generate_forward_exception()
    //     [runtime_loongarch.cpp] OptoRuntime::generate_exception_blob()
    //
    Register oop  = $ex_oop$$Register;
    Register exception_oop = V0;
    Register exception_pc = V1;

    __ move(exception_pc, RA);
    __ move(exception_oop, oop);

    __ jr(target);
  %}
  ins_pipe( pipe_jump );
%}

// ============================================================================
// Procedure Call/Return Instructions
// Call Java Static Instruction
// Note: If this code changes, the corresponding ret_addr_offset() and
//       compute_padding() functions will have to be adjusted.
instruct CallStaticJavaDirect(method meth) %{
  match(CallStaticJava);
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL,static #@CallStaticJavaDirect " %}
  ins_encode( Java_Static_Call( meth ) );
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(4);
%}

// Call Java Dynamic Instruction
// Note: If this code changes, the corresponding ret_addr_offset() and
//       compute_padding() functions will have to be adjusted.
instruct CallDynamicJavaDirect(method meth) %{
  match(CallDynamicJava);
  effect(USE meth);

  ins_cost(300);
  format %{"MOV IC_Klass, #Universe::non_oop_word()\n\t"
           "CallDynamic @ CallDynamicJavaDirect" %}
  ins_encode( Java_Dynamic_Call( meth ) );
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(4);
%}

instruct CallLeafNoFPDirect(method meth) %{
  match(CallLeafNoFP);
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL_LEAF_NOFP,runtime " %}
  ins_encode(Java_To_Runtime(meth));
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(4);
%}

// Prefetch instructions.

instruct prefetchr( memory mem ) %{
  match(PrefetchRead mem);
  ins_cost(125);

  format %{ "pref $mem\t# Prefetch into temporal cache for read @ prefetchr" %}
  ins_encode %{
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (scale == 0) {
        __ add_d(AT, as_Register(base), as_Register(index));
      } else {
        __ alsl_d(AT, as_Register(index), as_Register(base), scale - 1);
      }
    } else {
      __ move(AT, as_Register(base));
    }
    if( Assembler::is_simm(disp, 12) ) {
      __ addi_d(AT, AT, disp);
    } else {
      __ li(T4, disp);
      __ add_d(AT, AT, T4);
    }
    __ preld(0, AT, 0); //hint: 0:load
  %}
  ins_pipe(pipe_slow);
%}

instruct prefetchw( memory mem ) %{
  match(PrefetchWrite mem);
  ins_cost(125);
  format %{ "pref $mem\t# Prefetch to temporal cache for write @ prefetchw" %}
  ins_encode %{
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if( index != 0 ) {
      if (scale == 0) {
        __ add_d(AT, as_Register(base), as_Register(index));
      } else {
        __ alsl_d(AT, as_Register(index), as_Register(base), scale - 1);
      }
    } else {
      __ move(AT, as_Register(base));
    }
    if( Assembler::is_simm(disp, 12) ) {
      __ addi_d(AT, AT, disp);
    } else {
      __ li(T4, disp);
      __ add_d(AT, AT, T4);
    }
     __ preld(8, AT, 0); //hint: 8:store
  %}
  ins_pipe(pipe_slow);
%}

// Prefetch instructions for allocation.

instruct prefetchAlloc(memory mem) %{
  match(PrefetchAllocation mem);
  ins_cost(125);
  format %{ "preld $mem\t# Prefetch allocation @ prefetchAlloc" %}
  ins_encode %{
    int  base = $mem$$base;
    int  index = $mem$$index;
    int  scale = $mem$$scale;
    int  disp = $mem$$disp;

    if (index != 0) {
      if (scale == 0) {
        __ add_d(AT, as_Register(base), as_Register(index));
      } else {
        __ alsl_d(AT, as_Register(index), as_Register(base), scale - 1);
      }

      if (Assembler::is_simm(disp, 12)) {
        __ preld(8, AT, disp);
      } else {
        __ li(T4, disp);
        __ add_d(AT, AT, T4);
        __ preld(8, AT, 0);
      }
    } else {
      if (Assembler::is_simm(disp, 12)) {
        __ preld(8, as_Register(base), disp);
      } else {
        __ li(T4, disp);
        __ add_d(AT, as_Register(base), T4);
        __ preld(8, AT, 0);
      }
    }
  %}
  ins_pipe(pipe_slow);
%}


// Call runtime without safepoint
instruct CallLeafDirect(method meth) %{
  match(CallLeaf);
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL_LEAF,runtime #@CallLeafDirect " %}
  ins_encode(Java_To_Runtime(meth));
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(4);
%}

// Load Char (16bit unsigned)
instruct loadUS(mRegI dst, memory mem) %{
  match(Set dst (LoadUS mem));

  ins_cost(125);
  format %{ "loadUS  $dst,$mem @ loadC" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_SHORT);
  %}
  ins_pipe( ialu_loadI );
%}

instruct loadUS_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadUS mem)));

  ins_cost(125);
  format %{ "loadUS  $dst,$mem @ loadUS_convI2L" %}
  ins_encode %{
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_SHORT);
  %}
  ins_pipe( ialu_loadI );
%}

// Store Char (16bit unsigned)
instruct storeC(memory mem, mRegI src) %{
  match(Set mem (StoreC mem src));

  ins_cost(125);
  format %{ "storeC  $src, $mem @ storeC" %}
  ins_encode %{
    __ loadstore_enc($src$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_CHAR);
  %}
  ins_pipe( ialu_loadI );
%}

instruct storeC_0(memory mem, immI_0 zero) %{
  match(Set mem (StoreC mem zero));

  ins_cost(125);
  format %{ "storeC  $zero, $mem @ storeC_0" %}
  ins_encode %{
     __ loadstore_enc(R0, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_SHORT);
  %}
  ins_pipe( ialu_loadI );
%}


instruct loadConF_immF_0(regF dst, immF_0 zero) %{
  match(Set dst zero);
  ins_cost(100);

  format %{ "mov  $dst, zero @ loadConF_immF_0\n"%}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;

    __ movgr2fr_w(dst, R0);
  %}
  ins_pipe( fpu_loadF );
%}


instruct loadConF(regF dst, immF src) %{
  match(Set dst src);
  ins_cost(125);

  format %{ "fld_s  $dst, $constantoffset[$constanttablebase] # load FLOAT $src from table @ loadConF" %}
  ins_encode %{
    int con_offset = $constantoffset($src);

    if (Assembler::is_simm(con_offset, 12)) {
      __ fld_s($dst$$FloatRegister, $constanttablebase, con_offset);
    } else {
      __ li(AT, con_offset);
      __ fldx_s($dst$$FloatRegister, $constanttablebase, AT);
    }
  %}
  ins_pipe( fpu_loadF );
%}


instruct loadConD_immD_0(regD dst, immD_0 zero) %{
  match(Set dst zero);
  ins_cost(100);

  format %{ "mov  $dst, zero @ loadConD_immD_0"%}
  ins_encode %{
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ movgr2fr_d(dst, R0);
  %}
  ins_pipe( fpu_loadF );
%}

instruct loadConD(regD dst, immD src) %{
  match(Set dst src);
  ins_cost(125);

  format %{ "fld_d  $dst, $constantoffset[$constanttablebase] # load DOUBLE $src from table @ loadConD" %}
  ins_encode %{
    int con_offset = $constantoffset($src);

    if (Assembler::is_simm(con_offset, 12)) {
      __ fld_d($dst$$FloatRegister, $constanttablebase, con_offset);
    } else {
      __ li(AT, con_offset);
      __ fldx_d($dst$$FloatRegister, $constanttablebase, AT);
    }
  %}
  ins_pipe( fpu_loadF );
%}

// Store register Float value (it is faster than store from FPU register)
instruct storeF_reg( memory mem, regF src) %{
  match(Set mem (StoreF mem src));

  ins_cost(50);
  format %{ "store   $mem, $src\t# store float @ storeF_reg" %}
  ins_encode %{
    __ loadstore_enc($src$$FloatRegister, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_FLOAT);
  %}
  ins_pipe( fpu_storeF );
%}

instruct storeF_immF_0( memory mem, immF_0 zero) %{
  match(Set mem (StoreF mem zero));

  ins_cost(40);
  format %{ "store   $mem, zero\t# store float @ storeF_immF_0" %}
  ins_encode %{
    __ loadstore_enc(R0, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_INT);
  %}
  ins_pipe( ialu_storeI );
%}

// Load Double
instruct loadD(regD dst, memory mem) %{
  match(Set dst (LoadD mem));

  ins_cost(150);
  format %{ "loadD   $dst, $mem #@loadD" %}
  ins_encode %{
    __ loadstore_enc($dst$$FloatRegister, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_DOUBLE);
  %}
  ins_pipe( ialu_loadI );
%}

// Load Double - UNaligned
instruct loadD_unaligned(regD dst, memory mem ) %{
  match(Set dst (LoadD_unaligned mem));
  ins_cost(250);
  // FIXME: Need more effective ldl/ldr
  format %{ "loadD_unaligned   $dst, $mem #@loadD_unaligned" %}
  ins_encode %{
    __ loadstore_enc($dst$$FloatRegister, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_DOUBLE);
  %}
  ins_pipe( ialu_loadI );
%}

instruct storeD_reg( memory mem, regD src) %{
  match(Set mem (StoreD mem src));

  ins_cost(50);
  format %{ "store   $mem, $src\t# store float @ storeD_reg" %}
  ins_encode %{
    __ loadstore_enc($src$$FloatRegister, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_DOUBLE);
  %}
  ins_pipe( fpu_storeF );
%}

instruct storeD_immD_0( memory mem, immD_0 zero) %{
  match(Set mem (StoreD mem zero));

  ins_cost(40);
  format %{ "store   $mem, zero\t# store float @ storeD_immD_0" %}
  ins_encode %{
    __ loadstore_enc(R0, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_LONG);
  %}
  ins_pipe( ialu_storeI );
%}

instruct loadSSI(mRegI dst, stackSlotI src)
%{
  match(Set dst src);

  ins_cost(125);
  format %{ "ld_w    $dst, $src\t# int stk @ loadSSI" %}
  ins_encode %{
    guarantee( Assembler::is_simm($src$$disp, 12), "disp too long (loadSSI) !");
    __ ld_w($dst$$Register, SP, $src$$disp);
  %}
  ins_pipe(ialu_loadI);
%}

instruct storeSSI(stackSlotI dst, mRegI src)
%{
  match(Set dst src);

  ins_cost(100);
  format %{ "st_w    $dst, $src\t# int stk @ storeSSI" %}
  ins_encode %{
    guarantee( Assembler::is_simm($dst$$disp, 12), "disp too long (storeSSI) !");
    __ st_w($src$$Register, SP, $dst$$disp);
  %}
  ins_pipe(ialu_storeI);
%}

instruct loadSSL(mRegL dst, stackSlotL src)
%{
  match(Set dst src);

  ins_cost(125);
  format %{ "ld_d    $dst, $src\t# long stk @ loadSSL" %}
  ins_encode %{
    guarantee( Assembler::is_simm($src$$disp, 12), "disp too long (loadSSL) !");
    __ ld_d($dst$$Register, SP, $src$$disp);
  %}
  ins_pipe(ialu_loadI);
%}

instruct storeSSL(stackSlotL dst, mRegL src)
%{
  match(Set dst src);

  ins_cost(100);
  format %{ "st_d    $dst, $src\t# long stk @ storeSSL" %}
  ins_encode %{
    guarantee( Assembler::is_simm($dst$$disp, 12), "disp too long (storeSSL) !");
    __ st_d($src$$Register, SP, $dst$$disp);
  %}
  ins_pipe(ialu_storeI);
%}

instruct loadSSP(mRegP dst, stackSlotP src)
%{
  match(Set dst src);

  ins_cost(125);
  format %{ "ld_d    $dst, $src\t# ptr stk @ loadSSP" %}
  ins_encode %{
    guarantee( Assembler::is_simm($src$$disp, 12), "disp too long (loadSSP) !");
    __ ld_d($dst$$Register, SP, $src$$disp);
  %}
  ins_pipe(ialu_loadI);
%}

instruct storeSSP(stackSlotP dst, mRegP src)
%{
  match(Set dst src);

  ins_cost(100);
  format %{ "sd    $dst, $src\t# ptr stk @ storeSSP" %}
  ins_encode %{
    guarantee( Assembler::is_simm($dst$$disp, 12), "disp too long (storeSSP) !");
    __ st_d($src$$Register, SP, $dst$$disp);
  %}
  ins_pipe(ialu_storeI);
%}

instruct loadSSF(regF dst, stackSlotF src)
%{
  match(Set dst src);

  ins_cost(125);
  format %{ "fld_s   $dst, $src\t# float stk @ loadSSF" %}
  ins_encode %{
    guarantee( Assembler::is_simm($src$$disp, 12), "disp too long (loadSSF) !");
    __ fld_s($dst$$FloatRegister, SP, $src$$disp);
  %}
  ins_pipe(ialu_loadI);
%}

instruct storeSSF(stackSlotF dst, regF src)
%{
  match(Set dst src);

  ins_cost(100);
  format %{ "fst_s    $dst, $src\t# float stk @ storeSSF" %}
  ins_encode %{
    guarantee( Assembler::is_simm($dst$$disp, 12), "disp too long (storeSSF) !");
    __ fst_s($src$$FloatRegister, SP, $dst$$disp);
  %}
  ins_pipe(fpu_storeF);
%}

// Use the same format since predicate() can not be used here.
instruct loadSSD(regD dst, stackSlotD src)
%{
  match(Set dst src);

  ins_cost(125);
  format %{ "fld_d   $dst, $src\t# double stk @ loadSSD" %}
  ins_encode %{
    guarantee( Assembler::is_simm($src$$disp, 12), "disp too long (loadSSD) !");
    __ fld_d($dst$$FloatRegister, SP, $src$$disp);
  %}
  ins_pipe(ialu_loadI);
%}

instruct storeSSD(stackSlotD dst, regD src)
%{
  match(Set dst src);

  ins_cost(100);
  format %{ "sdc1    $dst, $src\t# double stk @ storeSSD" %}
  ins_encode %{
    guarantee( Assembler::is_simm($dst$$disp, 12), "disp too long (storeSSD) !");
    __ fst_d($src$$FloatRegister, SP, $dst$$disp);
  %}
  ins_pipe(fpu_storeF);
%}

instruct cmpFastLock(FlagsReg cr, mRegP object, mRegP box, mRegI tmp, mRegI scr) %{
  match(Set cr (FastLock object box));
  effect(TEMP tmp, TEMP scr);
  ins_cost(300);
  format %{ "FASTLOCK $cr <-- $object, $box, $tmp, $scr #@ cmpFastLock" %}
  ins_encode %{
    __ fast_lock($object$$Register, $box$$Register, $cr$$Register, $tmp$$Register, $scr$$Register);
  %}

  ins_pipe( pipe_slow );
  ins_pc_relative(1);
%}

instruct cmpFastUnlock(FlagsReg cr, mRegP object, mRegP box, mRegI tmp, mRegI scr) %{
  match(Set cr (FastUnlock object box));
  effect(TEMP tmp, TEMP scr);
  ins_cost(300);
  format %{ "FASTUNLOCK $cr <-- $object, $box, $tmp #@cmpFastUnlock" %}
  ins_encode %{
    __ fast_unlock($object$$Register, $box$$Register, $cr$$Register, $tmp$$Register, $scr$$Register);
  %}

  ins_pipe( pipe_slow );
  ins_pc_relative(1);
%}

// Store CMS card-mark Immediate 0
instruct storeImmCM_order(memory mem, immI_0 zero) %{
  match(Set mem (StoreCM mem zero));
  predicate(UseConcMarkSweepGC && !UseCondCardMark);
  ins_cost(100);
  format %{ "StoreCM MEMBAR storestore\n\t"
            "st_b   $mem, zero\t! card-mark imm0" %}
  ins_encode %{
    __ membar(__ StoreStore);
    __ loadstore_enc(R0, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_BYTE);
  %}
  ins_pipe( ialu_storeI );
%}

instruct storeImmCM(memory mem, immI_0 zero) %{
  match(Set mem (StoreCM mem zero));

  ins_cost(150);
  format %{ "st_b   $mem, zero\t! card-mark imm0" %}
  ins_encode %{
    __ loadstore_enc(R0, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_BYTE);
  %}
  ins_pipe( ialu_storeI );
%}

// Die now
instruct ShouldNotReachHere( )
%{
  match(Halt);
  ins_cost(300);

  // Use the following format syntax
  format %{ "ILLTRAP   ;#@ShouldNotReachHere" %}
  ins_encode %{
    // Here we should emit illtrap!
    __ brk(18);
  %}
  ins_pipe( pipe_jump );
%}

instruct leaP12Narrow(mRegP dst, indOffset12Narrow mem)
%{
  predicate(Universe::narrow_oop_shift() == 0);
  match(Set dst mem);

  ins_cost(110);
  format %{ "leaq    $dst, $mem\t# ptr off12narrow @ leaP12Narrow" %}
  ins_encode %{
    Register  dst  = $dst$$Register;
    Register  base = as_Register($mem$$base);
    int       disp = $mem$$disp;

    __ addi_d(dst, base, disp);
  %}
  ins_pipe( ialu_regI_imm16 );
%}

instruct leaPIdxScale(mRegP dst, mRegP reg, mRegLorI2L lreg, immI_0_3 scale)
%{
  match(Set dst (AddP reg (LShiftL lreg scale)));

  ins_cost(110);
  format %{ "leaq    $dst, [$reg + $lreg << $scale]\t# @ leaPIdxScale" %}
  ins_encode %{
    Register  dst   = $dst$$Register;
    Register  base  = $reg$$Register;
    Register  index = $lreg$$Register;
    int       scale = $scale$$constant;

    if (scale == 0) {
       __ add_d($dst$$Register, $reg$$Register, index);
    } else {
       __ alsl_d(dst, index, base, scale - 1);
    }
 %}

  ins_pipe( ialu_regI_imm16 );
%}


// ============================================================================
// The 2nd slow-half of a subtype check.  Scan the subklass's 2ndary superklass
// array for an instance of the superklass.  Set a hidden internal cache on a
// hit (cache is checked with exposed code in gen_subtype_check()).  Return
// NZ for a miss or zero for a hit.  The encoding ALSO sets flags.
instruct partialSubtypeCheck( mRegP result, no_T8_mRegP sub, no_T8_mRegP super, mT8RegI tmp ) %{
  match(Set result (PartialSubtypeCheck sub super));
  effect(KILL tmp);
  ins_cost(1100);  // slightly larger than the next version
  format %{ "partialSubtypeCheck result=$result, sub=$sub, super=$super, tmp=$tmp " %}

  ins_encode( enc_PartialSubtypeCheck(result, sub, super, tmp) );
  ins_pipe( pipe_slow );
%}

// Conditional-store of the updated heap-top.
// Used during allocation of the shared heap.

instruct storePConditional(memory heap_top_ptr, mRegP oldval, mRegP newval, FlagsReg cr) %{
  match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));

  format %{ "move AT, $newval\n\t"
            "sc_d $heap_top_ptr, AT\t# (ptr) @storePConditional \n\t"
            "move $cr, AT\n" %}
  ins_encode%{
    Register oldval = $oldval$$Register;
    Register newval = $newval$$Register;
    Address addr(as_Register($heap_top_ptr$$base), $heap_top_ptr$$disp);

    int     index = $heap_top_ptr$$index;
    int     scale = $heap_top_ptr$$scale;
    int      disp = $heap_top_ptr$$disp;

    guarantee(Assembler::is_simm(disp, 12), "");

    if (index != 0) {
      __ stop("in storePConditional: index != 0");
    } else {
      __ move(AT, newval);
      __ sc_d(AT, addr);
      __ move($cr$$Register, AT);
    }
  %}
  ins_pipe(long_memory_op);
%}

// Conditional-store of an int value.
// AT flag is set on success, reset otherwise.
instruct storeIConditional(memory mem, mRegI oldval, mRegI newval, FlagsReg cr) %{
  match(Set cr (StoreIConditional mem (Binary oldval newval)));
  format %{ "CMPXCHG  $newval, $mem, $oldval \t# @storeIConditional" %}

  ins_encode %{
    Register oldval = $oldval$$Register;
    Register newval = $newval$$Register;
    Register cr     = $cr$$Register;
    Address  addr(as_Register($mem$$base), $mem$$disp);

    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;

    guarantee(Assembler::is_simm(disp, 12), "");

    if (index != 0) {
      __ stop("in storeIConditional: index != 0");
    } else {
      if (cr != addr.base() && cr != oldval && cr != newval) {
        __ cmpxchg32(addr, oldval, newval, cr, true, false, true);
      } else {
        __ cmpxchg32(addr, oldval, newval, AT, true, false, true);
        __ move(cr, AT);
      }
    }
  %}

  ins_pipe(long_memory_op);
%}

// Conditional-store of a long value.
// ZF flag is set on success, reset otherwise.  Implemented with a CMPXCHG.
instruct storeLConditional(memory mem, mRegL oldval, mRegL newval, FlagsReg cr)
%{
  match(Set cr (StoreLConditional mem (Binary oldval newval)));

  format %{ "cmpxchg $mem, $newval\t# If $oldval == $mem then store $newval into $mem" %}
  ins_encode%{
    Register oldval = $oldval$$Register;
    Register newval = $newval$$Register;
    Register cr     = $cr$$Register;
    Address addr(as_Register($mem$$base), $mem$$disp);

    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;

    guarantee(Assembler::is_simm(disp, 12), "");

    if (index != 0) {
      __ stop("in storeIConditional: index != 0");
    } else {
      if (cr != addr.base() && cr != oldval && cr != newval) {
        __ cmpxchg(addr, oldval, newval, cr, false, true);
      } else {
        __ cmpxchg(addr, oldval, newval, AT, false, true);
        __ move(cr, AT);
      }
    }
  %}
  ins_pipe(long_memory_op);
%}

// Implement LoadPLocked. Must be ordered against changes of the memory location
// by storePConditional.
instruct loadPLocked(mRegP dst, memory mem) %{
  match(Set dst (LoadPLocked mem));
  ins_cost(MEMORY_REF_COST);

  format %{ "ll_d    $dst, $mem #@loadPLocked\n\t" %}
  size(12);
  ins_encode %{
    relocInfo::relocType disp_reloc = $mem->disp_reloc();
    assert(disp_reloc == relocInfo::none, "cannot have disp");
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_LINKED_LONG);
  %}
  ins_pipe( ialu_loadI );
%}


instruct compareAndSwapI(mRegI res, mRegP mem_ptr, mRegI oldval, mRegI newval) %{
  match(Set res (CompareAndSwapI mem_ptr (Binary oldval newval)));
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapI" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);

    if (res != addr.base() && res != oldval && res != newval) {
      __ cmpxchg32(addr, oldval, newval, res, true, false, true);
    } else {
      __ cmpxchg32(addr, oldval, newval, AT, true, false, true);
      __ move(res, AT);
    }
  %}
  ins_pipe(long_memory_op);
%}

instruct compareAndSwapL(mRegI res, mRegP mem_ptr, mRegL oldval, mRegL newval) %{
  predicate(VM_Version::supports_cx8());
  match(Set res (CompareAndSwapL mem_ptr (Binary oldval newval)));
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapL" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);

    if (res != addr.base() && res != oldval && res != newval) {
      __ cmpxchg(addr, oldval, newval, res, false, true);
    } else {
      __ cmpxchg(addr, oldval, newval, AT, false, true);
      __ move(res, AT);
    }
  %}
  ins_pipe(long_memory_op);
%}

instruct compareAndSwapP(mRegI res, mRegP mem_ptr, mRegP oldval, mRegP newval) %{
  match(Set res (CompareAndSwapP mem_ptr (Binary oldval newval)));
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapP" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);

    if (res != addr.base() && res != oldval && res != newval) {
      __ cmpxchg(addr, oldval, newval, res, false, true);
    } else {
      __ cmpxchg(addr, oldval, newval, AT, false, true);
      __ move(res, AT);
    }
  %}
  ins_pipe(long_memory_op);
%}

instruct compareAndSwapN(mRegI res, mRegP mem_ptr, mRegN oldval, mRegN newval) %{
  match(Set res (CompareAndSwapN mem_ptr (Binary oldval newval)));
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapN" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);

    if (res != addr.base() && res != oldval && res != newval) {
      __ cmpxchg32(addr, oldval, newval, res, false, false, true);
    } else {
      __ cmpxchg32(addr, oldval, newval, AT, false, false, true);
      __ move(res, AT);
    }
  %}
  ins_pipe(long_memory_op);
%}

//----------Max and Min--------------------------------------------------------

// Min Register with Register (generic version)
instruct minI_Reg_Reg(mRegI dst, mRegI src) %{
  match(Set dst (MinI dst src));
  //effect(KILL flags);
  ins_cost(80);

  format %{ "MIN    $dst, $src @minI_Reg_Reg" %}
  ins_encode %{
    Register dst   = $dst$$Register;
    Register src   = $src$$Register;

    __ slt(AT, src, dst);
    __ masknez(dst, dst, AT);
    __ maskeqz(AT, src, AT);
    __ OR(dst, dst, AT);
  %}

  ins_pipe( pipe_slow );
%}

// Max Register with Register (generic version)
instruct maxI_Reg_Reg(mRegI dst, mRegI src) %{
  match(Set dst (MaxI dst src));
  ins_cost(80);

  format %{ "MAX    $dst, $src @maxI_Reg_Reg" %}

  ins_encode %{
    Register dst   = $dst$$Register;
    Register src   = $src$$Register;

    __ slt(AT, dst, src);
    __ masknez(dst, dst, AT);
    __ maskeqz(AT, src, AT);
    __ OR(dst, dst, AT);
  %}

  ins_pipe( pipe_slow );
%}

instruct maxI_Reg_zero(mRegI dst, immI_0 zero) %{
  match(Set dst (MaxI dst zero));
  ins_cost(50);

  format %{ "MAX    $dst, 0 @maxI_Reg_zero" %}

  ins_encode %{
    Register dst   = $dst$$Register;

    __ slt(AT, dst, R0);
    __ masknez(dst, dst, AT);
  %}

  ins_pipe( pipe_slow );
%}

instruct zerox_long_reg_reg(mRegL dst, mRegL src, immL_MaxUI mask)
%{
  match(Set dst (AndL src mask));

  format %{ "movl    $dst, $src\t# zero-extend long @ zerox_long_reg_reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;

    __ bstrpick_d(dst, src, 31, 0);
  %}
  ins_pipe(ialu_regI_regI);
%}

instruct combine_i2l(mRegL dst, mRegI src1, immL_MaxUI mask, mRegI src2, immI_32 shift32)
%{
  match(Set dst (OrL (AndL (ConvI2L src1) mask) (LShiftL (ConvI2L src2) shift32)));

  format %{ "combine_i2l    $dst, $src2(H), $src1(L) @ combine_i2l" %}
  ins_encode %{
    Register dst  = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    if (src1 == dst) {
       __ bstrins_d(dst, src2, 63, 32);
    } else if (src2 == dst) {
       __ slli_d(dst, dst, 32);
       __ bstrins_d(dst, src1, 31, 0);
    } else {
       __ bstrpick_d(dst, src1, 31, 0);
       __ bstrins_d(dst, src2, 63, 32);
    }
  %}
  ins_pipe(ialu_regI_regI);
%}

// Zero-extend convert int to long
instruct convI2L_reg_reg_zex(mRegL dst, mRegI src, immL_MaxUI mask)
%{
  match(Set dst (AndL (ConvI2L src) mask));

  format %{ "movl    $dst, $src\t# i2l zero-extend @ convI2L_reg_reg_zex" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;

    __ bstrpick_d(dst, src, 31, 0);
  %}
  ins_pipe(ialu_regI_regI);
%}

instruct convL2I2L_reg_reg_zex(mRegL dst, mRegL src, immL_MaxUI mask)
%{
  match(Set dst (AndL (ConvI2L (ConvL2I src)) mask));

  format %{ "movl    $dst, $src\t# i2l zero-extend @ convL2I2L_reg_reg_zex" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src$$Register;

    __ bstrpick_d(dst, src, 31, 0);
  %}
  ins_pipe(ialu_regI_regI);
%}

// Match loading integer and casting it to unsigned int in long register.
// LoadI + ConvI2L + AndL 0xffffffff.
instruct loadUI2L_rmask(mRegL dst, memory mem, immL_MaxUI mask) %{
  match(Set dst (AndL (ConvI2L (LoadI mem)) mask));

  format %{ "ld_wu     $dst, $mem \t// zero-extend to long @ loadUI2L_rmask" %}
  ins_encode %{
    relocInfo::relocType disp_reloc = $mem->disp_reloc();
    assert(disp_reloc == relocInfo::none, "cannot have disp");
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_INT);
  %}
  ins_pipe(ialu_loadI);
%}

instruct loadUI2L_lmask(mRegL dst, memory mem, immL_MaxUI mask) %{
  match(Set dst (AndL mask (ConvI2L (LoadI mem))));

  format %{ "ld_wu     $dst, $mem \t// zero-extend to long @ loadUI2L_lmask" %}
  ins_encode %{
    relocInfo::relocType disp_reloc = $mem->disp_reloc();
    assert(disp_reloc == relocInfo::none, "cannot have disp");
    __ loadstore_enc($dst$$Register, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_U_INT);
  %}
  ins_pipe(ialu_loadI);
%}


// ============================================================================
// Safepoint Instruction
instruct safePoint_poll_reg(mRegP poll) %{
  match(SafePoint poll);
  predicate(false);
  effect(USE poll);

  ins_cost(125);
  format %{ "Safepoint @ [$poll] : poll for GC @ safePoint_poll_reg" %}

  ins_encode %{
    Register poll_reg = $poll$$Register;

    __ block_comment("Safepoint:");
    __ relocate(relocInfo::poll_type);
    __ ld_w(AT, poll_reg, 0);
  %}

  ins_pipe( ialu_storeI );
%}

instruct safePoint_poll() %{
  match(SafePoint);

  ins_cost(105);
  format %{ "poll for GC @ safePoint_poll" %}

  ins_encode %{
    __ block_comment("Safepoint:");
    __ li(T4, (long)os::get_polling_page());
    __ relocate(relocInfo::poll_type);
    __ ld_w(AT, T4, 0);
  %}

  ins_pipe( ialu_storeI );
%}

//----------Arithmetic Conversion Instructions---------------------------------

instruct roundFloat_nop(regF dst)
%{
  match(Set dst (RoundFloat dst));

  ins_cost(0);
  ins_encode();
  ins_pipe(empty);
%}

instruct roundDouble_nop(regD dst)
%{
  match(Set dst (RoundDouble dst));

  ins_cost(0);
  ins_encode();
  ins_pipe(empty);
%}

//---------- Zeros Count Instructions ------------------------------------------
// CountLeadingZerosINode CountTrailingZerosINode
instruct countLeadingZerosI(mRegI dst, mRegI src) %{
  match(Set dst (CountLeadingZerosI src));

  format %{ "clz_w  $dst, $src\t# count leading zeros (int)" %}
  ins_encode %{
    __ clz_w($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct countLeadingZerosL(mRegI dst, mRegL src) %{
  match(Set dst (CountLeadingZerosL src));

  format %{ "clz_d  $dst, $src\t# count leading zeros (long)" %}
  ins_encode %{
    __ clz_d($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct countTrailingZerosI(mRegI dst, mRegI src) %{
  match(Set dst (CountTrailingZerosI src));

  format %{ "ctz_w    $dst, $src\t# count trailing zeros (int)" %}
  ins_encode %{
    __ ctz_w($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct countTrailingZerosL(mRegI dst, mRegL src) %{
  match(Set dst (CountTrailingZerosL src));

  format %{ "ctz_d    $dst, $src\t# count trailing zeros (long)" %}
  ins_encode %{
    __ ctz_d($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

// ====================VECTOR INSTRUCTIONS=====================================

// --------------------------------- Load -------------------------------------

instruct loadV16(vecX dst, memory mem) %{
  predicate(n->as_LoadVector()->memory_size() == 16);
  match(Set dst (LoadVector mem));
  format %{ "vload    $dst, $mem\t# @loadV16" %}
  ins_encode %{
    __ loadstore_enc($dst$$FloatRegister, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_VECTORX);
  %}
  ins_pipe( pipe_slow );
%}

instruct loadV32(vecY dst, memory mem) %{
  predicate(n->as_LoadVector()->memory_size() == 32);
  match(Set dst (LoadVector mem));
  format %{ "xvload    $dst, $mem\t# @loadV32" %}
  ins_encode %{
    __ loadstore_enc($dst$$FloatRegister, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::LOAD_VECTORY);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- Store ------------------------------------

instruct storeV16(memory mem, vecX src) %{
  predicate(n->as_StoreVector()->memory_size() == 16);
  match(Set mem (StoreVector mem src));
  format %{ "vstore    $src, $mem\t# @storeV16" %}
  ins_encode %{
    __ loadstore_enc($src$$FloatRegister, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_VECTORX);
  %}
  ins_pipe( pipe_slow );
%}

instruct storeV32(memory mem, vecY src) %{
  predicate(n->as_StoreVector()->memory_size() == 32);
  match(Set mem (StoreVector mem src));
  format %{ "xvstore    $src, $mem\t# @storeV32" %}
  ins_encode %{
    __ loadstore_enc($src$$FloatRegister, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp, MacroAssembler::STORE_VECTORY);
  %}
  ins_pipe( pipe_slow );
%}

// ------------------------------- Replicate ----------------------------------

instruct repl16B(vecX dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (ReplicateB src));
  format %{ "vreplgr2vr.b    $dst, $src\t# @repl16B" %}
  ins_encode %{
    __ vreplgr2vr_b($dst$$FloatRegister, $src$$Register);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl16B_imm(vecX dst, immI_M128_255 imm) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (ReplicateB imm));
  format %{ "vldi    $dst, $imm\t# @repl16B_imm" %}
  ins_encode %{
    __ vldi($dst$$FloatRegister, ($imm$$constant & 0xff));
  %}
  ins_pipe( pipe_slow );
%}

instruct repl8S(vecX dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (ReplicateS src));
  format %{ "vreplgr2vr.h    $dst, $src\t# @repl8S" %}
  ins_encode %{
    __ vreplgr2vr_h($dst$$FloatRegister, $src$$Register);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl8S_imm(vecX dst, immI10 imm) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (ReplicateS imm));
  format %{ "vldi    $dst, $imm\t# @repl8S_imm" %}
  ins_encode %{
    __ vldi($dst$$FloatRegister, (0b001 << 10 ) | ($imm$$constant & 0x3ff));
  %}
  ins_pipe( pipe_slow );
%}

instruct repl4I(vecX dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (ReplicateI src));
  format %{ "vreplgr2vr.w    $dst, $src\t# @repl4I" %}
  ins_encode %{
    __ vreplgr2vr_w($dst$$FloatRegister, $src$$Register);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl4I_imm(vecX dst, immI10 imm) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (ReplicateI imm));
  format %{ "vldi    $dst, $imm\t# @repl4I_imm" %}
  ins_encode %{
    __ vldi($dst$$FloatRegister, (0b010 << 10 ) | ($imm$$constant & 0x3ff));
  %}
  ins_pipe( pipe_slow );
%}

instruct repl2L(vecX dst, mRegL src) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (ReplicateL src));
  format %{ "vreplgr2vr.d    $dst, $src\t# @repl2L" %}
  ins_encode %{
    __ vreplgr2vr_d($dst$$FloatRegister, $src$$Register);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl2L_imm(vecX dst, immL10 imm) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (ReplicateL imm));
  format %{ "vldi    $dst, $imm\t# @repl2L_imm" %}
  ins_encode %{
    __ vldi($dst$$FloatRegister, (0b011 << 10 ) | ($imm$$constant & 0x3ff));
  %}
  ins_pipe( pipe_slow );
%}

instruct repl4F(vecX dst, regF src) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (ReplicateF src));
  format %{ "vreplvei.w    $dst, $src, 0\t# @repl4F" %}
  ins_encode %{
    __ vreplvei_w($dst$$FloatRegister, $src$$FloatRegister, 0);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl2D(vecX dst, regD src) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (ReplicateD src));
  format %{ "vreplvei.d    $dst, $src, 0\t# @repl2D" %}
  ins_encode %{
    __ vreplvei_d($dst$$FloatRegister, $src$$FloatRegister, 0);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl32B(vecY dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (ReplicateB src));
  format %{ "xvreplgr2vr.b    $dst, $src\t# @repl32B" %}
  ins_encode %{
    __ xvreplgr2vr_b($dst$$FloatRegister, $src$$Register);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl32B_imm(vecY dst, immI_M128_255 imm) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (ReplicateB imm));
  format %{ "xvldi    $dst, $imm\t# @repl32B_imm" %}
  ins_encode %{
    __ xvldi($dst$$FloatRegister, ($imm$$constant & 0xff));
  %}
  ins_pipe( pipe_slow );
%}

instruct repl16S(vecY dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (ReplicateS src));
  format %{ "xvreplgr2vr.h    $dst, $src\t# @repl16S" %}
  ins_encode %{
    __ xvreplgr2vr_h($dst$$FloatRegister, $src$$Register);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl16S_imm(vecY dst, immI10 imm) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (ReplicateS imm));
  format %{ "xvldi    $dst, $imm\t# @repl16S_imm" %}
  ins_encode %{
    __ xvldi($dst$$FloatRegister, (0b001 << 10 ) | ($imm$$constant & 0x3ff));
  %}
  ins_pipe( pipe_slow );
%}

instruct repl8I(vecY dst, mRegI src) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (ReplicateI src));
  format %{ "xvreplgr2vr.w    $dst, $src\t# @repl8I" %}
  ins_encode %{
    __ xvreplgr2vr_w($dst$$FloatRegister, $src$$Register);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl8I_imm(vecY dst, immI10 imm) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (ReplicateI imm));
  format %{ "xvldi    $dst, $imm\t# @repl8I_imm" %}
  ins_encode %{
    __ xvldi($dst$$FloatRegister, (0b010 << 10 ) | ($imm$$constant & 0x3ff));
  %}
  ins_pipe( pipe_slow );
%}

instruct repl4L(vecY dst, mRegL src) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (ReplicateL src));
  format %{ "xvreplgr2vr.d    $dst, $src\t# @repl4L" %}
  ins_encode %{
    __ xvreplgr2vr_d($dst$$FloatRegister, $src$$Register);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl4L_imm(vecY dst, immL10 imm) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (ReplicateL imm));
  format %{ "xvldi    $dst, $imm\t# @repl4L_imm" %}
  ins_encode %{
    __ xvldi($dst$$FloatRegister, (0b011 << 10 ) | ($imm$$constant & 0x3ff));
  %}
  ins_pipe( pipe_slow );
%}

instruct repl8F(vecY dst, regF src) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (ReplicateF src));
  format %{ "xvreplve0.w    $dst, $src\t# @repl8F" %}
  ins_encode %{
    __ xvreplve0_w($dst$$FloatRegister, $src$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct repl4D(vecY dst, regD src) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (ReplicateD src));
  format %{ "xvreplve0.d    $dst, $src\t# @repl4D" %}
  ins_encode %{
    __ xvreplve0_d($dst$$FloatRegister, $src$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- ADD --------------------------------------

instruct add16B(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (AddVB src1 src2));
  format %{ "vadd.b    $dst, $src1, $src2\t# @add16B" %}
  ins_encode %{
    __ vadd_b($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add16B_imm(vecX dst, vecX src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (AddVB src (ReplicateB imm)));
  format %{ "vaddi.bu    $dst, $src, $imm\t# @add16B_imm" %}
  ins_encode %{
    __ vaddi_bu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct add8S(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (AddVS src1 src2));
  format %{ "vadd.h    $dst, $src1, $src2\t# @add8S" %}
  ins_encode %{
    __ vadd_h($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add8S_imm(vecX dst, vecX src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (AddVS src (ReplicateS imm)));
  format %{ "vaddi.hu    $dst, $src, $imm\t# @add8S_imm" %}
  ins_encode %{
    __ vaddi_hu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct add4I(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (AddVI src1 src2));
  format %{ "vadd.w    $dst, $src1, src2\t# @add4I" %}
  ins_encode %{
    __ vadd_w($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add4I_imm(vecX dst, vecX src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (AddVI src (ReplicateI imm)));
  format %{ "vaddi.wu    $dst, $src, $imm\t# @add4I_imm" %}
  ins_encode %{
    __ vaddi_wu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct add2L(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (AddVL src1 src2));
  format %{ "vadd.d    $dst, $src1, $src2\t# @add2L" %}
  ins_encode %{
    __ vadd_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add2L_imm(vecX dst, vecX src, immLU5 imm) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (AddVL src (ReplicateL imm)));
  format %{ "vaddi.du    $dst, $src, $imm\t# @add2L_imm" %}
  ins_encode %{
    __ vaddi_du($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct add4F(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (AddVF src1 src2));
  format %{ "vfadd.s    $dst, $src1, $src2\t# @add4F" %}
  ins_encode %{
    __ vfadd_s($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add2D(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (AddVD src1 src2));
  format %{ "vfadd.d    $dst, $src1, $src2\t# @add2D" %}
  ins_encode %{
    __ vfadd_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add32B(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (AddVB src1 src2));
  format %{ "xvadd.b    $dst, $src1, $src2\t# @add32B" %}
  ins_encode %{
    __ xvadd_b($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add32B_imm(vecY dst, vecY src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (AddVB src (ReplicateB imm)));
  format %{ "xvaddi.bu    $dst, $src, $imm\t# @add32B_imm" %}
  ins_encode %{
    __ xvaddi_bu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct add16S(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (AddVS src1 src2));
  format %{ "xvadd.h    $dst, $src1, $src2\t# @add16S" %}
  ins_encode %{
    __ xvadd_h($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add16S_imm(vecY dst, vecY src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (AddVS src (ReplicateS imm)));
  format %{ "xvaddi.hu    $dst, $src, $imm\t# @add16S_imm" %}
  ins_encode %{
    __ xvaddi_hu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct add8I(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (AddVI src1 src2));
  format %{ "xvadd.wu    $dst, $src1, $src2\t# @add8I" %}
  ins_encode %{
    __ xvadd_w($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add8I_imm(vecY dst, vecY src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (AddVI src (ReplicateI imm)));
  format %{ "xvaddi.wu    $dst, $src, $imm\t# @add8I_imm" %}
  ins_encode %{
    __ xvaddi_wu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct add4L(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (AddVL src1 src2));
  format %{ "xvadd.d    $dst, $src1, $src2\t# @add4L" %}
  ins_encode %{
    __ xvadd_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add4L_imm(vecY dst, vecY src, immLU5 imm) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (AddVL src (ReplicateL imm)));
  format %{ "xvaddi.du    $dst, $src, $imm\t# @add4L_imm" %}
  ins_encode %{
    __ xvaddi_du($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct add8F(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (AddVF src1 src2));
  format %{ "xvfadd.s    $dst, $src1, $src2\t# @add8F" %}
  ins_encode %{
    __ xvfadd_s($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct add4D(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (AddVD src1 src2));
  format %{ "xvfadd.d    $dst, $src1, $src2\t# @add4D" %}
  ins_encode %{
    __ xvfadd_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- SUB --------------------------------------

instruct sub16B(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (SubVB src1 src2));
  format %{ "vsub.b    $dst, $src1, $src2\t# @sub16B" %}
  ins_encode %{
    __ vsub_b($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub16B_imm(vecX dst, vecX src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (SubVB src (ReplicateB imm)));
  format %{ "vsubi.bu    $dst, $src, $imm\t# @sub16B_imm" %}
  ins_encode %{
    __ vsubi_bu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub8S(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (SubVS src1 src2));
  format %{ "vsub.h    $dst, $src1, $src2\t# @sub8S" %}
  ins_encode %{
    __ vsub_h($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub8S_imm(vecX dst, vecX src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (SubVS src (ReplicateS imm)));
  format %{ "vsubi.hu    $dst, $src, $imm\t# @sub8S_imm" %}
  ins_encode %{
    __ vsubi_hu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub4I(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (SubVI src1 src2));
  format %{ "vsub.w    $dst, $src1, src2\t# @sub4I" %}
  ins_encode %{
    __ vsub_w($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub4I_imm(vecX dst, vecX src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (SubVI src (ReplicateI imm)));
  format %{ "vsubi.wu    $dst, $src, $imm\t# @sub4I_imm" %}
  ins_encode %{
    __ vsubi_wu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub2L(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (SubVL src1 src2));
  format %{ "vsub.d    $dst, $src1, $src2\t# @sub2L" %}
  ins_encode %{
    __ vsub_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub2L_imm(vecX dst, vecX src, immLU5 imm) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (SubVL src (ReplicateL imm)));
  format %{ "vsubi.du    $dst, $src, $imm\t# @sub2L_imm" %}
  ins_encode %{
    __ vsubi_du($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub4F(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (SubVF src1 src2));
  format %{ "vfsub.s    $dst, $src1, $src2\t# @sub4F" %}
  ins_encode %{
    __ vfsub_s($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub2D(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (SubVD src1 src2));
  format %{ "vfsub.d    $dst, $src1, $src2\t# @sub2D" %}
  ins_encode %{
    __ vfsub_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub32B(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (SubVB src1 src2));
  format %{ "xvsub.b    $dst, $src1, $src2\t# @sub32B" %}
  ins_encode %{
    __ xvsub_b($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub32B_imm(vecY dst, vecY src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (SubVB src (ReplicateB imm)));
  format %{ "xvsubi.bu    $dst, $src, $imm\t# @sub32B_imm" %}
  ins_encode %{
    __ xvsubi_bu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub16S(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (SubVS src1 src2));
  format %{ "xvsub.h    $dst, $src1, $src2\t# @sub16S" %}
  ins_encode %{
    __ xvsub_h($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub16S_imm(vecY dst, vecY src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (SubVS src (ReplicateS imm)));
  format %{ "xvsubi.hu    $dst, $src, $imm\t# @sub16S_imm" %}
  ins_encode %{
    __ xvsubi_hu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub8I(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (SubVI src1 src2));
  format %{ "xvsub.w    $dst, $src1, $src2\t# @sub8I" %}
  ins_encode %{
    __ xvsub_w($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub8I_imm(vecY dst, vecY src, immIU5 imm) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (SubVI src (ReplicateI imm)));
  format %{ "xvsubi.wu    $dst, $src, $imm\t# @sub8I_imm" %}
  ins_encode %{
    __ xvsubi_wu($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub4L(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (SubVL src1 src2));
  format %{ "xvsub.d    $dst, $src1, $src2\t# @sub4L" %}
  ins_encode %{
    __ xvsub_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub4L_imm(vecY dst, vecY src, immLU5 imm) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (SubVL src (ReplicateL imm)));
  format %{ "xvsubi.du    $dst, $src, $imm\t# @sub4L_imm" %}
  ins_encode %{
    __ xvsubi_du($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub8F(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (SubVF src1 src2));
  format %{ "xvfsub.s    $dst, $src1, $src2\t# @sub8F" %}
  ins_encode %{
    __ xvfsub_s($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sub4D(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (SubVD src1 src2));
  format %{ "xvfsub.d    $dst,$src1,$src2\t# @sub4D" %}
  ins_encode %{
    __ xvfsub_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- MUL --------------------------------------
instruct mul8S(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (MulVS src1 src2));
  format %{ "vmul.h    $dst, $src1, $src2\t# @mul8S" %}
  ins_encode %{
    __ vmul_h($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct mul4I(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (MulVI src1 src2));
  format %{ "vmul.w    $dst, $src1, $src2\t# @mul4I" %}
  ins_encode %{
    __ vmul_w($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct mul4F(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (MulVF src1 src2));
  format %{ "vfmul.s    $dst, $src1, $src2\t# @mul4F" %}
  ins_encode %{
    __ vfmul_s($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct mul2D(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (MulVD src1 src2));
  format %{ "vfmul.d    $dst, $src1, $src2\t# @mul2D" %}
  ins_encode %{
    __ vfmul_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct mul16S(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (MulVS src1 src2));
  format %{ "xvmul.h    $dst, $src1, $src2\t# @mul16S" %}
  ins_encode %{
    __ xvmul_h($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct mul8I(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (MulVI src1 src2));
  format %{ "xvmul.w    $dst, $src1, $src2\t# @mul8I" %}
  ins_encode %{
    __ xvmul_w($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct mul8F(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (MulVF src1 src2));
  format %{ "xvfmul.s    $dst, $src1, $src2\t# @mul8F" %}
  ins_encode %{
    __ xvfmul_s($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct mul4D(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (MulVD src1 src2));
  format %{ "xvfmul.d    $dst, $src1, $src2\t# @mul4D" %}
  ins_encode %{
    __ xvfmul_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- DIV --------------------------------------
instruct div4F(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (DivVF src1 src2));
  format %{ "vfdiv.s    $dst, $src1, $src2\t# @div4F" %}
  ins_encode %{
    __ vfdiv_s($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct div2D(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (DivVD src1 src2));
  format %{ "vfdiv.d    $dst, $src1, $src2\t# @div2D" %}
  ins_encode %{
    __ vfdiv_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct div8F(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (DivVF src1 src2));
  format %{ "xvfdiv.s    $dst, $src1, $src2\t# @div8F" %}
  ins_encode %{
    __ xvfdiv_s($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct div4D(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (DivVD src1 src2));
  format %{ "xvfdiv.d    $dst, $src1, $src2\t# @div4D" %}
  ins_encode %{
    __ xvfdiv_d($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

// ------------------------------ Shift ---------------------------------------

instruct shiftcntX(vecX dst, mRegI cnt) %{
  predicate(n->as_Vector()->length_in_bytes() == 16);
  match(Set dst (LShiftCntV cnt));
  match(Set dst (RShiftCntV cnt));
  format %{ "vreplgr2vr.b    $dst, $cnt\t# @shiftcntX" %}
  ins_encode %{
    __ vreplgr2vr_b($dst$$FloatRegister, $cnt$$Register);
  %}
  ins_pipe( pipe_slow );
%}

instruct shiftcntY(vecY dst, mRegI cnt) %{
  predicate(n->as_Vector()->length_in_bytes() == 32);
  match(Set dst (LShiftCntV cnt));
  match(Set dst (RShiftCntV cnt));
  format %{ "xvreplgr2vr.b    $dst, $cnt\t# @shiftcntY" %}
  ins_encode %{
    __ xvreplgr2vr_b($dst$$FloatRegister, $cnt$$Register);
  %}
  ins_pipe( pipe_slow );
%}

// ------------------------------ LeftShift -----------------------------------

instruct sll16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (LShiftVB src shift));
  effect(TEMP dst, TEMP tmp);
  format %{ "vsll    $dst, $src, $shift\t# TEMP($tmp) @sll16B" %}
  ins_encode %{
    __ vsll_b($tmp$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
    __ vslti_bu($dst$$FloatRegister, $shift$$FloatRegister, 0x8);
    __ vand_v($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll16B_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (LShiftVB src shift));
  format %{ "vslli.b    $dst, $src, $shift\t# @sll16B_imm" %}
  ins_encode %{
    if ($shift$$constant >= 8) {
      __ vxor_v($dst$$FloatRegister, $dst$$FloatRegister, $dst$$FloatRegister);
    } else {
      __ vslli_b($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct sll8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (LShiftVS src shift));
  effect(TEMP dst, TEMP tmp);
  format %{ "vsll    $dst, $src, $shift\t# TEMP($tmp) @sll8S" %}
  ins_encode %{
    __ vsll_h($tmp$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
    __ vslti_bu($dst$$FloatRegister, $shift$$FloatRegister, 0x10);
    __ vand_v($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll8S_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (LShiftVS src shift));
  format %{ "vslli.h    $dst, $src, $shift\t# @sll8S_imm" %}
  ins_encode %{
    if ($shift$$constant >= 16) {
      __ vxor_v($dst$$FloatRegister, $dst$$FloatRegister, $dst$$FloatRegister);
    } else {
      __ vslli_h($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct sll4I(vecX dst, vecX src, vecX shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (LShiftVI src shift));
  format %{ "vsll.w    $dst, $src, $shift\t# @sll4I" %}
  ins_encode %{
    __ vsll_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll4I_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (LShiftVI src shift));
  format %{ "vslli.w    $dst, $src, $shift\t# @sll4I_imm" %}
  ins_encode %{
    __ vslli_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll2L(vecX dst, vecX src, vecX shift) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (LShiftVL src shift));
  format %{ "vsll.d    $dst, $src, $shift\t# @sll2L" %}
  ins_encode %{
    __ vsll_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll2L_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (LShiftVL src shift));
  format %{ "vslli.d    $dst, $src, $shift\t# @sll2L_imm" %}
  ins_encode %{
    __ vslli_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll32B(vecY dst, vecY src, vecY shift, vecY tmp) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (LShiftVB src shift));
  effect(TEMP dst, TEMP tmp);
  format %{ "xvsll    $dst, $src, $shift\t# TEMP($tmp) @sll32B" %}
  ins_encode %{
    __ xvsll_b($tmp$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
    __ xvslti_bu($dst$$FloatRegister, $shift$$FloatRegister, 0x8);
    __ xvand_v($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll32B_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (LShiftVB src shift));
  format %{ "xvslli.b    $dst, $src, $shift\t# @sll32B_imm" %}
  ins_encode %{
    if ($shift$$constant >= 8) {
      __ xvxor_v($dst$$FloatRegister, $dst$$FloatRegister, $dst$$FloatRegister);
    } else {
      __ xvslli_b($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct sll16S(vecY dst, vecY src, vecY shift, vecY tmp) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (LShiftVS src shift));
  effect(TEMP dst, TEMP tmp);
  format %{ "xvsll    $dst, $src, $shift\t# TEMP($tmp) @sll16S" %}
  ins_encode %{
    __ xvsll_h($tmp$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
    __ xvslti_bu($dst$$FloatRegister, $shift$$FloatRegister, 0x10);
    __ xvand_v($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll16S_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (LShiftVS src shift));
  format %{ "xvslli.h    $dst, $src, $shift\t# @sll16S_imm" %}
  ins_encode %{
    if ($shift$$constant >= 16) {
      __ xvxor_v($dst$$FloatRegister, $dst$$FloatRegister, $dst$$FloatRegister);
    } else {
      __ xvslli_h($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct sll8I(vecY dst, vecY src, vecY shift) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (LShiftVI src shift));
  format %{ "xvsll.w    $dst, $src, $shift\t# @sll8I" %}
  ins_encode %{
    __ xvsll_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll8I_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (LShiftVI src shift));
  format %{ "xvslli.w    $dst, $src, $shift\t# @sll8I_imm" %}
  ins_encode %{
    __ xvslli_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll4L(vecY dst, vecY src, vecY shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (LShiftVL src shift));
  format %{ "xvsll.d    $dst, $src, $shift\t# @sll4L" %}
  ins_encode %{
    __ xvsll_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sll4L_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (LShiftVL src shift));
  format %{ "xvslli.d    $dst, $src, $shift\t# @sll4L_imm" %}
  ins_encode %{
    __ xvslli_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

// ----------------------- LogicalRightShift ----------------------------------

instruct srl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (URShiftVB src shift));
  effect(TEMP dst, TEMP tmp);
  format %{ "vsrl    $dst, $src, $shift\t# TEMP($tmp) @srl16B" %}
  ins_encode %{
    __ vsrl_b($tmp$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
    __ vslti_bu($dst$$FloatRegister, $shift$$FloatRegister, 0x8);
    __ vand_v($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl16B_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (URShiftVB src shift));
  format %{ "vsrli.b    $dst, $src, $shift\t# @srl16B_imm" %}
  ins_encode %{
    if ($shift$$constant >= 8) {
      __ vxor_v($dst$$FloatRegister, $dst$$FloatRegister, $dst$$FloatRegister);
    } else {
      __ vsrli_b($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct srl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (URShiftVS src shift));
  effect(TEMP dst, TEMP tmp);
  format %{ "vsrl    $dst, $src, $shift\t# TEMP($tmp) @srl8S" %}
  ins_encode %{
    __ vsrl_h($tmp$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
    __ vslti_bu($dst$$FloatRegister, $shift$$FloatRegister, 0x10);
    __ vand_v($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl8S_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (URShiftVS src shift));
  format %{ "vsrli.h    $dst, $src, $shift\t# @srl8S_imm" %}
  ins_encode %{
    if ($shift$$constant >= 16) {
      __ vxor_v($dst$$FloatRegister, $dst$$FloatRegister, $dst$$FloatRegister);
    } else {
      __ vsrli_h($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct srl4I(vecX dst, vecX src, vecX shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (URShiftVI src shift));
  format %{ "vsrl.w    $dst, $src, $shift\t# @srl4I" %}
  ins_encode %{
    __ vsrl_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl4I_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (URShiftVI src shift));
  format %{ "vsrli.w    $dst, $src, $shift\t# @srl4I_imm" %}
  ins_encode %{
    __ vsrli_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl2L(vecX dst, vecX src, vecX shift) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (URShiftVL src shift));
  format %{ "vsrl.d    $dst, $src, $shift\t# @srl2L" %}
  ins_encode %{
    __ vsrl_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl2L_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (URShiftVL src shift));
  format %{ "vsrli.d    $dst, $src, $shift\t# @srl2L_imm" %}
  ins_encode %{
    __ vsrli_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl32B(vecY dst, vecY src, vecY shift, vecY tmp) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (URShiftVB src shift));
  effect(TEMP dst, TEMP tmp);
  format %{ "xvsrl    $dst, $src, $shift\t# TEMP($tmp) @srl32B" %}
  ins_encode %{
    __ xvsrl_b($tmp$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
    __ xvslti_bu($dst$$FloatRegister, $shift$$FloatRegister, 0x8);
    __ xvand_v($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl32B_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (URShiftVB src shift));
  format %{ "xvsrli.b    $dst, $src, $shift\t# @srl32B_imm" %}
  ins_encode %{
    if ($shift$$constant >= 8) {
      __ xvxor_v($dst$$FloatRegister, $dst$$FloatRegister, $dst$$FloatRegister);
    } else {
      __ xvsrli_b($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct srl16S(vecY dst, vecY src, vecY shift, vecY tmp) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (URShiftVS src shift));
  effect(TEMP dst, TEMP tmp);
  format %{ "xvsrl    $dst, $src, $shift\t# TEMP($tmp) @srl16S" %}
  ins_encode %{
    __ xvsrl_h($tmp$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
    __ xvslti_bu($dst$$FloatRegister, $shift$$FloatRegister, 0x10);
    __ xvand_v($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl16S_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (URShiftVS src shift));
  format %{ "xvsrli.h    $dst, $src, $shift\t# @srl16S_imm" %}
  ins_encode %{
    if ($shift$$constant >= 16) {
      __ xvxor_v($dst$$FloatRegister, $dst$$FloatRegister, $dst$$FloatRegister);
    } else {
      __ xvsrli_h($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct srl8I(vecY dst, vecY src, vecY shift) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (URShiftVI src shift));
  format %{ "xvsrl.w    $dst, $src, $shift\t# @srl8I" %}
  ins_encode %{
    __ xvsrl_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl8I_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (URShiftVI src shift));
  format %{ "xvsrli.w    $dst, $src, $shift\t# @srl8I_imm" %}
  ins_encode %{
    __ xvsrli_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl4L(vecY dst, vecY src, vecY shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (URShiftVL src shift));
  format %{ "xvsrl.d    $dst, $src, $shift\t# @srl4L" %}
  ins_encode %{
    __ xvsrl_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct srl4L_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (URShiftVL src shift));
  format %{ "xvsrli.d    $dst, $src, $shift\t# @srl4L_imm" %}
  ins_encode %{
    __ xvsrli_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

// ------------------------- ArithmeticRightShift -----------------------------

instruct sra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (RShiftVB src shift));
  effect(TEMP tmp);
  format %{ "vsra    $dst, $src, $shift\t# TEMP($tmp) @sra16B" %}
  ins_encode %{
    __ vslti_bu($tmp$$FloatRegister, $shift$$FloatRegister, 0x8);
    __ vorn_v($tmp$$FloatRegister, $shift$$FloatRegister, $tmp$$FloatRegister);
    __ vsra_b($dst$$FloatRegister, $src$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra16B_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (RShiftVB src shift));
  format %{ "vsrai.b    $dst, $src, $shift\t# @sra16B_imm" %}
  ins_encode %{
    if ($shift$$constant >= 8) {
      __ vsrai_b($dst$$FloatRegister, $src$$FloatRegister, 7);
    } else {
      __ vsrai_b($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct sra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (RShiftVS src shift));
  effect(TEMP tmp);
  format %{ "vsra    $dst, $src, $shift\t# TEMP($tmp) @sra8S" %}
  ins_encode %{
    __ vslti_bu($tmp$$FloatRegister, $shift$$FloatRegister, 0x10);
    __ vorn_v($tmp$$FloatRegister, $shift$$FloatRegister, $tmp$$FloatRegister);
    __ vsra_h($dst$$FloatRegister, $src$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra8S_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (RShiftVS src shift));
  format %{ "vsrai.h    $dst, $src, $shift\t# @sra8S_imm" %}
  ins_encode %{
    if ($shift$$constant >= 16) {
      __ vsrai_h($dst$$FloatRegister, $src$$FloatRegister, 15);
    } else {
      __ vsrai_h($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct sra4I(vecX dst, vecX src, vecX shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (RShiftVI src shift));
  format %{ "vsra.w    $dst, $src, $shift\t# @sra4I" %}
  ins_encode %{
    __ vsra_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra4I_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (RShiftVI src shift));
  format %{ "vsrai.w    $dst, $src, $shift\t# @sra4I_imm" %}
  ins_encode %{
    __ vsrai_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra2L(vecX dst, vecX src, vecX shift) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (RShiftVL src shift));
  format %{ "vsra.d    $dst, $src, $shift\t# @sra2L" %}
  ins_encode %{
    __ vsra_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra2L_imm(vecX dst, vecX src, immI shift) %{
  predicate(n->as_Vector()->length() == 2);
  match(Set dst (RShiftVL src shift));
  format %{ "vsrai.d    $dst, $src, $shift\t# @sra2L_imm" %}
  ins_encode %{
    __ vsrai_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra32B(vecY dst, vecY src, vecY shift, vecY tmp) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (RShiftVB src shift));
  effect(TEMP tmp);
  format %{ "xvsra    $dst, $src, $shift\t# TEMP($tmp) @sra32B" %}
  ins_encode %{
    __ xvslti_bu($tmp$$FloatRegister, $shift$$FloatRegister, 0x8);
    __ xvorn_v($tmp$$FloatRegister, $shift$$FloatRegister, $tmp$$FloatRegister);
    __ xvsra_b($dst$$FloatRegister, $src$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra32B_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (RShiftVB src shift));
  format %{ "xvsrai.b    $dst, $src, $shift\t# @sra32B_imm" %}
  ins_encode %{
    if ($shift$$constant >= 8) {
      __ xvsrai_b($dst$$FloatRegister, $src$$FloatRegister, 7);
    } else {
      __ xvsrai_b($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct sra16S(vecY dst, vecY src, vecY shift, vecY tmp) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (RShiftVS src shift));
  effect(TEMP tmp);
  format %{ "xvsra    $dst, $src, $shift\t# TEMP($tmp) @sra16S" %}
  ins_encode %{
    __ xvslti_bu($tmp$$FloatRegister, $shift$$FloatRegister, 0x10);
    __ xvorn_v($tmp$$FloatRegister, $shift$$FloatRegister, $tmp$$FloatRegister);
    __ xvsra_h($dst$$FloatRegister, $src$$FloatRegister, $tmp$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra16S_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (RShiftVS src shift));
  format %{ "xvsrai.h    $dst, $src, $shift\t# @sra16S_imm" %}
  ins_encode %{
    if ($shift$$constant >= 16) {
      __ xvsrai_h($dst$$FloatRegister, $src$$FloatRegister, 15);
    } else {
      __ xvsrai_h($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct sra8I(vecY dst, vecY src, vecY shift) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (RShiftVI src shift));
  format %{ "xvsra.w    $dst, $src, $shift\t# @sra8I" %}
  ins_encode %{
    __ xvsra_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra8I_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 8);
  match(Set dst (RShiftVI src shift));
  format %{ "xvsrai.w    $dst, $src, $shift\t# @sra8I_imm" %}
  ins_encode %{
    __ xvsrai_w($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra4L(vecY dst, vecY src, vecY shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (RShiftVL src shift));
  format %{ "xvsra.d    $dst, $src, $shift\t# @sra4L" %}
  ins_encode %{
    __ xvsra_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct sra4L_imm(vecY dst, vecY src, immI shift) %{
  predicate(n->as_Vector()->length() == 4);
  match(Set dst (RShiftVL src shift));
  format %{ "xvsrai.d    $dst, $src, $shift\t# @sra4L_imm" %}
  ins_encode %{
    __ xvsrai_d($dst$$FloatRegister, $src$$FloatRegister, $shift$$constant);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- AND --------------------------------------

instruct andV16(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length_in_bytes() == 16);
  match(Set dst (AndV src1 src2));
  format %{ "vand.v    $dst, $src1, $src2\t# @andV16" %}
  ins_encode %{
    __ vand_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct and16B_imm(vecX dst, vecX src, immIU8 imm) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (AndV src (ReplicateB imm)));
  format %{ "vandi.b    $dst, $src, $imm\t# @and16B_imm" %}
  ins_encode %{
    __ vandi_b($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct andV32(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length_in_bytes() == 32);
  match(Set dst (AndV src1 src2));
  format %{ "xvand.v    $dst, $src1, $src2\t# @andV32" %}
  ins_encode %{
    __ xvand_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct and32B_imm(vecY dst, vecY src, immIU8 imm) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (AndV src (ReplicateB imm)));
  format %{ "xvandi.b    $dst, $src, $imm\t# @and32B_imm" %}
  ins_encode %{
    __ xvandi_b($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- OR ---------------------------------------

instruct orV16(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length_in_bytes() == 16);
  match(Set dst (OrV src1 src2));
  format %{ "vor.v    $dst, $src1, $src2\t# @orV16" %}
  ins_encode %{
    __ vor_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct or16B_imm(vecX dst, vecX src, immIU8 imm) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (OrV src (ReplicateB imm)));
  format %{ "vori.b    $dst, $src, $imm\t# @or16B_imm" %}
  ins_encode %{
    __ vori_b($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct orV32(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length_in_bytes() == 32);
  match(Set dst (OrV src1 src2));
  format %{ "xvor.v    $dst, $src1, $src2\t# @orV32" %}
  ins_encode %{
    __ xvor_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct or32B_imm(vecY dst, vecY src, immIU8 imm) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (OrV src (ReplicateB imm)));
  format %{ "xvori.b    $dst, $src, $imm\t# @or32B_imm" %}
  ins_encode %{
    __ xvori_b($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- XOR --------------------------------------

instruct xorV16(vecX dst, vecX src1, vecX src2) %{
  predicate(n->as_Vector()->length_in_bytes() == 16);
  match(Set dst (XorV src1 src2));
  format %{ "vxor.v    $dst, $src1, $src2\t# @xorV16" %}
  ins_encode %{
    __ vxor_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct xor16B_imm(vecX dst, vecX src, immIU8 imm) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (XorV src (ReplicateB imm)));
  format %{ "vxori.b    $dst, $src, $imm\t# @xor16B_imm" %}
  ins_encode %{
    __ vxori_b($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct xorV32(vecY dst, vecY src1, vecY src2) %{
  predicate(n->as_Vector()->length_in_bytes() == 32);
  match(Set dst (XorV src1 src2));
  format %{ "xvxor.v    $dst, $src1, $src2\t# @xorV32" %}
  ins_encode %{
    __ xvxor_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct xor32B_imm(vecX dst, vecX src, immIU8 imm) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (XorV src (ReplicateB imm)));
  format %{ "xvxori.b    $dst, $src, $imm\t# @xor32B_imm" %}
  ins_encode %{
    __ xvxori_b($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- NOR --------------------------------------

instruct norV16(vecX dst, vecX src1, vecX src2, immI_M1 m1) %{
  predicate(n->as_Vector()->length_in_bytes() == 16);
  match(Set dst (XorV (OrV src1 src2) (ReplicateB m1)));
  match(Set dst (XorV (OrV src1 src2) (ReplicateS m1)));
  match(Set dst (XorV (OrV src1 src2) (ReplicateI m1)));
  format %{ "vnor.v    $dst, $src1, $src2\t# @norV16" %}
  ins_encode %{
    __ vnor_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct nor16B_imm(vecX dst, vecX src, immIU8 imm, immI_M1 m1) %{
  predicate(n->as_Vector()->length() == 16);
  match(Set dst (XorV (OrV src (ReplicateB imm)) (ReplicateB m1)));
  format %{ "vnori.b    $dst, $src, $imm\t# @nor16B_imm" %}
  ins_encode %{
    __ vnori_b($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

instruct norV32(vecY dst, vecY src1, vecY src2, immI_M1 m1) %{
  predicate(n->as_Vector()->length_in_bytes() == 32);
  match(Set dst (XorV (OrV src1 src2) (ReplicateB m1)));
  match(Set dst (XorV (OrV src1 src2) (ReplicateS m1)));
  match(Set dst (XorV (OrV src1 src2) (ReplicateI m1)));
  format %{ "xvnor.v    $dst, $src1, $src2\t# @norV32" %}
  ins_encode %{
    __ xvnor_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct nor32B_imm(vecY dst, vecY src, immIU8 imm, immI_M1 m1) %{
  predicate(n->as_Vector()->length() == 32);
  match(Set dst (XorV (OrV src (ReplicateB imm)) (ReplicateB m1)));
  format %{ "xvnori.b    $dst, $src, $imm\t# @nor32B_imm" %}
  ins_encode %{
    __ xvnori_b($dst$$FloatRegister, $src$$FloatRegister, $imm$$constant);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- ANDN -------------------------------------

instruct andnV16(vecX dst, vecX src1, vecX src2, immI_M1 m1) %{
  predicate(n->as_Vector()->length_in_bytes() == 16);
  match(Set dst (AndV src2 (XorV src1 (ReplicateB m1))));
  match(Set dst (AndV src2 (XorV src1 (ReplicateS m1))));
  match(Set dst (AndV src2 (XorV src1 (ReplicateI m1))));
  format %{ "vandn.v    $dst, $src1, $src2\t# @andnV16" %}
  ins_encode %{
    __ vandn_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct andnV32(vecY dst, vecY src1, vecY src2, immI_M1 m1) %{
  predicate(n->as_Vector()->length_in_bytes() == 32);
  match(Set dst (AndV src2 (XorV src1 (ReplicateB m1))));
  match(Set dst (AndV src2 (XorV src1 (ReplicateS m1))));
  match(Set dst (AndV src2 (XorV src1 (ReplicateI m1))));
  format %{ "xvandn.v    $dst, $src1, $src2\t# @andnV32" %}
  ins_encode %{
    __ xvandn_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

// --------------------------------- ORN --------------------------------------

instruct ornV16(vecX dst, vecX src1, vecX src2, immI_M1 m1) %{
  predicate(n->as_Vector()->length_in_bytes() == 16);
  match(Set dst (OrV src1 (XorV src2 (ReplicateB m1))));
  match(Set dst (OrV src1 (XorV src2 (ReplicateS m1))));
  match(Set dst (OrV src1 (XorV src2 (ReplicateI m1))));
  format %{ "vorn.v    $dst, $src1, $src2\t# @ornV16" %}
  ins_encode %{
    __ vorn_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}

instruct ornV32(vecY dst, vecY src1, vecY src2, immI_M1 m1) %{
  predicate(n->as_Vector()->length_in_bytes() == 32);
  match(Set dst (OrV src1 (XorV src2 (ReplicateB m1))));
  match(Set dst (OrV src1 (XorV src2 (ReplicateS m1))));
  match(Set dst (OrV src1 (XorV src2 (ReplicateI m1))));
  format %{ "xvorn.v    $dst, $src1, $src2\t# @ornV32" %}
  ins_encode %{
    __ xvorn_v($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
  %}
  ins_pipe( pipe_slow );
%}


//----------PEEPHOLE RULES-----------------------------------------------------
// These must follow all instruction definitions as they use the names
// defined in the instructions definitions.
//
// peepmatch ( root_instr_name [preceeding_instruction]* );
//
// peepconstraint %{
// (instruction_number.operand_name relational_op instruction_number.operand_name
//  [, ...] );
// // instruction numbers are zero-based using left to right order in peepmatch
//
// peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
// // provide an instruction_number.operand_name for each operand that appears
// // in the replacement instruction's match rule
//
// ---------VM FLAGS---------------------------------------------------------
//
// All peephole optimizations can be turned off using -XX:-OptoPeephole
//
// Each peephole rule is given an identifying number starting with zero and
// increasing by one in the order seen by the parser.  An individual peephole
// can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
// on the command-line.
//
// ---------CURRENT LIMITATIONS----------------------------------------------
//
// Only match adjacent instructions in same basic block
// Only equality constraints
// Only constraints between operands, not (0.dest_reg == EAX_enc)
// Only one replacement instruction
//
// ---------EXAMPLE----------------------------------------------------------
//
// // pertinent parts of existing instructions in architecture description
// instruct movI(eRegI dst, eRegI src) %{
//   match(Set dst (CopyI src));
// %}
//
// instruct incI_eReg(eRegI dst, immI_1 src, eFlagsReg cr) %{
//   match(Set dst (AddI dst src));
//   effect(KILL cr);
// %}
//
// // Change (inc mov) to lea
// peephole %{
//   // increment preceeded by register-register move
//   peepmatch ( incI_eReg movI );
//   // require that the destination register of the increment
//   // match the destination register of the move
//   peepconstraint ( 0.dst == 1.dst );
//   // construct a replacement instruction that sets
//   // the destination to ( move's source register + one )
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
//
// Implementation no longer uses movX instructions since
// machine-independent system no longer uses CopyX nodes.
//
// peephole %{
//   peepmatch ( incI_eReg movI );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
//
// peephole %{
//   peepmatch ( decI_eReg movI );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
//
// peephole %{
//   peepmatch ( addI_eReg_imm movI );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
//
// peephole %{
//   peepmatch ( addP_eReg_imm movP );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaP_eReg_immI( 0.dst 1.src 0.src ) );
// %}

// // Change load of spilled value to only a spill
// instruct storeI(memory mem, eRegI src) %{
//   match(Set mem (StoreI mem src));
// %}
//
// instruct loadI(eRegI dst, memory mem) %{
//   match(Set dst (LoadI mem));
// %}
//
//peephole %{
//  peepmatch ( loadI storeI );
//  peepconstraint ( 1.src == 0.dst, 1.mem == 0.mem );
//  peepreplace ( storeI( 1.mem 1.mem 1.src ) );
//%}

//----------SMARTSPILL RULES---------------------------------------------------
// These must follow all instruction definitions as they use the names
// defined in the instructions definitions.

